<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Animation on Gazoo.vrv</title>
    <link>http://donw.io/tags/animation/</link>
    <description>Recent content in Animation on Gazoo.vrv</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Aug 2012 16:07:23 +0100</lastBuildDate>
    <atom:link href="http://donw.io/tags/animation/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Skeletal Animation Looping with Autocorrelation</title>
      <link>http://donw.io/post/animation-autocorrelation/</link>
      <pubDate>Mon, 20 Aug 2012 16:07:23 +0100</pubDate>
      
      <guid>http://donw.io/post/animation-autocorrelation/</guid>
      <description>

&lt;p&gt;This is a bit of a fun post highlighting how some simple maths can be used to create great visual results. With some basic statistics, we can create looping skeletal animations from an input data set that contains non-exact loops. A typical example is a motion capture sampled run animation:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;http://donw.io/img/AnimLooping/OriginalAnim.gif&#34; alt=&#34;d&#34; /&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;This is derived from the &lt;a href=&#34;http://mocap.cs.cmu.edu/&#34;&gt;CMU Graphics Lab Motion Capture Database&lt;/a&gt;, which has been &lt;a href=&#34;https://sites.google.com/a/cgspeed.com/cgspeed/motion-capture/cmu-bvh-conversion&#34;&gt;converted to BVH files&lt;/a&gt; by Bruce Hahne. I can load BVH files and dynamically retarget them to my animation rigs so that I never have to worry about changing animation rigs again (this is absolutely key to some of the features of my product and would have been immensely useful for the animation pipelines in many of my past games).&lt;/p&gt;

&lt;p&gt;The first task is to center the animation on the origin to allow movement to be controlled by the game. Appropriate playback timing/blending and IK foot fixups are added after that. Many games simply strip the root bone offset from the animation but you lose a lot of animated weight transfer and bounce. I chose instead to send out a &amp;ldquo;rabbit&amp;rdquo; node that attempts to keep up with the moving skeleton via a fixed linear velocity, subtracting its position to get:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;http://donw.io/img/AnimLooping/CenteredAnim.gif&#34; alt=&#34;d&#34; /&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;You can notice the three-and-a-bit steps the skeleton takes, the slow raising of the torso and the hard snap at the end when the animation ends. Somewhere in there is a two step loop that can be used to create a seamlessly looping animation. The tasks required are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use auto/cross correlation to identify potential loop lengths in the animation.&lt;/li&gt;
&lt;li&gt;Search the animation using the loop lengths for start and end frames whose poses match.&lt;/li&gt;
&lt;li&gt;Cross-fade the beginning and end of the animation to smooth out the differences.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Statistics aren&amp;rsquo;t my strong point so I would really appreciate any corrections to this post!&lt;/p&gt;

&lt;h5 id=&#34;cross-correlation:894f9b4cb59901f5bf4506e115ff54db&#34;&gt;Cross Correlation&lt;/h5&gt;

&lt;p&gt;Given two discrete real data sets:&lt;/p&gt;

&lt;p&gt;$$x = [ x_0, x_1, x_2, &amp;hellip;, x_n ]$$
$$y = [ y_0, y_1, y_2, &amp;hellip;, y_n ]$$&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Correlation_and_dependence&#34;&gt;Correlation&lt;/a&gt; can give you a single number that tells you how similar these two data sets are. This number is generally called the correlation coefficient and can be calculated in a number of different ways, depending on what particular features of the data set you&amp;rsquo;re interested in highlighting.&lt;/p&gt;

&lt;p&gt;The most common coefficient appears to be the &lt;a href=&#34;http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient&#34;&gt;Pearson product-moment correlation coefficient&lt;/a&gt;. The coefficient is in the range -1 to 1, where 1 means there is a perfect linear relationship, 0 means there is no relationship and -1 means there is a negative linear relationship. A simple definition for a population is:&lt;/p&gt;

&lt;p&gt;$$R(x,y) = \frac{1}{n} \sum\limits_{i=1}^n \frac{x(i) - m(x)}{s(x)} * \frac{y(i) - m(y)}{s(y)}$$&lt;/p&gt;

&lt;p&gt;where $m$ is the median and $s$ is the standard deviation of the population.&lt;/p&gt;

&lt;p&gt;Interestingly, this coefficient is independent of the unit of measurement: it can report 100% correlation between data sets that differ in scale or offset. For example, if set $x$ recorded your age in months and set $y$ recorded your height in inches at that age, it will be able to report any linear relationship (e.g. you get taller as you get older) with a correlation coefficient close to 1. This nice result is achieved by first of all centering each data set on its median and then transforming the set into units of its standard deviation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Cross-correlation&#34;&gt;Cross Correlation&lt;/a&gt; uses this basic tool to evaluate how similar two input data sets are when one of them is offset (or, time-lagged in the case of audio samples). Assuming the data sets are equal in length, for every sample in $x$, the correlation coefficient is calculated with an offset version of $y$:&lt;/p&gt;

&lt;p&gt;$$xcorr(x, y)[n] = sum(x&amp;rsquo; [m] * y[m + n])$$&lt;/p&gt;

&lt;p&gt;Here, $&amp;lsquo;$ is the complex conjugate. As we&amp;rsquo;ll be dealing with real numbers, this can safely be ignored. You can use this for many things, like detecting the presence of one signal (or similar) somewhere within another, measuring tempo or even auto-tuning (yes, Mathematicians helped create our current generation of &lt;a href=&#34;http://www.time.com/time/magazine/article/0,9171,1877372,00.html&#34;&gt;talentless musicians&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;This leads to the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;double CrossCorrelate(const std::vector&amp;lt;double&amp;gt;&amp;amp; x, const std::vector&amp;lt;double&amp;gt;&amp;amp; y)
{
    // Assume data sets are the same size
    size_t size = x.size();
    assert(size == y.size());

    // Calculate mean and standard deviation of data sets
    double mx = mean(x);
    double my = mean(y);
    double sx = stddev(x);
    double sy = stddev(y);

    // Calculate correlation coefficient for each offset
    std::vector&amp;lt;double&amp;gt; Rxy(size);
    for (size_t i = 0; i &amp;lt; size; i++)
    {
        // First term can be pulled out of the inner loop
        double a = (x[i] - mx) / sx;

        double c = 0;
        for (size_t j = 0; j &amp;lt; size; j++)
        {
            // Second term is always offset by the constant &#39;i&#39;
            // I&#39;m choosing to wrap here whereas you can also zero-pad
            size_t ij = (i + j) % size;
            double b = (y[ij] - my) / sy;

            c += a * b;
        }

        Rxy[i] = c / size;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assuming the input data sets are the same size is not very useful in reality, however we don&amp;rsquo;t need to do full cross correlation. With animation, we want to be able to detect loops within one dataset; essentially making $x$ and $y$ the same.&lt;/p&gt;

&lt;p&gt;This is called &lt;a href=&#34;http://en.wikipedia.org/wiki/Autocorrelation&#34;&gt;Autocorrelation&lt;/a&gt; and it gets even better. Given that we&amp;rsquo;re not interested in the unit-independent properties of cross correlation (we&amp;rsquo;re comparing the same data set values), we can set the median to zero and standard deviation to one, leaving:&lt;/p&gt;

&lt;p&gt;$$R(x,y) = \frac{1}{n} \sum\limits_{i=1}^n x(i) * y(i)$$&lt;/p&gt;

&lt;h5 id=&#34;application-to-skeletal-animation:894f9b4cb59901f5bf4506e115ff54db&#34;&gt;Application to Skeletal Animation&lt;/h5&gt;

&lt;p&gt;The data set we have is the rotation values of each bone in an animation for each frame (I&amp;rsquo;m ignoring scale as you don&amp;rsquo;t generally get that from BVH data and translations are present only on root bones). We want to perform autocorrelation for each frame of the animation with a frame offset version of itself.&lt;/p&gt;

&lt;p&gt;Autocorrelation above was defined in terms of scalar value multiplication, so an equivalent data type and multiplication operator needs to be defined for a single frame of animation. This can be achieved by using a vector of all bone rotations for a specific frame, combined with a vector dot product, which is effectively a projection of one frame onto another (result is max when all bones line up).&lt;/p&gt;

&lt;p&gt;You can use the quaternion values directly or euler angles; it doesn&amp;rsquo;t matter. We&amp;rsquo;re not interested in the values themselves, we&amp;rsquo;re just interested in how they relate to each other. I have found, though, that I&amp;rsquo;m getting better results using rotations that are relative to their parent bone, as opposed to object-space rotations.&lt;/p&gt;

&lt;p&gt;This leads to the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct Anim
{
    size_t int nb_bones;
    size_t int nb_frames;

    // Just rotation data for all bones in all frames
    // size = nb_bones * nb_frames
    std::vector&amp;lt;quat&amp;gt; frame_data;
};

double DotProduct(
    const std::vector&amp;lt;quat&amp;gt;&amp;amp; x,
    const std::vector&amp;lt;quat&amp;gt;&amp;amp; y,
    size_t ox,
    size_t oy,
    size_t vector_size)
{
    // Dot product of two frame vectors. As they&#39;re just collections of rotation quaternions,
    // sum all quaternion dot products.
    double dp = 0;
    for (size_t i = 0; i &amp;lt; vector_size; i++)
    {
        quat q0 = x[ox + i];
        quat q1 = y[oy + i];
        dp += q0.x * q1.x + q0.y * q1.y + q0.z * q1.z + q0.w * q1.w;
    }
    return dp;
}


double Correlate(
    const Anim&amp;amp; anim,
    const std::vector&amp;lt;quat&amp;gt;&amp;amp; x,
    const std::vector&amp;lt;quat&amp;gt;&amp;amp; y,
    size_t frame_offset)
{
    double Rxy = 0;
    for (size_t i = 0; i &amp;lt; anim.nb_frames; i++)
    {
        // Shift and wrap to keep the inputs the same length
        size_t ox = i;
        size_t oy = (frame_offset + i) % anim.nb_frames;

        // Calculating the Pearson correlation co-efficient using mean of zero and stdev of 1
        Rxy += DotProduct(x, y, ox, oy, anim.nb_bones);
    }

    return Rxy / anim.nb_frames;
}

// Calculate the cross-correlation sequence using the same animation for both inputs (auto-correlation)
std::vector&amp;lt;double&amp;gt; Rxy(anim.nb_frames);
for (size_t i = 0; i &amp;lt; anim.nb_frames; i++)
    Rxy[i] = Correlate(anim, anim.frame_data, anim.frame_data, i);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When applied to the centered animation above, the sequence looks like this:&lt;/p&gt;

&lt;div id=&#34;xcorr_anim_graph&#34; style=&#34;width:400px;height:250px;margin-left:auto;margin-right:auto;&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;text/javascript&#34;&gt;
	new Dygraph(document.getElementById(&#34;xcorr_anim_graph&#34;), &#34;\/img\/AnimLooping\/a.csv&#34;,
		{
			title: &#34;Autocorrelation Sequence&#34;,
			titleHeight: 22,
			xlabel: &#34;Click and drag to zoom; double-click to restore zoom level&#34;,
			xLabelHeight: 12,
		});
&lt;/script&gt;
&lt;br/&gt;


&lt;p&gt;We&amp;rsquo;re interested here in looking for the peaks of the graph, answering the question: other than at the start, where does the animation most look like itself? This is a standard local maximum search that starts off with computing the first derivative:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// We want to detect the local minimum/maximum points in the sequence, as periodicity
// estimates for the animation so calculate 1st derivative
std::vector&amp;lt;double&amp;gt; Rxy_df(anim.nb_frames);
for (size_t i = 1; i &amp;lt; Rxy.size(); i++)
    Rxy_df[i] = Rxy[i] - Rxy[i - 1];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;leading to:&lt;/p&gt;

&lt;div id=&#34;1stderiv_anim_graph&#34; style=&#34;width:400px;height:250px;margin-left:auto;margin-right:auto;&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;text/javascript&#34;&gt;
	new Dygraph(document.getElementById(&#34;1stderiv_anim_graph&#34;), &#34;\/img\/AnimLooping\/b.csv&#34;,
		{
			title: &#34;First Derivative&#34;,
			titleHeight: 22,
			xlabel: &#34;Click and drag to zoom; double-click to restore zoom level&#34;,
			xLabelHeight: 12,
		});
&lt;/script&gt;
&lt;br/&gt;


&lt;p&gt;Local minima/maxima are located at the zero crossings and local maxima can be detected where the derivative is decreasing.&lt;/p&gt;

&lt;h5 id=&#34;searching-for-start-and-end-frames:894f9b4cb59901f5bf4506e115ff54db&#34;&gt;Searching for Start and End Frames&lt;/h5&gt;

&lt;p&gt;Just as autocorrelation in audio can only measure tempo and not tell you where specific beats are, this technique will only tell you potential lengths of the animation. Autocorrelation is a function of the signal, not a frame, so we will need to search the animation for start/end frames that match each other as closely as possible.&lt;/p&gt;

&lt;p&gt;Beyond rotation similarity, we also want to ensure velocity/acceleration and general trajectory similarity. Given a potential start and end frame, we can determine a simple measure of similarity by summing squared distances within a set window. By walking through all possible start/end frames and keeping the smallest sum, we can get our best match.&lt;/p&gt;

&lt;p&gt;This code is based on Benjy Cook&amp;rsquo;s Python mocap tools for Blender, linked below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;double SqrDistance(
    const std::vector&amp;lt;quat&amp;gt;&amp;amp; x,
    const std::vector&amp;lt;quat&amp;gt;&amp;amp; y,
    size_t ox,
    size_t oy,
    size_t vector_size)
{
    double d = 0;
    for (size_t i = 0; i &amp;lt; vector_size; i++)
    {
        quat q0 = x[ox + i];
        quat q1 = y[oy + i];
        quat q = { q0.x - q1.x, q0.y - q1.y, q0.z - q1.z, q0.w - q1.w };
        d += q.x * q.x + q.y * q.y + q.z * q.z + q.w * q.w;
    }
    return d;
}

static const int WINDOW_SIZE = 5;
int best_fit_frame = -1;
size_t best_fit_length = 0;
double best_fit_sum = 0;

for (size_t i = 0; i &amp;lt; local_maxima.size(); i++)
{
    size_t length = local_maxima[i];

    // Precalculate distances between all possible start/end frames at this length
    std::vector&amp;lt;double&amp;gt; distance(anim.nb_frames - length);
    for (size_t j = 0; j &amp;lt; distance.size(); j++)
    {
        size_t ox = j * anim.nb_bones;
        size_t oy = (j + length) * anim.nb_bones;
        distance[j] = SqrDistance(anim.frame_data, anim.frame_data, ox, oy, anim.nb_bones);
    }

    // Search for the best start/end frame pair
    for (size_t j = WINDOW_SIZE; j &amp;lt; distance.size() - WINDOW_SIZE - 1; j++)
    {
        // Sum distances in local neighbourhood
        double sum = 0;
        for (size_t k = j - WINDOW_SIZE; k &amp;lt;= j + WINDOW_SIZE; k++)
            sum += distance[k];

        // Keep the best fit
        if (best_fit_frame == -1 || sum &amp;lt; best_fit_sum)
        {
            best_fit_frame = j;
            best_fit_length = length;
            best_fit_sum = sum;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using the best fit frame and length, the animation can then be clipped to give:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;http://donw.io/img/AnimLooping/ClippedAnim.gif&#34; alt=&#34;d&#34; /&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;There are a few things to note about the result:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The two step loop has been correctly identified.&lt;/li&gt;
&lt;li&gt;The start and end frames match pretty well: both leg and arm movement is almost seamless.&lt;/li&gt;
&lt;li&gt;There is a visible snap after the torso still rises for the duration of the animation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Beyond employing better loop detection methods, this is really the best we can do without modifying the original animation. Even if we tried to look for better techniques, the chances of a single mocap shoot giving a perfectly loopable animation are minimal.&lt;/p&gt;

&lt;h5 id=&#34;cross-fading-around-the-seam:894f9b4cb59901f5bf4506e115ff54db&#34;&gt;Cross-fading Around the Seam&lt;/h5&gt;

&lt;p&gt;The final simple part to this is to blend the last few frames in the animation so that they meet seamlessly with the frame at the start of the animation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;static const int BLEND_SIZE = 10;
for (size_t i = 0; i &amp;lt; BLEND_SIZE; i++)
{
    size_t offset = (anim.nb_frames - BLEND_SIZE + i) * anim.nb_bones;
    double t = (double)i / BLEND_SIZE;

    for (size_t j = 0; j &amp;lt; anim.nb_bones; j++)
    {
        const math::frame&amp;amp; dst = anim.frame_data[j];
        math::frame&amp;amp; src = anim.frame_data[offset + j];
        src = fLerp(src, dst, (float)t);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A &lt;code&gt;frame&lt;/code&gt; in my code base is an &lt;a href=&#34;http://en.wikipedia.org/wiki/Affine_frame&#34;&gt;Affine Frame&lt;/a&gt; with vector position and quaternion rotation. I linearly interpolate both components based on their distance from the end of the animation (the quaternion lerp is normalised, as opposed to &lt;a href=&#34;http://number-none.com/product/Understanding%20Slerp,%20Then%20Not%20Using%20It/&#34;&gt;using slerp&lt;/a&gt;). This cleans up any small position differences in the hip bone.&lt;/p&gt;

&lt;p&gt;The final result is pretty cool!&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;http://donw.io/img/AnimLooping/LoopingAnim.gif&#34; alt=&#34;d&#34; /&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;You can tweak the number of blend frames a little to get a smoother transition.&lt;/p&gt;

&lt;h5 id=&#34;conclusion:894f9b4cb59901f5bf4506e115ff54db&#34;&gt;Conclusion&lt;/h5&gt;

&lt;p&gt;There is a whole bunch of stuff that you&amp;rsquo;ll need to do to make this production-ready (loops within loops, signal filtering, artist pre/post input/modification, etc) but it this should be a good start.&lt;/p&gt;

&lt;p&gt;Curiously, while debugging all my code for this I found that zero-crossings of the second differential (representing local minima of the first derivative) were giving good approximations to the start and end frame in animation loops:&lt;/p&gt;

&lt;div id=&#34;2ndderiv_anim_graph&#34; style=&#34;width:400px;height:250px;margin-left:auto;margin-right:auto;&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;text/javascript&#34;&gt;
	new Dygraph(document.getElementById(&#34;2ndderiv_anim_graph&#34;), &#34;\/img\/AnimLooping\/c.csv&#34;,
		{
			title: &#34;Second Derivative&#34;,
			titleHeight: 22,
			xlabel: &#34;Click and drag to zoom; double-click to restore zoom level&#34;,
			xLabelHeight: 12,
		});
&lt;/script&gt;
&lt;br/&gt;


&lt;p&gt;If I start this specific animation at 15 and end it at 123, it loops just as well! I&amp;rsquo;ve not tested this on many data sets or dug into the maths further to see if there is anything to this, but it&amp;rsquo;s an interesting avenue for future investigation.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s some links for further reading:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://wiki.blender.org/index.php/Extensions:2.6/Py/Scripts/Animation/Motion_Capture_Tools&#34;&gt;Blender Mocap Tools&lt;/a&gt; - A great source code reference for stuff like this, written by &lt;a href=&#34;https://plus.google.com/104243235864119960562&#34;&gt;Benjy Cook&lt;/a&gt;. (Python)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.hawaii.edu/powerkills/UC.HTM&#34;&gt;Understanding Correlation&lt;/a&gt; - Online book hoping to shed some intuition on correlation.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://audiograins.com/blog/tag/cross-correlation/&#34;&gt;Autocorrelation for Tempo Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://dsp.stackexchange.com/questions/736/how-do-i-implement-cross-correlation-to-prove-two-audio-files-are-similar&#34;&gt;How do I implement Cross-correlation to prove two audio files are similar?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Quaternions and Dual Quaternion Skinning</title>
      <link>http://donw.io/post/dual-quaternion-skinning/</link>
      <pubDate>Thu, 19 Jul 2012 12:52:03 +0100</pubDate>
      
      <guid>http://donw.io/post/dual-quaternion-skinning/</guid>
      <description>

&lt;p&gt;For some reason I like quaternions. I fell in love with complex numbers back in school when I found out that they &lt;a href=&#34;http://en.wikipedia.org/wiki/Algebraically_closed_field#Examples&#34;&gt;made more sense than real numbers&lt;/a&gt;. While it &lt;a href=&#34;http://www.geometricalgebra.net/quaternions.html&#34;&gt;might not exactly be helpful&lt;/a&gt; to visualise quaternions as an extension of complex numbers, there&amp;rsquo;s something in there that just grabs at me. Unlike previous posts, I&amp;rsquo;ve managed to update to D3D11 so I&amp;rsquo;ll be discussing implementation details in terms of HLSL (Shader Model 4, as I also have a D3D10 dev machine).&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m no mathematician so hopefully this information in this post should be pretty accessible.&lt;/p&gt;

&lt;h5 id=&#34;dual-quaternion-skinning:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Dual Quaternion Skinning&lt;/h5&gt;

&lt;p&gt;I spent a couple of hours last week converting my skinning pipeline to use dual quaternions. My animation pipeline works with quaternions; the source animation data, skeleton pose and inverse base pose are quaternion-based. Right at the very end, the composited result is converted to matrix and sent to the GPU. In effect, I&amp;rsquo;m doing this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;for (int i = 0; i &amp;lt; nb_bones; i++)
{
    const rend::Bone&amp;amp; bone = skeleton.bones[i];
    const rend::Keyframe&amp;amp; kf = keyframes[i + frame * nb_bones];

    // Calculate inverse base pose
    math::quat q0 = qConjugate(bone.base_pose.rotation);
    math::vec3 p0 = qTransformPos(q0, v3Negate(bone.base_pose.position));

    // Concatenate with animation keyframe
    math::quat q = qMultiply(q0, kf.rotation);
    math::vec3 p = qTransformPos(kf.rotation, p0);
    p = v3Add(p, kf.position);

    // Set the transform
    math::mat4&amp;amp; transform = transforms[i];
    transform = qToMat4(q);
    transform.r[3] = math::v4Make(p.x, p.y, p.z, 1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In reality, I precalculate the inverse base pose, keeping the inner loop tight and low on ALU operations. My goals were:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Capitalise on the quaternion input and remove the conversion to matrix step. On all past games I&amp;rsquo;ve worked on, the matrix multiply with base pose has had a destructive influence on CPU performance; if I could remove this step, I&amp;rsquo;d have a solution that would be faster than my past implementations.&lt;/li&gt;
&lt;li&gt;Reduce the amount of data being mapped/sent to the GPU. While my existing solution was sending 4x4 matrices, one of the columns was redundant - I could be sending 4x3. However, dual quaternions would allow me to halve the amount of data sent.&lt;/li&gt;
&lt;li&gt;Get volume-preserving skinning on joints under extreme rotation.&lt;/li&gt;
&lt;li&gt;Have a bit of fun and exercise some neglected quaternion/vector math muscles.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I skimmed the paper, copied the HLSL source code and tested everything on a basic idle animation. Bad idea, right? But everything seemed to work. I hooked up my mocap pipeline this week and everything went wrong - limbs were folding inside each other and the character was skewing all over the place.&lt;/p&gt;

&lt;p&gt;Searching the internets for equivalent implementations found that most basically copied and pasted from the paper. Some seemed to make an effort to understand what was going on under the hood but all of them produced the same results (oddly, the nVidia shader was the most needlessly complicated and inefficient of them all). So I knuckled down and decided to read the following papers in more detail:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://wscg.zcu.cz/wscg2012/cd-rom/short/A29-full.pdf&#34;&gt;A Beginners Guide to Dual Quaternions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://isg.cs.tcd.ie/projects/DualQuaternions/&#34;&gt;Geometric Skinning with Approximate Dual Quaternion Blending&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The basic method is this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Convert your quaternion rotation and position vector to a dual quaternion on the CPU for each bone.&lt;/li&gt;
&lt;li&gt;In your vertex shader, load all dual quaternion bone transforms for the vertex.&lt;/li&gt;
&lt;li&gt;Create a single dual quaternion that is the weighted average of all the bone transforms.&lt;/li&gt;
&lt;li&gt;Transform the vertex position and normal by this dual quaternion.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;quaternion-vector-multiplication:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Quaternion/Vector Multiplication&lt;/h5&gt;

&lt;p&gt;To cut a long story short, the reason none of this was working for me was that I was looking at Cg code, as opposed to HLSL code. Having never really used Cg, it never occurred to me that the order of cross product parameters should be swapped to account for handedness. Cross products are used to define the quaternion multiplication:&lt;/p&gt;

&lt;p&gt;$$ Q = (w, V) \\ Q_r = Q_0 Q_1  \\ Q_r = (w_0 w_1 - V_0 \cdot V_1, w_0 V_1 + w_1 V_0 + V_0 \times V_1)$$&lt;/p&gt;

&lt;p&gt;&lt;center&gt; ($\cdot$ is the vector dot product and $\times$ is the vector cross product) &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Naturally, this is then a non-commutative operation, giving the order in which you pass arguments into your multiply functions importance, too. A basic C++ implementation of the multiplication looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;math::quat math::qMultiply(const math::quat&amp;amp; a, const math::quat&amp;amp; b)
{
    quat q =
    {
        a.w * b.x + a.x * b.w + a.y * b.z - a.z * b.y,
        a.w * b.y - a.x * b.z + a.y * b.w + a.z * b.x,
        a.w * b.z + a.x * b.y - a.y * b.x + a.z * b.w,
        a.w * b.w - a.x * b.x - a.y * b.y - a.z * b.z,
    };
    return q;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assuming we&amp;rsquo;re using unit quaternions, you can rotate a vector by a quaternion using multiplication:&lt;/p&gt;

&lt;p&gt;$$P_r = Q*(0, P)*Q&amp;rsquo;$$&lt;/p&gt;

&lt;p&gt;Here, $*$ is the quaternion multiplication, $&amp;lsquo;$ is the quaternion conjugate and $(0,P)$ is construction of a pure quaternion using the vector, setting the quaternion real component to zero. This equation is used to convert to and from dual quaternions, so it&amp;rsquo;s important you keep order of multiplications in mind.&lt;/p&gt;

&lt;p&gt;If you work with Cg, make sure you have your cross products round the other way to my shader examples below!&lt;/p&gt;

&lt;h5 id=&#34;converting-to-dual-quaternion:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Converting to Dual Quaternion&lt;/h5&gt;

&lt;p&gt;I&amp;rsquo;d suggest reading the second paper linked above to get a good introduction to what dual quaternions are and what the various components mean. For our means here it&amp;rsquo;s enough to say that dual quaternions are just a pair of quaternions - the &amp;ldquo;real&amp;rdquo; quaternion and the &amp;ldquo;dual&amp;rdquo; quaternion:&lt;/p&gt;

&lt;p&gt;$$DQ = (Q_r, Q_d)$$&lt;/p&gt;

&lt;p&gt;Converting a quaternion rotation and position vector to this representation is simple. The $Q_r$ term is a simple copy of your quaternion rotation and $Q_d$ is:&lt;/p&gt;

&lt;p&gt;$$Q_d = 0.5(0, V)*Q_r$$&lt;/p&gt;

&lt;p&gt;This allows the matrix conversion code on the CPU to become:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Convert position/rotation to dual quaternion
math::dualquat&amp;amp; transform = transforms[i];
transform.r = q;
transform.d = qScale(qMultiplyPure(q, p), 0.5f);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Much nicer! &lt;code&gt;MultiplyPure&lt;/code&gt; is a simple function that does a special case multiply where &lt;code&gt;p.w&lt;/code&gt; is zero.&lt;/p&gt;

&lt;h5 id=&#34;blending-dual-quaternions:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Blending Dual Quaternions&lt;/h5&gt;

&lt;p&gt;Now we can move over to the HLSL side. This is my transform loading code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;Buffer&amp;lt;float4&amp;gt; g_BoneTransforms;

float2x4 GetBoneDualQuat(uint bone_index)
{
    // Load bone rows individually
    float4 row0 = g_BoneTransforms.Load(bone_index * 2 + 0);
    float4 row1 = g_BoneTransforms.Load(bone_index * 2 + 1);
    return float2x4(row0, row1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As mentioned before, we want to load the bones that influence a vertex, weight them and transform the vertex position and normal:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float2x4 BlendBoneTransforms(uint4 bone_indices, float4 bone_weights)
{
    // Fetch bones
    float2x4 dq0 = GetBoneDualQuat(bone_indices.x);
    float2x4 dq1 = GetBoneDualQuat(bone_indices.y);
    float2x4 dq2 = GetBoneDualQuat(bone_indices.z);
    float2x4 dq3 = GetBoneDualQuat(bone_indices.w);

    // ...blend...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As with quaternions, weighting dual quaternions can be achieved using a normalised lerp of its components. As explained in the paper &lt;a href=&#34;http://number-none.com/product/Understanding%20Slerp,%20Then%20Not%20Using%20It/&#34;&gt;Understanding Slerp, Then Not Using It&lt;/a&gt;, it&amp;rsquo;s not as good as a SLERP in that it&amp;rsquo;s not constant velocity. However, it has minimal torque, rotating along the sphere and unlike SLERP, is commutative; meaning, if you combine multiple quaternions in a different order, the result will always be the same.&lt;/p&gt;

&lt;p&gt;Besides, when you&amp;rsquo;re regenerating bone rotations each frame, interpolation velocity won&amp;rsquo;t really factor into the solution. The weighting code thus becomes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Blend
float2x4 result =
    bone_weights.x * dq0 +
    bone_weights.y * dq1 +
    bone_weights.z * dq2 +
    bone_weights.w * dq3;

// Normalise
float norm = length(result[0]);
return result / norm;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Simples! In the original paper, Kavan goes into great detail on why this works so well over previous solutions and why a SLERP isn&amp;rsquo;t the ideal solution. Well worth a read.&lt;/p&gt;

&lt;h5 id=&#34;antipodality-or-quaternion-double-cover:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Antipodality or, Quaternion Double-Cover&lt;/h5&gt;

&lt;p&gt;Take a look at one of the classic release bugs of this generation:&lt;/p&gt;

&lt;p&gt;&lt;center&gt; &lt;iframe width=&#34;420&#34; height=&#34;315&#34; src=&#34;http://www.youtube.com/embed/ToKIkw3LIoQ&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s a pretty awesome reason for why the head can spin the long way around to get to its target rotation (no doubt the bug will be more complicated than that). Casey Muratori goes into &lt;a href=&#34;https://mollyrocket.com/837&#34;&gt;great detail on this&lt;/a&gt; and I&amp;rsquo;ll attempt to summarise.&lt;/p&gt;

&lt;p&gt;The axis-angle definition of a quaternion is:&lt;/p&gt;

&lt;p&gt;$$Q = (cos(\frac{\theta}{2}), Vsin(\frac{\theta}{2}))$$&lt;/p&gt;

&lt;p&gt;Inherent in this definition is the ability for quaternions to represent up to 720 degrees of rotation. Assuming we use the x-axis as our example vector, this leads to these quantities:&lt;/p&gt;

&lt;p&gt;$$Q(0) = (1, 0, 0, 0) \\ Q(360) = (-1, 0, 0, 0) \\ Q(720) = (1, 0, 0, 0)$$&lt;/p&gt;

&lt;p&gt;While sine and cosine are periodic every 360 degrees, the division by two of the input angle leads the quaternion representation to be periodic every 720 degrees.&lt;/p&gt;

&lt;p&gt;Clearly, 360 degrees and 720 degrees represent the same geometrical rotation. However, when you interpolate between rotations, you may find yourself interpolating the long way round. Your source/target rotation range may geometrically be only 30 to 35 degrees but your quaternion may represent that as 30 to 395 degrees!&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;ve glimpsed at the inner workings of a SLERP, this is the case they are trying to avoid when trying to solve for the &amp;ldquo;shortest path&amp;rdquo;. Given that $Q$ and $-Q$ represent the same rotation, you can ensure interpolation between two quaternions follows this shortest path by negating one of the quaternions if the dot product between them is negative.&lt;/p&gt;

&lt;p&gt;When blending dual quaternions, you have to watch for the same case. Not only that, you have to ensure that all of your bone transforms are in the same neighbourhood. While there are &lt;a href=&#34;http://pages.cs.wisc.edu/~joony/RESEARCH/online_locomotion.pdf&#34;&gt;complicated ways of achieving that&lt;/a&gt;, most of the time it can be guaranteed by comparing all bone rotations to the first one and adjusting the sign of the blend weight.&lt;/p&gt;

&lt;p&gt;This leads to the final code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float2x4 BlendBoneTransforms(uint4 bone_indices, float4 bone_weights)
{
    // Fetch bones
    float2x4 dq0 = GetBoneDualQuat(bone_indices.x);
    float2x4 dq1 = GetBoneDualQuat(bone_indices.y);
    float2x4 dq2 = GetBoneDualQuat(bone_indices.z);
    float2x4 dq3 = GetBoneDualQuat(bone_indices.w);

    // Ensure all bone transforms are in the same neighbourhood
    if (dot(dq0[0], dq1[0]) &amp;lt; 0.0) bone_weights.y *= -1.0;
    if (dot(dq0[0], dq2[0]) &amp;lt; 0.0) bone_weights.z *= -1.0;
    if (dot(dq0[0], dq3[0]) &amp;lt; 0.0) bone_weights.w *= -1.0;

    // Blend
    float2x4 result =
        bone_weights.x * dq0 +
        bone_weights.y * dq1 +
        bone_weights.z * dq2 +
        bone_weights.w * dq3;

    // Normalise
    float norm = length(result[0]);
    return result / norm;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are cases which can still fail these checks but they are very rare for the general use-case of skinning - I can&amp;rsquo;t imagine this working well for severe joint twists, for example (beyond the range of human constraints, that is).&lt;/p&gt;

&lt;h5 id=&#34;transforming-the-vertex-with-dual-quaternions:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Transforming the Vertex with Dual Quaternions&lt;/h5&gt;

&lt;p&gt;Once you have the blended result you need to convert it back into quaternion/vector form and transform your vertex. There are two ways of achieving this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Convert straight to matrix and use the matrix to transform the vertex.&lt;/li&gt;
&lt;li&gt;Convert to quaternion/vector and transform the vertex using that.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The fastest and by far cleanest way is the second so I will concentrate on that. Given that you already have the rotation in the $Q_r$ component of the dual quaternion, extraction of the translation vector is achieved using the following:&lt;/p&gt;

&lt;p&gt;$$V = 2Q_d*Q_r&amp;rsquo;$$&lt;/p&gt;

&lt;p&gt;This can be implemented directly as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float4 Conjugate(float4 q)
{
    return float4(-q.x, -q.y, -q.z, q.w);
}

float4 Multiply(float4 a, float4 b)
{
    return float4(a.w * b.xyz + b.w * a.xyz + cross(b.xyz, a.xyz), a.w * b.w - dot(a.xyz, b.xyz));
}

float3 ReconstructTranslation(float4 Qr, float4 Qd)
{
    // The input is the dual quaternion, real part and dual part
    return Multiply(Qd, Conjugate(Qr)).xyz;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Of course, the complete calculation can be collapsed by directly applying the conjugate sign and discarding w:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float3 ReconstructTranslation(float4 Qr, float4 Qd)
{
    return 2 * (Qr.w * Qd.xyz - Qd.w * Qr.xyz + cross(Qd.xyz, Qr.xyz));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using the Conjugate and Multiply functions, it&amp;rsquo;s then easy to transform a position and vector by the quaternion rotation and reconstructed position:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float3 QuatRotateVector(float4 Qr, float3 v)
{
    // Straight-forward application of Q.v.Q&#39;, discarding w
    return Multiply(Multiply(Qr, float4(v, 0)), Conjugate(Qr)).xyz;
}

float3 DualQuatTransformPoint(float4 Qr, float4 Qd, float3 p)
{
    // Reconstruct translation from the dual quaternion
    float3 t = 2 * (Qr.w * Qd.xyz - Qd.w * Qr.xyz + cross(Qd.xyz, Qr.xyz));

    // Combine with rotation of the input point
    return QuatRotateVector(Qr, p) + t;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This leaves you with the final code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float2x4 skin_transform = BlendBoneTransforms(input.bone_indices, input.bone_weights);
float3 pos = DualQuatTransformPoint(skin_transform[0], skin_transform[1], input.pos);
float3 normal = QuatRotateVector(skin_transform[0], input.normal);
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;optimising-the-vertex-transformation:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Optimising the Vertex Transformation&lt;/h5&gt;

&lt;p&gt;There&amp;rsquo;s a bit of redundancy in the transformation code above; results being thrown away and inputs being used when they could be discarded. There are also some identities we can apply to the rotation equation that can simplify it. As it stands, reconstruction of the translation is good enough.&lt;/p&gt;

&lt;p&gt;Starting with &lt;code&gt;QuatRotateVector&lt;/code&gt;, we can already see that the first multiplication uses $w=0$, allowing us to construct a function which removes the necessary terms in its calculation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float4 MultiplyPure(float4 a, float3 b)
{
    return float4(a.w * b + cross(b, a.xyz), -dot(a.xyz, b));
}

float3 QuatRotateVector(float4 Qr, float3 v)
{
    return Multiply(MultiplyPure(Qr, v), Conjugate(Qr)).xyz;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The final redundancy is that we&amp;rsquo;re calculating w and throwing it away, leading to:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float3 MultiplyConjugate3(float4 a, float4 b)
{
    return b.w * a.xyz - a.w * b.xyz - cross(b.xyz, a.xyz);
}
float3 QuatRotateVector(float4 Qr, float3 v)
{
    return MultiplyConjugate3(MultiplyPure(Qr, v), Qr);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Realistically, the shader compiler should be able to handle all that for you. However, it gives us a good starting point to take this further.&lt;/p&gt;

&lt;h5 id=&#34;we-can-do-better-than-that:f775451b420ca7b05862adf0dcf3e408&#34;&gt;We can do better than that&lt;/h5&gt;

&lt;p&gt;Let&amp;rsquo;s try to explode the transformation and bring it back to something far simpler. I&amp;rsquo;ll work through the steps I took in simplifying this explicitly - it serves as a nice record for me and will hopefully help if you&amp;rsquo;re trying to understand where the final result came from (I was always losing signs during my school days - I&amp;rsquo;m no better 15 years on!)&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re trying to simplify:&lt;/p&gt;

&lt;p&gt;$$P_r = Q*(0,V)*Q&amp;rsquo;$$&lt;/p&gt;

&lt;p&gt;This is a sequence of two quaternion multiplies. Again, quaternion multiplication is defined as:&lt;/p&gt;

&lt;p&gt;$$Q_0 Q_1 = (w_0 w_1 - V_0 \cdot V_1, w_0 V_1 + w_1 V_0 + V_0 \times V_1)$$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s make a few quick substitutions:&lt;/p&gt;

&lt;p&gt;$$R = Q.xyz \\ w = Q.w$$&lt;/p&gt;

&lt;p&gt;Expand $Q*(0,V)$ first:&lt;/p&gt;

&lt;p&gt;$$P_r = (-R \cdot V + wV + R \times V)(w - R)$$&lt;/p&gt;

&lt;p&gt;Expand the second multiplication:&lt;/p&gt;

&lt;p&gt;$$P_r = -R \cdot Vw + (wV + R \times V) \cdot R + (R \cdot V)R + w(wV + R \times V) - (wV + R \times V) \times R$$&lt;/p&gt;

&lt;p&gt;The dot product distributes over addition so distribute them all:&lt;/p&gt;

&lt;p&gt;$$P_r = -R \cdot Vw + wV \cdot R + R \times V \cdot R + (R \cdot V)R + + w^2V + wR \times V - (wV + R \times V) \times R$$&lt;/p&gt;

&lt;p&gt;The first two terms cancel as the dot product is commutative:&lt;/p&gt;

&lt;p&gt;$$P_r = R \times V \cdot R + (R \cdot V)R + w^2V + wR \times V - (wV + R \times V) \times R$$&lt;/p&gt;

&lt;p&gt;Using the identity $A \times B=-B \times A$ swap the last cross product around:&lt;/p&gt;

&lt;p&gt;$$P_r = R \times V \cdot R + (R \cdot V)R + w^2V + wR \times V + R \times (wV + R \times V)$$&lt;/p&gt;

&lt;p&gt;The cross product distributes over addition so distribute the last cross product:&lt;/p&gt;

&lt;p&gt;$$P_r = R \times V \cdot R + (R \cdot V)R + w^2V + wR \times V + R \times wV + R \times (R \times V)$$&lt;/p&gt;

&lt;p&gt;As we&amp;rsquo;re only interested in the &lt;code&gt;xyz&lt;/code&gt; components of the result, discard all scalar terms:&lt;/p&gt;

&lt;p&gt;$$P_r = (R \cdot V)R + w^2V + wR \times V + R \times wV + R \times (R \times V)$$&lt;/p&gt;

&lt;p&gt;Pull the scalar out of $R \times wV$ and sum with its neighbour:&lt;/p&gt;

&lt;p&gt;$$P_r = (R \cdot V)R + w^2V + wR \times V + wR \times V + R \times (R \times V)$$
$$P_r = (R \cdot V)R + w^2V + 2wR \times V + R \times (R \times V)$$&lt;/p&gt;

&lt;p&gt;The next bit requires knowledge of the &lt;a href=&#34;http://en.wikipedia.org/wiki/Triple_product#Vector_triple_product&#34;&gt;vector triple product&lt;/a&gt; (or Lagrange&amp;rsquo;s formula - of many). This takes the form:&lt;/p&gt;

&lt;p&gt;$$R \times (R \times V) = (R \cdot V)R - (R \cdot R)V$$&lt;/p&gt;

&lt;p&gt;If we rearrange that to equal zero then we can add that to the end of our existing equation and play around with it a little:&lt;/p&gt;

&lt;p&gt;$$R \times (R \times V) - (R \cdot V)R + (R \cdot R)V = 0$$
$$P_r = (R \cdot V)R + w^2V + 2wR \times V + R \times (R \times V) + R \times (R \times V) - (R \cdot V)R + (R \cdot R)V$$
$$P_r = (R \cdot V)R + w^2V + 2wR \times V + 2R \times (R \times V) - (R \cdot V)R + (R \cdot R)V$$&lt;/p&gt;

&lt;p&gt;The $(R \cdot V)R$ terms cancel:&lt;/p&gt;

&lt;p&gt;$$P_r = w^2V + 2wR \times V + 2R \times (R \times V) + (R \cdot R)V$$&lt;/p&gt;

&lt;p&gt;We can now factor the scale of $V$:&lt;/p&gt;

&lt;p&gt;$$P_r = w^2V  + (R \cdot R)V+ 2wR \times V + 2R \times (R \times V)$$
$$P_r = (w^2  + R \cdot R)V+ 2wR \times V + 2R \times (R \times V)$$&lt;/p&gt;

&lt;p&gt;The quaternion norm operation is given by:&lt;/p&gt;

&lt;p&gt;$$norm(q) = q_w q_w + q_x q_x + q_y q_y + q_z q_z$$&lt;/p&gt;

&lt;p&gt;Assuming we&amp;rsquo;re dealing with unit quaternions, the norm will always be 1. Looking above, we can see the norm right at the beginning and can get rid of it:&lt;/p&gt;

&lt;p&gt;$$P_r = V+ 2wR \times V + 2R \times (R \times V)$$&lt;/p&gt;

&lt;p&gt;Finally, factor the 2:&lt;/p&gt;

&lt;p&gt;$$P_r = V+ 2(wR \times V + R \times (R \times V))$$&lt;/p&gt;

&lt;p&gt;And factor the cross product:&lt;/p&gt;

&lt;p&gt;$$P_r = V+ 2(R \times (wV + R \times V))$$&lt;/p&gt;

&lt;p&gt;This is a delightfully simple result! The HLSL code is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float3 QuatRotateVector(float4 Qr, float3 v)
{
    return v + 2 * cross(Qr.w * v + cross(v, Qr.xyz), Qr.xyz);
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>