<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Gazoo.vrv</title>
    <link>http://donw.io/</link>
    <description>Recent content on Gazoo.vrv</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 23 Oct 2016 19:14:32 +0100</lastBuildDate>
    <atom:link href="http://donw.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Three Methods to Extract Frustum Points</title>
      <link>http://donw.io/post/frustum-point-extraction/</link>
      <pubDate>Sun, 23 Oct 2016 19:14:32 +0100</pubDate>
      
      <guid>http://donw.io/post/frustum-point-extraction/</guid>
      <description>

&lt;p&gt;Getting frustum points in world-space can be useful in a number of scenarios, such as debug visualisation or building a coarse volume around a partition in your frustum. Each method can be used depending what information you have available to you and what you want to avoid recalculating.&lt;/p&gt;

&lt;h5 id=&#34;reverse-projection:fd36dbbb65d24a21fc8a65073d1aa07e&#34;&gt;Reverse Projection&lt;/h5&gt;

&lt;p&gt;If you have access to the world to clip-space matrix you can invert it and transform the clip-space frustum cube back into world-space:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Full 4x4 inverse, can&#39;t use an affine inverse optimisation
float4x4 clip_to_world = inverse(world_to_clip);

// Homogenous points for source cube in clip-space
// With -1 to 1 in x/y and 0 to 1 in z (D3D)
float4 v[8] =
{
    {-1, -1, 0, 1},
    {-1,  1, 0, 1},
    { 1,  1, 0, 1},
    { 1, -1, 0, 1},
    {-1, -1, 1, 1},
    {-1,  1, 1, 1},
    { 1,  1, 1, 1},
    { 1, -1, 1, 1}
};

for (int i = 0; i &amp;lt; 8; i++)
{
    // 4x4 * 4x1 matrix/vector multiplication 
    v[i] = transform(clip_to_world, v[i]);

    // Homogenous to cartesian conversion
    v[i] /= v[i].w;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is an incredibly useful little snippet that can be used at any part of the pipeline without needing to know specifics of the projection.&lt;/p&gt;

&lt;h5 id=&#34;plane-intersection:fd36dbbb65d24a21fc8a65073d1aa07e&#34;&gt;Plane Intersection&lt;/h5&gt;

&lt;p&gt;If you have 6 planes which define the frustum in world-space, 3 planes at a time can be intersected to find each point in the frustum. In the general case, 3 intersecting planes either intersect at a point or a line. Given the 3 planes defined by their normal and distance from origin:&lt;/p&gt;

&lt;p&gt;$$P_0 = \langle N_0, d_0 \rangle$$
$$P_1 = \langle N_1, d_1 \rangle$$
$$P_2 = \langle N_2, d_2 \rangle$$&lt;/p&gt;

&lt;p&gt;Finding the intersection point is a case of solving the linear system:&lt;/p&gt;

&lt;p&gt;$$P_0 \cdot I = 0$$
$$P_1 \cdot I = 0$$
$$P_2 \cdot I = 0$$&lt;/p&gt;

&lt;p&gt;This can be written in matrix form:&lt;/p&gt;

&lt;p&gt;$$\begin{bmatrix} N_0 &amp;amp; N_1 &amp;amp; N_2 \end{bmatrix} \cdot I = \begin{bmatrix} -d_0 \\ -d_1 \\ -d_2 \end{bmatrix}$$&lt;/p&gt;

&lt;p&gt;Which then allows the intersection point to be found with a matrix inverse:&lt;/p&gt;

&lt;p&gt;$$I = \begin{bmatrix} N_0 &amp;amp; N_1 &amp;amp; N_2 \end{bmatrix} ^{-1} \cdot \begin{bmatrix} -d_0 \\ -d_1 \\ -d_2 \end{bmatrix}$$&lt;/p&gt;

&lt;p&gt;In code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;bool IntersectPlanes(float4 P0, float4 P1, float4 P2, out float3 I)
{
    // Form the normal matrix
    float3x3 M;
    M[0][0] = P0.x; M[1][0] = P0.y; M[2][0] = P0.z;
    M[0][1] = P1.x; M[1][1] = P1.y; M[2][1] = P1.z;
    M[0][2] = P2.x; M[1][2] = P2.y; M[2][2] = P2.z;

    // Solve the linear system
    // If M is singular the three planes intersect with a line, not a point
    if (!invert(M))
        return false;

    // Transform the distance vector by the inverse to get the intersection point
    I.x = M[0][0] * -P0.w + M[1][0] * -P1.w + M[2][0] * -P2.w;
    I.y = M[0][1] * -P0.w + M[1][1] * -P1.w + M[2][1] * -P2.w;
    I.z = M[0][2] * -P0.w + M[1][2] * -P1.w + M[2][2] * -P2.w;

    return true;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The frustum points can then be found:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;v[0] = IntersectPlanes(planes[Near], planes[Left],  planes[Bottom]);
v[1] = IntersectPlanes(planes[Near], planes[Left],  planes[Top]);
v[2] = IntersectPlanes(planes[Near], planes[Right], planes[Top]);
v[3] = IntersectPlanes(planes[Near], planes[Right], planes[Bottom]);
v[4] = IntersectPlanes(planes[Far],  planes[Left],  planes[Bottom]);
v[5] = IntersectPlanes(planes[Far],  planes[Left],  planes[Top]);
v[6] = IntersectPlanes(planes[Far],  planes[Right], planes[Top]);
v[7] = IntersectPlanes(planes[Far],  planes[Right], planes[Bottom]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s safe to ignore the singular case of planes intersecting at a line if your frustum is a well defined convex hull. While this is useful if you only have access to the planes, a 3x3 inverse for each point is a bit excessive. It can be improved slightly when not considering degenerate cases:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float3 IntersectPlanes(float4 P0, float4 P1, float4 P2)
{
    float3 bxc = cross(P1.xyz, P2.xyz);
    float3 cxa = cross(P2.xyz, P0.xyz);
    float3 axb = cross(P0.xyz, P1.xyz);
    float3 r = -P0.w * bxc - P1.w * cxa - P2.w * axb;
    return r * (1 / dot(P0.xyz, bxc));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h5 id=&#34;near-far-plane-interpolation:fd36dbbb65d24a21fc8a65073d1aa07e&#34;&gt;Near/Far Plane Interpolation&lt;/h5&gt;

&lt;p&gt;This method is by far the fastest and tailored to a perspective projection. If you have access to the field of view and aspect ratio early in the pipeline, it&amp;rsquo;s also the most accurate. Beyond that, all you need is the camera&amp;rsquo;s world rotation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Pull camera basis
float3 axis_x = camera_to_world[0];
float3 axis_y = camera_to_world[1];
float3 axis_z = camera_to_world[2];

// Near/far plane center points
float3 near_center = axis_z * zn;
float3 far_center = axis_z * zf;

// Get projected viewport extents on near/far planes
float e = tanf(fov_y * 0.5f);
float near_ext_y = e * zn;
float near_ext_x = near_ext_y * aspect_ratio;
float far_ext_y = e * zf;
float far_ext_x = far_ext_y * aspect_ratio;

// Points are just offset from the center points along camera basis
v[0] = near_center - axis_x * near_ext_x - axis_y * near_ext_y;
v[1] = near_center - axis_x * near_ext_x + axis_y * near_ext_y;
v[2] = near_center + axis_x * near_ext_x + axis_y * near_ext_y;
v[3] = near_center + axis_x * near_ext_x - axis_y * near_ext_y;
v[4] = far_center  - axis_x * far_ext_x  - axis_y * far_ext_y;
v[5] = far_center  - axis_x * far_ext_x  + axis_y * far_ext_y;
v[6] = far_center  + axis_x * far_ext_x  + axis_y * far_ext_y;
v[7] = far_center  + axis_x * far_ext_x  - axis_y * far_ext_y;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s always helpful to keep each of these around and pick and choose based on situation. Add the clear case first and use a combination of experience and profiling to determine when stages need to be more tightly bound and generation needs to be optimised.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Convenient Expression for Packed Circle Radius</title>
      <link>http://donw.io/post/packed-circle-radius/</link>
      <pubDate>Sat, 15 Oct 2016 21:45:31 +0100</pubDate>
      
      <guid>http://donw.io/post/packed-circle-radius/</guid>
      <description>&lt;p&gt;When you develop a solver for the Tammes problem you&amp;rsquo;re usually concerned with &lt;a href=&#34;http://paulbourke.net/geometry/circlesphere/#spherepoints&#34;&gt;distributing points evenly on the sphere&lt;/a&gt;, ensuring they are equidistant from each other. The radius of the circles you place at those points is generally not considered:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;http://donw.io/img/CirclePacking/snapshot2.png&#34; alt=&#34;d&#34; /&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;There are known solutions for a &lt;a href=&#34;https://arxiv.org/abs/1509.01768&#34;&gt;given number of circles&lt;/a&gt; but there is no known solution for any number of points. Relaxation can be used in the general case.&lt;/p&gt;

&lt;p&gt;Once the unit sphere is packed with circles, finding the radius can start with two circles and the planes they lie within:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;http://donw.io/img/CirclePacking/planes.png&#34; alt=&#34;d&#34; /&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;If the circle center points $p_0$ and $p_1$ are on the unit sphere, they can also be considered the normals of the planes they lie within. The acute angle $\theta$ between these two planes is called the &lt;em&gt;dihedral angle&lt;/em&gt; and is easily calculated as:&lt;/p&gt;

&lt;p&gt;$$\theta = acos(p_0 \cdot p_1)$$&lt;/p&gt;

&lt;p&gt;The obtuse angle, $\alpha$, is called the &lt;em&gt;anhedral angle&lt;/em&gt; and is thus:&lt;/p&gt;

&lt;p&gt;$$\alpha = \pi - \theta$$&lt;/p&gt;

&lt;p&gt;The adjacent/opposite sides of the triangle formed by the two planes and the line joining $p_0$ and $p_1$ will be the same size and can be considered the desired circle radius:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;http://donw.io/img/CirclePacking/triangle.png&#34; alt=&#34;d&#34; /&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Using the &lt;a href=&#34;http://mathworld.wolfram.com/LawofCosines.html&#34;&gt;Law of Cosines&lt;/a&gt; an expression for $d$ and then $r$, can quickly be attained:&lt;/p&gt;

&lt;p&gt;$$d^2 = r^2 + r^2 - 2r^2cos(\alpha)$$
$$d^2 = 2r^2(1 - cos(\alpha))$$
$$r = \sqrt{\frac{d^2}{2(1 - cos(\alpha))}}$$&lt;/p&gt;

&lt;p&gt;This works well enough to get the radius you want but the overuse of transcendentals feels like it can be squeezed some more. Following the &lt;a href=&#34;http://mathworld.wolfram.com/LawofSines.html&#34;&gt;Law of Sines&lt;/a&gt; makes things even worse but there&amp;rsquo;s a clue in the $cos(\alpha)$ term which expands to:&lt;/p&gt;

&lt;p&gt;$$cos(\pi - \theta)$$&lt;/p&gt;

&lt;p&gt;This can be reduced using a common trigonometric identity:&lt;/p&gt;

&lt;p&gt;$$cos(\pi - \theta) = cos(\pi)cos(\theta) + sin(\pi)sin(\theta)$$&lt;/p&gt;

&lt;p&gt;Given that $cos(\pi)=-1$, $sin(\pi)=0$ and $\theta=acos(p_0 \cdot p_1)$, this immediately reduces to:&lt;/p&gt;

&lt;p&gt;$$cos(\pi - \theta) = -(p_0 \cdot p_1)$$&lt;/p&gt;

&lt;p&gt;Leaving the final substitution:&lt;/p&gt;

&lt;p&gt;$$r = \sqrt{\frac{d^2}{2(p_0 \cdot p_1 + 1)}}$$&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mixed Precision GPU Noise with HLSL</title>
      <link>http://donw.io/post/high-prec-noise-hlsl/</link>
      <pubDate>Thu, 25 Aug 2016 22:05:56 +0100</pubDate>
      
      <guid>http://donw.io/post/high-prec-noise-hlsl/</guid>
      <description>&lt;p&gt;I posted an article a while back, entitled &lt;a href=&#34;http://donw.io/post/high-prec-gradient-noise/&#34;&gt;Very Fast, High-Precision SIMD/GPU Gradient Noise&lt;/a&gt;, where I outlined a technique for achieving double-resolution noise at speeds close to that when using float arithmetic. The key observation was that &lt;code&gt;floor&lt;/code&gt; could be used on cell boundaries to mask off the ranges that require double arithmetic, allowing the bulk of the work to use float arithmetic.&lt;/p&gt;

&lt;p&gt;The GPU code was initially written in OpenCL and then ported to CUDA using &lt;a href=&#34;https://github.com/Celtoys/ComputeBridge&#34;&gt;ComputeBridge&lt;/a&gt;. Neither were good platforms for releasing a game; releasing them on both at the same time was a recipe for madness so I ported everything to HLSL. Unfortunately HLSL SM5 doesn&amp;rsquo;t support &lt;code&gt;floor(double)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;So I sat down and took some time to cook up a software version. The first task was to isolate the fraction:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;double MaskOutFraction(double v)
{
    // Alias double as 2 32-bit integers
    uint d0, d1;
    asuint(v, d0, d1);

    // 0  ... 51   mantissa     0  ... 19
    // 52 ... 62   exponent     20 ... 30
    // 63 ... 63   sign

    // Already a fraction?
    int exponent = ((d1 &amp;gt;&amp;gt; 20) &amp;amp; 0x7FF) - 1023;
    if (exponent &amp;lt; 0)
        return 0;

    // Calculate how many bits to shift to remove the fraction
    // As there is no check here for mask_bits &amp;lt;= 0, if the input double is large enough
    // such that it can&#39;t have any fractional representation, thie function will return
    // an incorrect result.
    // As this is the GPU, I&#39;ve decided against that branch.
    int mask_bits = max(52 - exponent, 0);

    // Calculate low 31-bits of the inverted mantissa mask
    uint lo_shift_bits = min(mask_bits, 31);
    uint lo_mask = (1 &amp;lt;&amp;lt; lo_shift_bits) - 1;

    // Can&#39;t do (1&amp;lt;&amp;lt;32)-1 with 32-bit integer so OR in the final bit if need be
    lo_mask |= mask_bits &amp;gt; 31 ? 0x80000000 : 0;

    // Calculate high 20 bits of the inverted mantissa mask
    uint hi_shift_bits = max(mask_bits - 32, 0);
    uint hi_mask = (1 &amp;lt;&amp;lt; hi_shift_bits) - 1;

    // Mask out the fractional bits and recombine as a double
    d0 &amp;amp;= ~lo_mask;
    d1 &amp;amp;= ~hi_mask;
    v = asdouble(d0, d1);

    return v;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With that you can then subtract the fraction and provide necessary overloads:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// HLSL(SM5) doesn&#39;t support floor(double) so implement it in software
double Floor(double v)
{
    double r = MaskOutFraction(v);
    return v - r &amp;lt; 0 ? r - 1 : r;
}
double2 Floor(double2 v)
{
    v.x = Floor(v.x);
    v.y = Floor(v.y);
    return v;
}
double3 Floor(double3 v)
{
    v.x = Floor(v.x);
    v.y = Floor(v.y);
    v.z = Floor(v.z);
    return v;
}
double4 Floor(double4 v)
{
    v.x = Floor(v.x);
    v.y = Floor(v.y);
    v.z = Floor(v.z);
    v.w = Floor(v.w);
    return v;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Performance is admirably close to the CUDA/OpenCL versions (on nVidia/AMD hardware, respectively) and the same mask function can be reused for &lt;code&gt;Round&lt;/code&gt; or &lt;code&gt;Ceil&lt;/code&gt; functions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A New Host, Server and Site Generator</title>
      <link>http://donw.io/post/a-new-host-server-site/</link>
      <pubDate>Sun, 19 Jun 2016 21:48:11 +0100</pubDate>
      
      <guid>http://donw.io/post/a-new-host-server-site/</guid>
      <description>&lt;p&gt;And we are back! It must be a year now since my old site &lt;code&gt;donw.org&lt;/code&gt; went dark for many reasons, including being busy working on my own game. There&amp;rsquo;s some big changes with this new setup:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I own the domain &lt;a href=&#34;donw.io&#34;&gt;donw.io&lt;/a&gt; this time round. I&amp;rsquo;ve gone through a bunch of domains &amp;ndash; &lt;code&gt;donw.org&lt;/code&gt;, &lt;code&gt;donw.co.uk&lt;/code&gt;, etc. &amp;ndash; that I used to pay somebody else to manage for me. That was obviously not the right way of going about this as I no longer own them.&lt;/li&gt;
&lt;li&gt;My old websites were on servers hosted by an old work colleague who was very difficult to contact. I&amp;rsquo;m now running a shared hosting plan at &lt;a href=&#34;https://www.digitalocean.com/&#34;&gt;Digital Ocean&lt;/a&gt; and really enjoy maintaining all the software on that. Digital Ocean&amp;rsquo;s setup is really great, they&amp;rsquo;ve got a good community and are reasonably priced.&lt;/li&gt;
&lt;li&gt;Rather than writing my own blog software &lt;a href=&#34;https://github.com/dwilliamson/b&#34;&gt;like I did previously&lt;/a&gt;, I&amp;rsquo;ve switched to the static website generator &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;. It&amp;rsquo;s some seriously awesome software and updating the site no longer feels like a chore.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This all means that I am now in complete control and the site will never go dark again.&lt;/p&gt;

&lt;p&gt;I plan to kick-off by bringing back a lot of my older posts that were popular. I used my own Markdown-style engine previously so will have to port all the text over, but that will give me a chance to proof-read and update links.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s get this party started!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Distant Spherical Area Light Sources</title>
      <link>http://donw.io/post/distant-sphere-lights/</link>
      <pubDate>Wed, 11 Feb 2015 12:58:23 +0100</pubDate>
      
      <guid>http://donw.io/post/distant-sphere-lights/</guid>
      <description>&lt;p&gt;This is a small test post exercising math notation with &lt;a href=&#34;http://www.mathjax.org/&#34;&gt;MathJax&lt;/a&gt; in &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Epic use the following equation for a spherical light source  [&lt;a href=&#34;http://blog.selfshadow.com/publications/s2013-shading-course/&#34; title=&#34;Real Shading in Unreal Engine 4&#34;&gt;1&lt;/a&gt;]:&lt;/p&gt;

&lt;p&gt;$$\mathbf{C} = (\mathbf{L} \cdot \mathbf{r})\mathbf{r} - \mathbf{L}$$
$$\mathbf{P} = \mathbf{L} + \langle \frac{sourceRadius}{ &amp;verbar; \mathbf{C} &amp;verbar; } \rangle \mathbf{C}$$&lt;/p&gt;

&lt;p&gt;where the point with the smallest distance to the reflected ray is then $&amp;par;\mathbf{P}&amp;par;$.&lt;/p&gt;

&lt;p&gt;Implicit in this equation is that $\mathbf{L}$ is unnormalised. With a Sun/Earth distance of 149,600,000km and Sun radius of 695,800km these calculations are not really going to work in limited precision shaders. To get around this we need to separate the length of $\mathbf{L}$ from its direction and hope that the large value terms fall out at the end. Using this substitution:&lt;/p&gt;

&lt;p&gt;$$d\mathbf{l} = \mathbf{L}$$&lt;/p&gt;

&lt;p&gt;we start with:&lt;/p&gt;

&lt;p&gt;$$\mathbf{C} = (d\mathbf{l} \cdot \mathbf{r})\mathbf{r} - d\mathbf{l}$$&lt;/p&gt;

&lt;p&gt;As the dot product is homogeneous under scaling we can pull $d$ out and factor it:&lt;/p&gt;

&lt;p&gt;$$\mathbf{C} = d((\mathbf{l} \cdot \mathbf{r})\mathbf{r} - \mathbf{l})$$&lt;/p&gt;

&lt;p&gt;leaving $\mathbf{P}$ at:&lt;/p&gt;

&lt;p&gt;$$\mathbf{P} = d\mathbf{l} + \langle \frac{sourceRadius}{ sqrt(\mathbf{C} \cdot \mathbf{C}) } \rangle \mathbf{C}$$&lt;/p&gt;

&lt;p&gt;Things become a little easier if we make the simple substitution:&lt;/p&gt;

&lt;p&gt;$$\mathbf{D} = (\mathbf{l} \cdot \mathbf{r})\mathbf{r} - \mathbf{l}$$
$$\mathbf{C} = d\mathbf{D}$$&lt;/p&gt;

&lt;p&gt;After a little reduction, $\mathbf{P}$ simplifies to:&lt;/p&gt;

&lt;p&gt;$$\mathbf{P} = d\mathbf{l} + \langle \frac{sourceRadius}{d} \frac{1}{sqrt(\mathbf{D} \cdot \mathbf{D})} \rangle d\mathbf{D}$$&lt;/p&gt;

&lt;p&gt;This allows two things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The $\frac{sourceRadius}{d}$ term can be precalculated outside the shader at whatever precision you like. As long as the result is float-representable then you&amp;rsquo;re good to go. As an example, the Sun/Earth ratio is roughly 0.00465.&lt;/li&gt;
&lt;li&gt;The remaining $d$ scalar can be factored and ignored as we&amp;rsquo;re only interested in the direction of $\mathbf{P}$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The shader code is just as simple:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float3 r = reflect(surface_to_camera, normal);
float3 D = dot(l, r) * r - l;
float3 P = l + D * saturate(radius_over_distance * rsqrt(dot(D, D)));
float3 specular_l = normalize(P);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is a little simpler than the area disk light presented in [&lt;a href=&#34;http://www.frostbite.com/2014/11/moving-frostbite-to-pbr/&#34; title=&#34;Moving Frostbite to PBR&#34;&gt;2&lt;/a&gt;] and allows you to use Epic&amp;rsquo;s energy normalisation constant.&lt;/p&gt;

&lt;p&gt;References:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.selfshadow.com/publications/s2013-shading-course/&#34; title=&#34;Real Shading in Unreal Engine 4&#34;&gt;Real Shading in Unreal Engine 4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.frostbite.com/2014/11/moving-frostbite-to-pbr/&#34; title=&#34;Moving Frostbite to PBR&#34;&gt;Moving Frostbite to PBR&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Very Fast, High-Precision SIMD/GPU Gradient Noise</title>
      <link>http://donw.io/post/high-prec-gradient-noise/</link>
      <pubDate>Mon, 17 Dec 2012 11:38:22 +0100</pubDate>
      
      <guid>http://donw.io/post/high-prec-gradient-noise/</guid>
      <description>

&lt;p&gt;A recently published article by Inigo Quilez on &lt;a href=&#34;http://www.iquilezles.org/www/articles/voronoilines/voronoilines.htm&#34;&gt;Voronoi Edges&lt;/a&gt; highlights the technique of shifting the co-ordinate frame of procedural algorithms to improve precision. This is a really important little trick that I felt was worth reviewing, as it provides huge benefits to world generation at a planetary scale.&lt;/p&gt;

&lt;p&gt;The GPGPU crowd have used similar techniques for a while, dubbed &lt;a href=&#34;http://www.mpi-inf.mpg.de/~strzodka/projects/double/&#34;&gt;Mixed Precision Methods&lt;/a&gt; and the first reference I can find to using relative values for &amp;ldquo;Infinite noise&amp;rdquo; is in Pixar&amp;rsquo;s paper on &lt;a href=&#34;http://graphics.pixar.com/library/WaveletNoise/paper.pdf&#34;&gt;Wavelet Noise&lt;/a&gt;.&lt;/p&gt;

&lt;h5 id=&#34;perlin-s-gradient-noise:e6e69b71ef866b6d53d10ae9b1d8d2cb&#34;&gt;Perlin&amp;rsquo;s Gradient Noise&lt;/h5&gt;

&lt;p&gt;One of the simplest noise implementations involves taking &amp;ldquo;random&amp;rdquo; gradient vectors from points on a lattice nearest your sampling point and interpolating them. I say &amp;ldquo;random&amp;rdquo; because while the result effectively looks random, it&amp;rsquo;s more a hashing process with no state:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// A series of primes for the hash function
const int NOISE_HASH_X = 1213;
const int NOISE_HASH_Y = 6203;
const int NOISE_HASH_Z = 5237;
const int NOISE_HASH_SEED = 1039;
const int NOISE_HASH_SHIFT = 13;

float lerp(float t, float a, float b)
{
    return a + t * (b - a);
}

float quintic(float t)
{
    return t * t * t * (t * (t * 6.0f - 15.0f) + 10.0f);
}

float grad_project(float dx, float dy, float dz, int ix, int iy, int iz)
{
    // Hash the lattice indices to get a gradient vector index
    int index = NOISE_HASH_X * ix + NOISE_HASH_Y * iy + NOISE_HASH_Z * iz + NOISE_HASH_SEED;
    index ^= (index &amp;gt;&amp;gt; NOISE_HASH_SHIFT);
    index &amp;amp;= 0xFF;

    // Lookup the gradient vector
    float grad_x = g_RandomGradients[(index &amp;lt;&amp;lt; 2) + 0];
    float grad_y = g_RandomGradients[(index &amp;lt;&amp;lt; 2) + 1];
    float grad_z = g_RandomGradients[(index &amp;lt;&amp;lt; 2) + 2];

    // Project the local point onto the gradient vector
    return (grad_x * dx + grad_y * dy + grad_z * dz);
}

float grad_noise(float x, float y, float z)
{
    // Get the nearest lattice indices
    int x0 = (int)floor(x);
    int y0 = (int)floor(y);
    int z0 = (int)floor(z);
    int x1 = x0 + 1;
    int y1 = y0 + 1;
    int z1 = z0 + 1;

    // Get local deltas to lattice positions
    float dx0 = x - x0;
    float dy0 = y - y0;
    float dz0 = z - z0;
    float dx1 = dx0 - 1.0f;
    float dy1 = dy0 - 1.0f;
    float dz1 = dz0 - 1.0f;

    // Get gradient projection for each local lattice point
    float g0 = grad_project(dx0, dy0, dz0, x0, y0, z0);
    float g1 = grad_project(dx1, dy0, dz0, x1, y0, z0);
    float g2 = grad_project(dx0, dy1, dz0, x0, y1, z0);
    float g3 = grad_project(dx1, dy1, dz0, x1, y1, z0);
    float g4 = grad_project(dx0, dy0, dz1, x0, y0, z1);
    float g5 = grad_project(dx1, dy0, dz1, x1, y0, z1);
    float g6 = grad_project(dx0, dy1, dz1, x0, y1, z1);
    float g7 = grad_project(dx1, dy1, dz1, x1, y1, z1);

    // Remap linear interpolation to a quintic (see Perlin&#39;s Improved Noise paper)
    float rx = quintic(dx0);
    float ry = quintic(dy0);
    float rz = quintic(dz0);

    // Trilinear interpolation
    float gx0 = lerp(rx, g0, g1);
    float gx1 = lerp(rx, g2, g3);
    float gx2 = lerp(rx, g4, g5);
    float gx3 = lerp(rx, g6, g7);
    float gy0 = lerp(ry, gx0, gx1);
    float gy1 = lerp(ry, gx2, gx3);
    return lerp(rz, gy0, gy1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;g_Gradients&lt;/code&gt; is a table of randomly generated unit vectors. While my table size is 256, Perlin notes that the number of gradient vectors isn&amp;rsquo;t really that important - just that they&amp;rsquo;re &lt;a href=&#34;http://http.developer.nvidia.com/GPUGems/gpugems_ch05.html&#34;&gt;evenly distributed&lt;/a&gt;. He suggests a relaxation step to achieve Poisson distribution, which I might try, but for now I&amp;rsquo;m just using a &lt;a href=&#34;https://bitbucket.org/dwilliamson/shrotation/src/tip/Source/NRook.cpp&#34;&gt;stratified sampling of the sphere&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In the majority of cases this all works well. There are many variants, each tailored to different use-cases, for example:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If you are doing very small-scale noisy details you might be able to get away with one gradient vector look-up, using the GPU&amp;rsquo;s volume texture sampling to do the &lt;a href=&#34;http://prettyprocs.wordpress.com/2012/10/20/fast-perlin-noise/&#34;&gt;interpolation and index wrapping for you&lt;/a&gt;. This isn&amp;rsquo;t a great technique for variance, however it&amp;rsquo;s useful for the small details when you have lower frequencies available to hide the repetition.&lt;/li&gt;
&lt;li&gt;When table/texture lookups are not possible or too slow and when branching is expensive, you can switch to Ashima Arts&amp;rsquo; &lt;a href=&#34;https://github.com/ashima/webgl-noise&#34;&gt;Simplex Noise&lt;/a&gt; variant. Or you can use Simplex Noise as popularised by Perlin and brilliantly documented by &lt;a href=&#34;http://staffwww.itn.liu.se/~stegu/simplexnoise/&#34;&gt;Stefan Gustavson&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;rsquo;ve not found Simplex noise to give any real gains in terms of visuals and performance. Either the branches become a problem or the increased ALU to avoid branches steps in. As I want 100x gains here, not minor &amp;ldquo;potential&amp;rdquo; gains, it&amp;rsquo;s not been worth the complexity increase for me.&lt;/p&gt;

&lt;h5 id=&#34;single-precision-motivation:e6e69b71ef866b6d53d10ae9b1d8d2cb&#34;&gt;Single Precision Motivation&lt;/h5&gt;

&lt;p&gt;When you start applying the noise functions on a large scale, single-precision noise breaks down entirely. The easiest way to fix this is by changing all float values in the above source to double. Depending on your use case, this can be quite a sensible solution and it&amp;rsquo;s very easy to find noise examples out there where people brush over the problem entirely and switch to doubles.&lt;/p&gt;

&lt;p&gt;On modern PCs (last 8 years or so), the equivalent of the x87 co-processor has been doing floating point arithmetic at 64-bit precision. When you write floating point code on PC, you should be using doubles, as the overhead of marshalling back and forth between float/double precision can make your code slower.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s what I did, but eventually I wanted bigger and faster. Not just three or four times faster: one hundred times faster! For that you need to start exploiting AVX/SSE or your GPU, but double life in these lands is not as rosy. I have a few numbers that can demonstrate this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;25,596,000&lt;/strong&gt; : C Gradient Noise double&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;29,987,000&lt;/strong&gt; : C Gradient Noise float&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;13,709,000&lt;/strong&gt; : SSE Gradient Noise double&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;11,613,000&lt;/strong&gt; : SSE Gradient Noise float&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Timings are in nano-seconds. The first two results quite evidently demonstrate the benefit of working in double space to begin with. The last two results show how useful switching to SSE techniques can be but also show that doubles (implemented using recent AVX instructions) don&amp;rsquo;t perform as well. However, when you compare these with GPU numbers, it becomes evident how fast we can really make things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;875,072&lt;/strong&gt; : OpenCL Gradient Noise double&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;126,016&lt;/strong&gt; : OpenCL Gradient Noise float&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The double version is around 30 times faster than the original implementation, however the real fruit from the tree is the float version at roughly 200 times faster! If we can find a way to make the float version work on a large scale, this could be very good. Of course, the economics of GPU use doesn&amp;rsquo;t really net you those gains: the GPU version needs to be that fast because there are potentially several free CPU cores hanging around that could do the work in 10ms, 3 times a frame. The GPU version doesn&amp;rsquo;t have that flexibility as it needs a good 30ms to render a frame.&lt;/p&gt;

&lt;p&gt;Branchless Simplex noise is worth a quick mention here:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;3,238,144&lt;/strong&gt; : OpenCL Simplex Noise double&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;283,072&lt;/strong&gt; : OpenCL Simplex Noise float&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This demonstrates a couple of things: the lack of real double performance on GPUs and the greatly increased ALU under-performing table lookups vs. the gradient version.&lt;/p&gt;

&lt;h5 id=&#34;making-single-precision-scale:e6e69b71ef866b6d53d10ae9b1d8d2cb&#34;&gt;Making Single Precision Scale&lt;/h5&gt;

&lt;p&gt;The above noise function is already in a format ready for improvement. The first step is to accept doubles as parameters:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float grad_noise(double x, double y, double z)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the source position that gets scaled based on what octave it comes from. There are cases, for extremely low frequency noise, where you can get away with floats. In my planet generator (earth sized planets and larger), my first couple of octaves are entirely float-based.&lt;/p&gt;

&lt;p&gt;This also means the conversion to integer needs to be done in double-precision:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Get the nearest lattice indices
int x0 = (int)floor(x);
int y0 = (int)floor(y);
int z0 = (int)floor(z);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assuming you have a planet that is earth-sized, most detail will be generated at a distance of ~6,000,000 metres from the origin. Up there, the resolution of a float goes rapidly &lt;a href=&#34;http://www.altdevblogaday.com/2012/02/05/dont-store-that-in-a-float/&#34;&gt;from 0.0625 metres to 1 metre&lt;/a&gt;. While the rounding won&amp;rsquo;t show its effect until you get above 10,000km, there&amp;rsquo;s really no point in trying to marshal the position into a float and I&amp;rsquo;d rather not have to worry about changing the function for larger planet radii.&lt;/p&gt;

&lt;p&gt;This resolution becomes extremely important in the next bit of code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Get local deltas to lattice positions
double dx0 = x - x0;
double dy0 = y - y0;
double dz0 = z - z0;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If this delta is calculated with floats at this height, you will get multiples of 0.0625 or higher. This produces stair-stepping artifacts every few centimetres and a complete loss of detail that looks quite horrendous. However, if you calculate the delta using doubles and convert the 0-1 value to float, it&amp;rsquo;s all fine:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Get local deltas to lattice positions
float dx0 = float(x - x0);
float dy0 = float(y - y0);
float dz0 = float(z - z0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The rest of the code does not need to touch a double value, ever; the distance to the far lattice indices has already been adjusted so that it&amp;rsquo;s not in terms of the incoming position.&lt;/p&gt;

&lt;h5 id=&#34;a-simd-implementation:e6e69b71ef866b6d53d10ae9b1d8d2cb&#34;&gt;A SIMD Implementation&lt;/h5&gt;

&lt;p&gt;There are two ways to write a complete double SIMD implementation. The first is to use the &lt;a href=&#34;http://softpixel.com/~cwright/programming/simd/sse2.php&#34;&gt;SSE2&lt;/a&gt; instructions, storing 3x double values in two 128-bit registers. This is quite painful and the resulting code has significantly less through-put than its float equivalent. I didn&amp;rsquo;t get a chance to correctly profile my implementation but initial investigations proved there was little benefit, especially for the large increase in complexity.&lt;/p&gt;

&lt;p&gt;The second way is to use the more recent &lt;a href=&#34;http://software.intel.com/en-us/avx&#34;&gt;AVX instructions&lt;/a&gt;. These have a new, extended 256-bit register set, representing a step forward for Intel that&amp;rsquo;s not without its problems:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Mixing 128-bit SSE and 256-bit AVX code is very easy to do and can cause significant performance penalties. The problem and some solutions are discussed in &lt;a href=&#34;http://software.intel.com/en-us/articles/avoiding-avx-sse-transition-penalties&#34;&gt;Avoiding AVX-SSE Transition Penalties&lt;/a&gt; and &lt;a href=&#34;http://software.intel.com/en-us/articles/intel-avx-state-transitions-migrating-sse-code-to-avx&#34;&gt;Intel AVX State Transitions: Migrating SSE Code to AVX&lt;/a&gt;. I used C intrinsics to write SIMD code so I was having to parse the generated assembler from MSVC on each run to double-check me or the compiler weren&amp;rsquo;t making mistakes. Intel&amp;rsquo;s solution of running your code through an emulator to check sounds just a little too much.&lt;/li&gt;
&lt;li&gt;There is an horrendous Windows 7 WoW64 bug better explained in the post &lt;a href=&#34;http://www.os2museum.com/wp/?p=960&#34;&gt;AVX support disrupts WoW64 debugging&lt;/a&gt;. The short version is that, for 32-bit programs, AVX state is incorrectly managed during stack walks leading to incorrect call stacks whenever you attach a debugger to a crashed application. A fix is to either run with the debugger attached at all times and have &lt;a href=&#34;http://www.altdevblogaday.com/2012/07/06/when-even-crashing-doesnt-work/&#34;&gt;Win32 Exceptions Enabled&lt;/a&gt; or to disable AVX support in Windows 7 altogether! Not exactly great choices, there.&lt;/li&gt;
&lt;li&gt;32-bit programs have access to only half the registers the equivalent 64-bit programs do. While not really that important for the future, it&amp;rsquo;s a pain when you&amp;rsquo;re trying a slow migration to 64-bit.&lt;/li&gt;
&lt;li&gt;AVX is recent enough that you may still need to write an SSE implementation to make up for lack of support on older machines.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Given that we now have a way of using doubles in only a small portion of the code, there&amp;rsquo;s pretty much no reason to need an AVX version. Which is good!&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s an SSE version:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;namespace simd
{
    typedef __m128i v128i;
    typedef __m128d v128d;
    typedef __m128 v128f;
}

simd::v128f __fastcall grad_noise_simd(simd::v128d pos_xy, simd::v128d pos_z)
{
    using namespace simd;

    // Round to the lowest integer boundary
    // DOUBLE PRECISION
    v128d pos_xy_0 = _mm_floor_pd(pos_xy);
    v128d pos_z_0 = _mm_floor_pd(pos_z);

    // Convert to integer to get the lower cube corner
    v128i xyi = _mm_cvtpd_epi32(pos_xy_0);
    v128i zi = _mm_cvtpd_epi32(pos_z_0);
    zi = shuffle_epi32&amp;lt;Az, Aw, Ax, Ay&amp;gt;(zi);
    v128i cube_pos0 = _mm_add_epi32(xyi, zi);

    // Add one to get the upper cube corner
    v128i cube_pos1 = _mm_add_epi32(cube_pos0, iONE);

    // Get fractional to lower cube corner
    // DOUBLE PRECISION
    v128d t_xy_d = _mm_sub_pd(pos_xy, pos_xy_0);
    v128d t_z_d = _mm_sub_pd(pos_z, pos_z_0);

    // Convert to higher-throughput float
    v128f t_xy_f = _mm_cvtpd_ps(t_xy_d);
    v128f t_zw_f = _mm_cvtpd_ps(t_z_d);
    v128f t0 = shuffle_ps&amp;lt;Ax, Ay, Bx, By&amp;gt;(t_xy_f, t_zw_f);

    // Get fractional to upper cube corner
    v128f t1 = _mm_sub_ps(t0, fONE);

    int x0 = cube_pos0.m128i_i32[0];
    int y0 = cube_pos0.m128i_i32[1];
    int z0 = cube_pos0.m128i_i32[2];

    int x1 = cube_pos1.m128i_i32[0];
    int y1 = cube_pos1.m128i_i32[1];
    int z1 = cube_pos1.m128i_i32[2];

    // Partial hash of extreme cube corner indices
    int ox0 = NOISE_X * x0 + NOISE_SEED;
    int oy0 = NOISE_Y * y0;
    int oz0 = NOISE_Z * z0;
    int ox1 = NOISE_X * x1 + NOISE_SEED;
    int oy1 = NOISE_Y * y1;
    int oz1 = NOISE_Z * z1;

    // Hash all cube corners
    int index0 = ox0 + oy0 + oz0;
    int index1 = ox1 + oy0 + oz0;
    int index2 = ox0 + oy1 + oz0;
    int index3 = ox1 + oy1 + oz0;
    int index4 = ox0 + oy0 + oz1;
    int index5 = ox1 + oy0 + oz1;
    int index6 = ox0 + oy1 + oz1;
    int index7 = ox1 + oy1 + oz1;
    index0 ^= (index0 &amp;gt;&amp;gt; NOISE_SHIFT);
    index1 ^= (index1 &amp;gt;&amp;gt; NOISE_SHIFT);
    index2 ^= (index2 &amp;gt;&amp;gt; NOISE_SHIFT);
    index3 ^= (index3 &amp;gt;&amp;gt; NOISE_SHIFT);
    index4 ^= (index4 &amp;gt;&amp;gt; NOISE_SHIFT);
    index5 ^= (index5 &amp;gt;&amp;gt; NOISE_SHIFT);
    index6 ^= (index6 &amp;gt;&amp;gt; NOISE_SHIFT);
    index7 ^= (index7 &amp;gt;&amp;gt; NOISE_SHIFT);
    index0 &amp;amp;= 0xFF;
    index1 &amp;amp;= 0xFF;
    index2 &amp;amp;= 0xFF;
    index3 &amp;amp;= 0xFF;
    index4 &amp;amp;= 0xFF;
    index5 &amp;amp;= 0xFF;
    index6 &amp;amp;= 0xFF;
    index7 &amp;amp;= 0xFF;

    // Lookup gradients
    v128f grad0 = g_RandomGradients_v128f[index0];
    v128f grad1 = g_RandomGradients_v128f[index1];
    v128f grad2 = g_RandomGradients_v128f[index2];
    v128f grad3 = g_RandomGradients_v128f[index3];
    v128f grad4 = g_RandomGradients_v128f[index4];
    v128f grad5 = g_RandomGradients_v128f[index5];
    v128f grad6 = g_RandomGradients_v128f[index6];
    v128f grad7 = g_RandomGradients_v128f[index7];

    // Project permuted offsets onto gradient vector
    v128f g0_ = _mm_dp_ps(grad0, blend_ps&amp;lt;Ax, Ay, Az&amp;gt;(t0, t1), 0x7F);
    v128f g1_ = _mm_dp_ps(grad1, blend_ps&amp;lt;Bx, Ay, Az&amp;gt;(t0, t1), 0x7F);
    v128f g2_ = _mm_dp_ps(grad2, blend_ps&amp;lt;Ax, By, Az&amp;gt;(t0, t1), 0x7F);
    v128f g3_ = _mm_dp_ps(grad3, blend_ps&amp;lt;Bx, By, Az&amp;gt;(t0, t1), 0x7F);
    v128f g4_ = _mm_dp_ps(grad4, blend_ps&amp;lt;Ax, Ay, Bz&amp;gt;(t0, t1), 0x7F);
    v128f g5_ = _mm_dp_ps(grad5, blend_ps&amp;lt;Bx, Ay, Bz&amp;gt;(t0, t1), 0x7F);
    v128f g6_ = _mm_dp_ps(grad6, blend_ps&amp;lt;Ax, By, Bz&amp;gt;(t0, t1), 0x7F);
    v128f g7_ = _mm_dp_ps(grad7, blend_ps&amp;lt;Bx, By, Bz&amp;gt;(t0, t1), 0x7F);

    // mix g0, g2, g4, g6 for lerp
    v128f g02__ = blend_ps&amp;lt;Ax, By, Az, Aw&amp;gt;(g0_, g2_);
    v128f g__46 = blend_ps&amp;lt;Ax, Ay, Az, Bw&amp;gt;(g4_, g6_);
    v128f g0246 = blend_ps&amp;lt;Ax, Ay, Bz, Bw&amp;gt;(g02__, g__46);

    // mix g1, g3, g5, g7 for lerp
    v128f g13__ = blend_ps&amp;lt;Ax, By, Az, Aw&amp;gt;(g1_, g3_);
    v128f g__57 = blend_ps&amp;lt;Ax, Ay, Az, Bw&amp;gt;(g5_, g7_);
    v128f g1357 = blend_ps&amp;lt;Ax, Ay, Bz, Bw&amp;gt;(g13__, g__57);

    // Apply a cubic fade to the near distance parameter for trilinear interpolation
    v128f r = _mm_mul_ps(t0, t0);
    v128f r0 = _mm_mul_ps(fTWO, t0);
    r0 = _mm_sub_ps(fTHREE, r0);
    r = _mm_mul_ps(r, r0);

    // Trilinear interpolation 
    v128f rx = shuffle_ps&amp;lt;Ax, Ax, Bx, Bx&amp;gt;(r, r);
    v128f gx0123 = simd::lerp(rx, g0246, g1357);

    v128f ry = shuffle_ps&amp;lt;Ay, Ay, By, By&amp;gt;(r, r);
    v128f gx1032 = shuffle_ps&amp;lt;Ay, Ax, Bw, Bz&amp;gt;(gx0123, gx0123);

    v128f gy0_1_ = simd::lerp(ry, gx0123, gx1032);
    v128f rz = shuffle_ps&amp;lt;Az, Az, Bz, Bz&amp;gt;(r, r);
    v128f gy1_0_ = shuffle_ps&amp;lt;Az, Az, Bx, Bx&amp;gt;(gy0_1_, gy0_1_);
    v128f gz = simd::lerp(rz, gy0_1_, gy1_0_);

    return gz;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is a bunch of stuff you could do to get a couple milliseconds out of this but it&amp;rsquo;s already over twice as fast as the C version, so it&amp;rsquo;s a good enough SIMD version for now. The compiler will effectively pipeline the int operations with the SSE operations for you and on modern processors the dot product is actually quite fast. You could tranpose the inner loop for older processors to remove the dot product:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Transpose first 4 gradients within XMM registers
v128f temp0 = _mm_unpacklo_ps(grad0, grad2);
v128f temp1 = _mm_unpacklo_ps(grad4, grad6);
v128f temp2 = _mm_unpackhi_ps(grad0, grad2);
v128f temp3 = _mm_unpackhi_ps(grad4, grad6);
v128f grad0246x = _mm_movelh_ps(temp0, temp1);
v128f grad0246y = _mm_movehl_ps(temp1, temp0);
v128f grad0246z = _mm_movelh_ps(temp2, temp3);

// Transpose second 4 gradients within XMM registers
temp0 = _mm_unpacklo_ps(grad1, grad3);
temp1 = _mm_unpacklo_ps(grad5, grad7);
temp2 = _mm_unpackhi_ps(grad1, grad3);
temp3 = _mm_unpackhi_ps(grad5, grad7);
v128f grad1357x = _mm_movelh_ps(temp0, temp1);
v128f grad1357y = _mm_movehl_ps(temp1, temp0);
v128f grad1357z = _mm_movelh_ps(temp2, temp3);

// Tranpose needed permutations
v128f t0000x = shuffle_ps&amp;lt;Ax, Ax, Bx, Bx&amp;gt;(t0, t0);
v128f t0000y = shuffle_ps&amp;lt;Ay, Ay, By, By&amp;gt;(t0, t0);
v128f t0000z = shuffle_ps&amp;lt;Az, Az, Bz, Bz&amp;gt;(t0, t0);
v128f t1111x = shuffle_ps&amp;lt;Ax, Ax, Bx, Bx&amp;gt;(t1, t1);
v128f t1111y = shuffle_ps&amp;lt;Ay, Ay, By, By&amp;gt;(t1, t1);
v128f t1111z = shuffle_ps&amp;lt;Az, Az, Bz, Bz&amp;gt;(t1, t1);
v128f t0101y = blend_ps&amp;lt;Ax, By, Az, Bw&amp;gt;(t0000y, t1111y);
v128f t0011z = blend_ps&amp;lt;Ax, Ay, Bz, Bw&amp;gt;(t0000z, t1111z);

// Calculate 8 dot products
v128f mulx = _mm_mul_ps(t0000x, grad0246x);
v128f muly = _mm_mul_ps(t0101y, grad0246y);
v128f mulz = _mm_mul_ps(t0011z, grad0246z);
v128f g0246 = _mm_add_ps(mulx, _mm_add_ps(muly, mulz));
mulx = _mm_mul_ps(t1111x, grad1357x);
muly = _mm_mul_ps(t0101y, grad1357y);
mulz = _mm_mul_ps(t0011z, grad1357z);
v128f g1357 = _mm_add_ps(mulx, _mm_add_ps(muly, mulz));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, the shuffle overhead makes this slower on modern processors so it&amp;rsquo;s only really a gain if your input data is already rotated.&lt;/p&gt;

&lt;p&gt;The SIMD approach is valuable. If you have enough free cores, there&amp;rsquo;s nothing stopping you using it at the same time as a GPU implementation. However, better gains in terms of productivity are more likely if you use something like the &lt;a href=&#34;http://ispc.github.com/&#34;&gt;Intel SPMD Program Compiler&lt;/a&gt;. You can also do something like use OpenCL on the CPU but the availability of CPU drivers on the PC may make this very problematic.&lt;/p&gt;

&lt;h5 id=&#34;an-opencl-implementation:e6e69b71ef866b6d53d10ae9b1d8d2cb&#34;&gt;An OpenCL Implementation&lt;/h5&gt;

&lt;p&gt;Knowing the float/double trick above, an OpenCL implementation is more straight-forward, &lt;em&gt;provided you have your program setup for loading/running OpenCL kernels&lt;/em&gt;. The same approach maps to CUDA or whatever favourite compute setup you have and you can even change and reload your noise functions on the fly (seeing the surface of a planet update in real-time as you edit its noise functions is quite funky):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float gradient_noise_inner(__global const float3* gradient_table, float3 cube_pos0, float3 cube_pos1, float3 t0, float3 t1)
{
    int x0 = cube_pos0.x;
    int y0 = cube_pos0.y;
    int z0 = cube_pos0.z;

    int x1 = cube_pos1.x;
    int y1 = cube_pos1.y;
    int z1 = cube_pos1.z;

    const int NOISE_HASH_X = 1213;
    const int NOISE_HASH_Y = 6203;
    const int NOISE_HASH_Z = 5237;
    const int NOISE_HASH_SEED = 1039;
    int ox0 = NOISE_HASH_X * x0 + NOISE_HASH_SEED;
    int oy0 = NOISE_HASH_Y * y0;
    int oz0 = NOISE_HASH_Z * z0;
    int ox1 = NOISE_HASH_X * x1 + NOISE_HASH_SEED;
    int oy1 = NOISE_HASH_Y * y1;
    int oz1 = NOISE_HASH_Z * z1;

    const int NOISE_HASH_SHIFT = 13;
    int index0 = ox0 + oy0 + oz0;
    int index1 = ox1 + oy0 + oz0;
    int index2 = ox0 + oy1 + oz0;
    int index3 = ox1 + oy1 + oz0;
    int index4 = ox0 + oy0 + oz1;
    int index5 = ox1 + oy0 + oz1;
    int index6 = ox0 + oy1 + oz1;
    int index7 = ox1 + oy1 + oz1;
    index0 ^= (index0 &amp;gt;&amp;gt; NOISE_HASH_SHIFT);
    index1 ^= (index1 &amp;gt;&amp;gt; NOISE_HASH_SHIFT);
    index2 ^= (index2 &amp;gt;&amp;gt; NOISE_HASH_SHIFT);
    index3 ^= (index3 &amp;gt;&amp;gt; NOISE_HASH_SHIFT);
    index4 ^= (index4 &amp;gt;&amp;gt; NOISE_HASH_SHIFT);
    index5 ^= (index5 &amp;gt;&amp;gt; NOISE_HASH_SHIFT);
    index6 ^= (index6 &amp;gt;&amp;gt; NOISE_HASH_SHIFT);
    index7 ^= (index7 &amp;gt;&amp;gt; NOISE_HASH_SHIFT);
    index0 &amp;amp;= 0xFF;
    index1 &amp;amp;= 0xFF;
    index2 &amp;amp;= 0xFF;
    index3 &amp;amp;= 0xFF;
    index4 &amp;amp;= 0xFF;
    index5 &amp;amp;= 0xFF;
    index6 &amp;amp;= 0xFF;
    index7 &amp;amp;= 0xFF;

    float3 grad0 = gradient_table[index0];
    float3 grad1 = gradient_table[index1];
    float3 grad2 = gradient_table[index2];
    float3 grad3 = gradient_table[index3];
    float3 grad4 = gradient_table[index4];
    float3 grad5 = gradient_table[index5];
    float3 grad6 = gradient_table[index6];
    float3 grad7 = gradient_table[index7];

    // Project permuted fractionals onto gradient vector
    float4 g0246, g1357;
    g0246.x = dot(grad0, select(t0, t1, (int3){ 0, 0, 0}));
    g1357.x = dot(grad1, select(t0, t1, (int3){-1, 0, 0}));
    g0246.y = dot(grad2, select(t0, t1, (int3){ 0,-1, 0}));
    g1357.y = dot(grad3, select(t0, t1, (int3){-1,-1, 0}));
    g0246.z = dot(grad4, select(t0, t1, (int3){ 0, 0,-1}));
    g1357.z = dot(grad5, select(t0, t1, (int3){-1, 0,-1}));
    g0246.w = dot(grad6, select(t0, t1, (int3){ 0,-1,-1}));
    g1357.w = dot(grad7, select(t0, t1, (int3){-1,-1,-1}));

    float3 r = quintic(t0);
    float4 gx0123 = lerp4(r.x, g0246, g1357);
    float2 gy01 = lerp2(r.y, gx0123.xz, gx0123.yw);
    float gz = lerp1(r.z, gy01.x, gy01.y);

    return gz;
}


float gradient_noise_d(__global const float3* gradient_table, double3 p)
{
    // Round to lowest integer boundary
    double3 pos0 = floor(p);

    // Convert to integer and get cube corners
    float3 cube_pos0 = convert_float3(pos0);
    float3 cube_pos1 = cube_pos0 + 1;

    // Get fractional to the lower corner and convert to float
    float3 t0 = convert_float3(p - pos0);

    // Get fractional to upper cube corner
    float3 t1 = t0 - 1;

    return gradient_noise_inner(gradient_table, cube_pos0, cube_pos1, t0, t1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is a crazy amount of work you can do to make this even faster, a couple of examples are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The integer hashing is quite slow. Vectorising it is pointless but doing some form of float hash can give significant speed gains (with potential vendor differences).&lt;/li&gt;
&lt;li&gt;The lookup table can be condensed and maybe moved into constant memory.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It&amp;rsquo;s already pretty fast but the most important additions I&amp;rsquo;d suggest are to use multiple noise functions: experiment with value noise, reduce the problem from 3D to 2D, anything. Getting great performance requires domain-specific knowledge of the patterns you&amp;rsquo;re trying to emulate and an appreciation for how much you can cheat.&lt;/p&gt;

&lt;h5 id=&#34;memorising-mm-shuffle-parameters:e6e69b71ef866b6d53d10ae9b1d8d2cb&#34;&gt;Memorising _MM_SHUFFLE parameters&lt;/h5&gt;

&lt;p&gt;The SSE code above contains a few calls to some cute little templates that replace use of the &lt;code&gt;_MM_SHUFFLE&lt;/code&gt; macro. It&amp;rsquo;s a particularly nasty macro to remember, especially when multiple calls use it differently. Here&amp;rsquo;s the templates that help make life a little easier:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;namespace simd
{
    enum VectorSelect
    {
        Ax = 0, Ay = 1, Az = 2, Aw = 3,
        Bx = 8, By = 9, Bz = 10, Bw = 11,
    };


    template &amp;lt;VectorSelect S0, VectorSelect S1, VectorSelect S2, VectorSelect S3&amp;gt;
    inline v128f shuffle_ps(v128f x, v128f y)
    {
        STATIC_ASSERT(S0 &amp;gt;= Ax &amp;amp;&amp;amp; S0 &amp;lt;= Aw);
        STATIC_ASSERT(S1 &amp;gt;= Ax &amp;amp;&amp;amp; S1 &amp;lt;= Aw);
        STATIC_ASSERT(S2 &amp;gt;= Bx &amp;amp;&amp;amp; S2 &amp;lt;= Bw);
        STATIC_ASSERT(S3 &amp;gt;= Bx &amp;amp;&amp;amp; S3 &amp;lt;= Bw);
        return _mm_shuffle_ps(x, y, S0 + S1 * 4 + (S2 - Bx) * 16 + (S3 - Bx) * 64);
    }

    template&amp;lt;VectorSelect S0, VectorSelect S1, VectorSelect S2, VectorSelect S3&amp;gt;
    inline v128f blend_ps(v128f x, v128f y)
    {
        STATIC_ASSERT(S0 == Ax || S0 == Bx);
        STATIC_ASSERT(S1 == Ay || S1 == By);
        STATIC_ASSERT(S2 == Az || S2 == Bz);
        STATIC_ASSERT(S3 == Aw || S3 == Bw);
        return _mm_blend_ps(x, y, (S0 / Bx) *  1 + (S1 / By) *  2 + (S2 / Bz) *  4 + (S3 / Bw) *  8);
    }

    template&amp;lt;VectorSelect S0, VectorSelect S1, VectorSelect S2&amp;gt;
    inline v128f blend_ps(v128f x, v128f y)
    {
        STATIC_ASSERT(S0 == Ax || S0 == Bx);
        STATIC_ASSERT(S1 == Ay || S1 == By);
        STATIC_ASSERT(S2 == Az || S2 == Bz);
        return _mm_blend_ps(x, y, (S0 / Bx) *  1 + (S1 / By) *  2 + (S2 / Bz) *  4);
    }


    template &amp;lt;VectorSelect S0, VectorSelect S1, VectorSelect S2, VectorSelect S3&amp;gt;
    inline v128i shuffle_epi32(v128i x)
    {
        STATIC_ASSERT(S0 &amp;gt;= Ax &amp;amp;&amp;amp; S0 &amp;lt;= Aw);
        STATIC_ASSERT(S1 &amp;gt;= Ax &amp;amp;&amp;amp; S1 &amp;lt;= Aw);
        STATIC_ASSERT(S2 &amp;gt;= Ax &amp;amp;&amp;amp; S2 &amp;lt;= Aw);
        STATIC_ASSERT(S3 &amp;gt;= Ax &amp;amp;&amp;amp; S3 &amp;lt;= Aw);
        return _mm_shuffle_epi32(x, S0 + S1 * 4 + S2 * 16 + S3 * 64);
    }


    inline v128f lerp(v128f t, v128f a, v128f b)
    {
        v128f r = _mm_sub_ps(b, a);
        r = _mm_mul_ps(r, t);
        r = _mm_add_ps(r, a);
        return r;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The static assert should nicely catch any errors you make at compile-time, as well as providing implicit documentation on the valid range of inputs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Skeletal Animation Looping with Autocorrelation</title>
      <link>http://donw.io/post/animation-autocorrelation/</link>
      <pubDate>Mon, 20 Aug 2012 16:07:23 +0100</pubDate>
      
      <guid>http://donw.io/post/animation-autocorrelation/</guid>
      <description>

&lt;p&gt;This is a bit of a fun post highlighting how some simple maths can be used to create great visual results. With some basic statistics, we can create looping skeletal animations from an input data set that contains non-exact loops. A typical example is a motion capture sampled run animation:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;http://donw.io/img/AnimLooping/OriginalAnim.gif&#34; alt=&#34;d&#34; /&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;This is derived from the &lt;a href=&#34;http://mocap.cs.cmu.edu/&#34;&gt;CMU Graphics Lab Motion Capture Database&lt;/a&gt;, which has been &lt;a href=&#34;https://sites.google.com/a/cgspeed.com/cgspeed/motion-capture/cmu-bvh-conversion&#34;&gt;converted to BVH files&lt;/a&gt; by Bruce Hahne. I can load BVH files and dynamically retarget them to my animation rigs so that I never have to worry about changing animation rigs again (this is absolutely key to some of the features of my product and would have been immensely useful for the animation pipelines in many of my past games).&lt;/p&gt;

&lt;p&gt;The first task is to center the animation on the origin to allow movement to be controlled by the game. Appropriate playback timing/blending and IK foot fixups are added after that. Many games simply strip the root bone offset from the animation but you lose a lot of animated weight transfer and bounce. I chose instead to send out a &amp;ldquo;rabbit&amp;rdquo; node that attempts to keep up with the moving skeleton via a fixed linear velocity, subtracting its position to get:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;http://donw.io/img/AnimLooping/CenteredAnim.gif&#34; alt=&#34;d&#34; /&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;You can notice the three-and-a-bit steps the skeleton takes, the slow raising of the torso and the hard snap at the end when the animation ends. Somewhere in there is a two step loop that can be used to create a seamlessly looping animation. The tasks required are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use auto/cross correlation to identify potential loop lengths in the animation.&lt;/li&gt;
&lt;li&gt;Search the animation using the loop lengths for start and end frames whose poses match.&lt;/li&gt;
&lt;li&gt;Cross-fade the beginning and end of the animation to smooth out the differences.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Statistics aren&amp;rsquo;t my strong point so I would really appreciate any corrections to this post!&lt;/p&gt;

&lt;h5 id=&#34;cross-correlation:894f9b4cb59901f5bf4506e115ff54db&#34;&gt;Cross Correlation&lt;/h5&gt;

&lt;p&gt;Given two discrete real data sets:&lt;/p&gt;

&lt;p&gt;$$x = [ x_0, x_1, x_2, &amp;hellip;, x_n ]$$
$$y = [ y_0, y_1, y_2, &amp;hellip;, y_n ]$$&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Correlation_and_dependence&#34;&gt;Correlation&lt;/a&gt; can give you a single number that tells you how similar these two data sets are. This number is generally called the correlation coefficient and can be calculated in a number of different ways, depending on what particular features of the data set you&amp;rsquo;re interested in highlighting.&lt;/p&gt;

&lt;p&gt;The most common coefficient appears to be the &lt;a href=&#34;http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient&#34;&gt;Pearson product-moment correlation coefficient&lt;/a&gt;. The coefficient is in the range -1 to 1, where 1 means there is a perfect linear relationship, 0 means there is no relationship and -1 means there is a negative linear relationship. A simple definition for a population is:&lt;/p&gt;

&lt;p&gt;$$R(x,y) = \frac{1}{n} \sum\limits_{i=1}^n \frac{x(i) - m(x)}{s(x)} * \frac{y(i) - m(y)}{s(y)}$$&lt;/p&gt;

&lt;p&gt;where $m$ is the median and $s$ is the standard deviation of the population.&lt;/p&gt;

&lt;p&gt;Interestingly, this coefficient is independent of the unit of measurement: it can report 100% correlation between data sets that differ in scale or offset. For example, if set $x$ recorded your age in months and set $y$ recorded your height in inches at that age, it will be able to report any linear relationship (e.g. you get taller as you get older) with a correlation coefficient close to 1. This nice result is achieved by first of all centering each data set on its median and then transforming the set into units of its standard deviation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Cross-correlation&#34;&gt;Cross Correlation&lt;/a&gt; uses this basic tool to evaluate how similar two input data sets are when one of them is offset (or, time-lagged in the case of audio samples). Assuming the data sets are equal in length, for every sample in $x$, the correlation coefficient is calculated with an offset version of $y$:&lt;/p&gt;

&lt;p&gt;$$xcorr(x, y)[n] = sum(x&amp;rsquo; [m] * y[m + n])$$&lt;/p&gt;

&lt;p&gt;Here, $&amp;lsquo;$ is the complex conjugate. As we&amp;rsquo;ll be dealing with real numbers, this can safely be ignored. You can use this for many things, like detecting the presence of one signal (or similar) somewhere within another, measuring tempo or even auto-tuning (yes, Mathematicians helped create our current generation of &lt;a href=&#34;http://www.time.com/time/magazine/article/0,9171,1877372,00.html&#34;&gt;talentless musicians&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;This leads to the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;double CrossCorrelate(const std::vector&amp;lt;double&amp;gt;&amp;amp; x, const std::vector&amp;lt;double&amp;gt;&amp;amp; y)
{
    // Assume data sets are the same size
    size_t size = x.size();
    assert(size == y.size());

    // Calculate mean and standard deviation of data sets
    double mx = mean(x);
    double my = mean(y);
    double sx = stddev(x);
    double sy = stddev(y);

    // Calculate correlation coefficient for each offset
    std::vector&amp;lt;double&amp;gt; Rxy(size);
    for (size_t i = 0; i &amp;lt; size; i++)
    {
        // First term can be pulled out of the inner loop
        double a = (x[i] - mx) / sx;

        double c = 0;
        for (size_t j = 0; j &amp;lt; size; j++)
        {
            // Second term is always offset by the constant &#39;i&#39;
            // I&#39;m choosing to wrap here whereas you can also zero-pad
            size_t ij = (i + j) % size;
            double b = (y[ij] - my) / sy;

            c += a * b;
        }

        Rxy[i] = c / size;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assuming the input data sets are the same size is not very useful in reality, however we don&amp;rsquo;t need to do full cross correlation. With animation, we want to be able to detect loops within one dataset; essentially making $x$ and $y$ the same.&lt;/p&gt;

&lt;p&gt;This is called &lt;a href=&#34;http://en.wikipedia.org/wiki/Autocorrelation&#34;&gt;Autocorrelation&lt;/a&gt; and it gets even better. Given that we&amp;rsquo;re not interested in the unit-independent properties of cross correlation (we&amp;rsquo;re comparing the same data set values), we can set the median to zero and standard deviation to one, leaving:&lt;/p&gt;

&lt;p&gt;$$R(x,y) = \frac{1}{n} \sum\limits_{i=1}^n x(i) * y(i)$$&lt;/p&gt;

&lt;h5 id=&#34;application-to-skeletal-animation:894f9b4cb59901f5bf4506e115ff54db&#34;&gt;Application to Skeletal Animation&lt;/h5&gt;

&lt;p&gt;The data set we have is the rotation values of each bone in an animation for each frame (I&amp;rsquo;m ignoring scale as you don&amp;rsquo;t generally get that from BVH data and translations are present only on root bones). We want to perform autocorrelation for each frame of the animation with a frame offset version of itself.&lt;/p&gt;

&lt;p&gt;Autocorrelation above was defined in terms of scalar value multiplication, so an equivalent data type and multiplication operator needs to be defined for a single frame of animation. This can be achieved by using a vector of all bone rotations for a specific frame, combined with a vector dot product, which is effectively a projection of one frame onto another (result is max when all bones line up).&lt;/p&gt;

&lt;p&gt;You can use the quaternion values directly or euler angles; it doesn&amp;rsquo;t matter. We&amp;rsquo;re not interested in the values themselves, we&amp;rsquo;re just interested in how they relate to each other. I have found, though, that I&amp;rsquo;m getting better results using rotations that are relative to their parent bone, as opposed to object-space rotations.&lt;/p&gt;

&lt;p&gt;This leads to the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct Anim
{
    size_t int nb_bones;
    size_t int nb_frames;

    // Just rotation data for all bones in all frames
    // size = nb_bones * nb_frames
    std::vector&amp;lt;quat&amp;gt; frame_data;
};

double DotProduct(
    const std::vector&amp;lt;quat&amp;gt;&amp;amp; x,
    const std::vector&amp;lt;quat&amp;gt;&amp;amp; y,
    size_t ox,
    size_t oy,
    size_t vector_size)
{
    // Dot product of two frame vectors. As they&#39;re just collections of rotation quaternions,
    // sum all quaternion dot products.
    double dp = 0;
    for (size_t i = 0; i &amp;lt; vector_size; i++)
    {
        quat q0 = x[ox + i];
        quat q1 = y[oy + i];
        dp += q0.x * q1.x + q0.y * q1.y + q0.z * q1.z + q0.w * q1.w;
    }
    return dp;
}


double Correlate(
    const Anim&amp;amp; anim,
    const std::vector&amp;lt;quat&amp;gt;&amp;amp; x,
    const std::vector&amp;lt;quat&amp;gt;&amp;amp; y,
    size_t frame_offset)
{
    double Rxy = 0;
    for (size_t i = 0; i &amp;lt; anim.nb_frames; i++)
    {
        // Shift and wrap to keep the inputs the same length
        size_t ox = i;
        size_t oy = (frame_offset + i) % anim.nb_frames;

        // Calculating the Pearson correlation co-efficient using mean of zero and stdev of 1
        Rxy += DotProduct(x, y, ox, oy, anim.nb_bones);
    }

    return Rxy / anim.nb_frames;
}

// Calculate the cross-correlation sequence using the same animation for both inputs (auto-correlation)
std::vector&amp;lt;double&amp;gt; Rxy(anim.nb_frames);
for (size_t i = 0; i &amp;lt; anim.nb_frames; i++)
    Rxy[i] = Correlate(anim, anim.frame_data, anim.frame_data, i);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When applied to the centered animation above, the sequence looks like this:&lt;/p&gt;

&lt;div id=&#34;xcorr_anim_graph&#34; style=&#34;width:400px;height:250px;margin-left:auto;margin-right:auto;&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;text/javascript&#34;&gt;
	new Dygraph(document.getElementById(&#34;xcorr_anim_graph&#34;), &#34;\/img\/AnimLooping\/a.csv&#34;,
		{
			title: &#34;Autocorrelation Sequence&#34;,
			titleHeight: 22,
			xlabel: &#34;Click and drag to zoom; double-click to restore zoom level&#34;,
			xLabelHeight: 12,
		});
&lt;/script&gt;
&lt;br/&gt;


&lt;p&gt;We&amp;rsquo;re interested here in looking for the peaks of the graph, answering the question: other than at the start, where does the animation most look like itself? This is a standard local maximum search that starts off with computing the first derivative:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// We want to detect the local minimum/maximum points in the sequence, as periodicity
// estimates for the animation so calculate 1st derivative
std::vector&amp;lt;double&amp;gt; Rxy_df(anim.nb_frames);
for (size_t i = 1; i &amp;lt; Rxy.size(); i++)
    Rxy_df[i] = Rxy[i] - Rxy[i - 1];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;leading to:&lt;/p&gt;

&lt;div id=&#34;1stderiv_anim_graph&#34; style=&#34;width:400px;height:250px;margin-left:auto;margin-right:auto;&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;text/javascript&#34;&gt;
	new Dygraph(document.getElementById(&#34;1stderiv_anim_graph&#34;), &#34;\/img\/AnimLooping\/b.csv&#34;,
		{
			title: &#34;First Derivative&#34;,
			titleHeight: 22,
			xlabel: &#34;Click and drag to zoom; double-click to restore zoom level&#34;,
			xLabelHeight: 12,
		});
&lt;/script&gt;
&lt;br/&gt;


&lt;p&gt;Local minima/maxima are located at the zero crossings and local maxima can be detected where the derivative is decreasing.&lt;/p&gt;

&lt;h5 id=&#34;searching-for-start-and-end-frames:894f9b4cb59901f5bf4506e115ff54db&#34;&gt;Searching for Start and End Frames&lt;/h5&gt;

&lt;p&gt;Just as autocorrelation in audio can only measure tempo and not tell you where specific beats are, this technique will only tell you potential lengths of the animation. Autocorrelation is a function of the signal, not a frame, so we will need to search the animation for start/end frames that match each other as closely as possible.&lt;/p&gt;

&lt;p&gt;Beyond rotation similarity, we also want to ensure velocity/acceleration and general trajectory similarity. Given a potential start and end frame, we can determine a simple measure of similarity by summing squared distances within a set window. By walking through all possible start/end frames and keeping the smallest sum, we can get our best match.&lt;/p&gt;

&lt;p&gt;This code is based on Benjy Cook&amp;rsquo;s Python mocap tools for Blender, linked below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;double SqrDistance(
    const std::vector&amp;lt;quat&amp;gt;&amp;amp; x,
    const std::vector&amp;lt;quat&amp;gt;&amp;amp; y,
    size_t ox,
    size_t oy,
    size_t vector_size)
{
    double d = 0;
    for (size_t i = 0; i &amp;lt; vector_size; i++)
    {
        quat q0 = x[ox + i];
        quat q1 = y[oy + i];
        quat q = { q0.x - q1.x, q0.y - q1.y, q0.z - q1.z, q0.w - q1.w };
        d += q.x * q.x + q.y * q.y + q.z * q.z + q.w * q.w;
    }
    return d;
}

static const int WINDOW_SIZE = 5;
int best_fit_frame = -1;
size_t best_fit_length = 0;
double best_fit_sum = 0;

for (size_t i = 0; i &amp;lt; local_maxima.size(); i++)
{
    size_t length = local_maxima[i];

    // Precalculate distances between all possible start/end frames at this length
    std::vector&amp;lt;double&amp;gt; distance(anim.nb_frames - length);
    for (size_t j = 0; j &amp;lt; distance.size(); j++)
    {
        size_t ox = j * anim.nb_bones;
        size_t oy = (j + length) * anim.nb_bones;
        distance[j] = SqrDistance(anim.frame_data, anim.frame_data, ox, oy, anim.nb_bones);
    }

    // Search for the best start/end frame pair
    for (size_t j = WINDOW_SIZE; j &amp;lt; distance.size() - WINDOW_SIZE - 1; j++)
    {
        // Sum distances in local neighbourhood
        double sum = 0;
        for (size_t k = j - WINDOW_SIZE; k &amp;lt;= j + WINDOW_SIZE; k++)
            sum += distance[k];

        // Keep the best fit
        if (best_fit_frame == -1 || sum &amp;lt; best_fit_sum)
        {
            best_fit_frame = j;
            best_fit_length = length;
            best_fit_sum = sum;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using the best fit frame and length, the animation can then be clipped to give:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;http://donw.io/img/AnimLooping/ClippedAnim.gif&#34; alt=&#34;d&#34; /&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;There are a few things to note about the result:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The two step loop has been correctly identified.&lt;/li&gt;
&lt;li&gt;The start and end frames match pretty well: both leg and arm movement is almost seamless.&lt;/li&gt;
&lt;li&gt;There is a visible snap after the torso still rises for the duration of the animation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Beyond employing better loop detection methods, this is really the best we can do without modifying the original animation. Even if we tried to look for better techniques, the chances of a single mocap shoot giving a perfectly loopable animation are minimal.&lt;/p&gt;

&lt;h5 id=&#34;cross-fading-around-the-seam:894f9b4cb59901f5bf4506e115ff54db&#34;&gt;Cross-fading Around the Seam&lt;/h5&gt;

&lt;p&gt;The final simple part to this is to blend the last few frames in the animation so that they meet seamlessly with the frame at the start of the animation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;static const int BLEND_SIZE = 10;
for (size_t i = 0; i &amp;lt; BLEND_SIZE; i++)
{
    size_t offset = (anim.nb_frames - BLEND_SIZE + i) * anim.nb_bones;
    double t = (double)i / BLEND_SIZE;

    for (size_t j = 0; j &amp;lt; anim.nb_bones; j++)
    {
        const math::frame&amp;amp; dst = anim.frame_data[j];
        math::frame&amp;amp; src = anim.frame_data[offset + j];
        src = fLerp(src, dst, (float)t);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A &lt;code&gt;frame&lt;/code&gt; in my code base is an &lt;a href=&#34;http://en.wikipedia.org/wiki/Affine_frame&#34;&gt;Affine Frame&lt;/a&gt; with vector position and quaternion rotation. I linearly interpolate both components based on their distance from the end of the animation (the quaternion lerp is normalised, as opposed to &lt;a href=&#34;http://number-none.com/product/Understanding%20Slerp,%20Then%20Not%20Using%20It/&#34;&gt;using slerp&lt;/a&gt;). This cleans up any small position differences in the hip bone.&lt;/p&gt;

&lt;p&gt;The final result is pretty cool!&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;http://donw.io/img/AnimLooping/LoopingAnim.gif&#34; alt=&#34;d&#34; /&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;You can tweak the number of blend frames a little to get a smoother transition.&lt;/p&gt;

&lt;h5 id=&#34;conclusion:894f9b4cb59901f5bf4506e115ff54db&#34;&gt;Conclusion&lt;/h5&gt;

&lt;p&gt;There is a whole bunch of stuff that you&amp;rsquo;ll need to do to make this production-ready (loops within loops, signal filtering, artist pre/post input/modification, etc) but it this should be a good start.&lt;/p&gt;

&lt;p&gt;Curiously, while debugging all my code for this I found that zero-crossings of the second differential (representing local minima of the first derivative) were giving good approximations to the start and end frame in animation loops:&lt;/p&gt;

&lt;div id=&#34;2ndderiv_anim_graph&#34; style=&#34;width:400px;height:250px;margin-left:auto;margin-right:auto;&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;text/javascript&#34;&gt;
	new Dygraph(document.getElementById(&#34;2ndderiv_anim_graph&#34;), &#34;\/img\/AnimLooping\/c.csv&#34;,
		{
			title: &#34;Second Derivative&#34;,
			titleHeight: 22,
			xlabel: &#34;Click and drag to zoom; double-click to restore zoom level&#34;,
			xLabelHeight: 12,
		});
&lt;/script&gt;
&lt;br/&gt;


&lt;p&gt;If I start this specific animation at 15 and end it at 123, it loops just as well! I&amp;rsquo;ve not tested this on many data sets or dug into the maths further to see if there is anything to this, but it&amp;rsquo;s an interesting avenue for future investigation.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s some links for further reading:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://wiki.blender.org/index.php/Extensions:2.6/Py/Scripts/Animation/Motion_Capture_Tools&#34;&gt;Blender Mocap Tools&lt;/a&gt; - A great source code reference for stuff like this, written by &lt;a href=&#34;https://plus.google.com/104243235864119960562&#34;&gt;Benjy Cook&lt;/a&gt;. (Python)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.hawaii.edu/powerkills/UC.HTM&#34;&gt;Understanding Correlation&lt;/a&gt; - Online book hoping to shed some intuition on correlation.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://audiograins.com/blog/tag/cross-correlation/&#34;&gt;Autocorrelation for Tempo Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://dsp.stackexchange.com/questions/736/how-do-i-implement-cross-correlation-to-prove-two-audio-files-are-similar&#34;&gt;How do I implement Cross-correlation to prove two audio files are similar?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Quaternions and Dual Quaternion Skinning</title>
      <link>http://donw.io/post/dual-quaternion-skinning/</link>
      <pubDate>Thu, 19 Jul 2012 12:52:03 +0100</pubDate>
      
      <guid>http://donw.io/post/dual-quaternion-skinning/</guid>
      <description>

&lt;p&gt;For some reason I like quaternions. I fell in love with complex numbers back in school when I found out that they &lt;a href=&#34;http://en.wikipedia.org/wiki/Algebraically_closed_field#Examples&#34;&gt;made more sense than real numbers&lt;/a&gt;. While it &lt;a href=&#34;http://www.geometricalgebra.net/quaternions.html&#34;&gt;might not exactly be helpful&lt;/a&gt; to visualise quaternions as an extension of complex numbers, there&amp;rsquo;s something in there that just grabs at me. Unlike previous posts, I&amp;rsquo;ve managed to update to D3D11 so I&amp;rsquo;ll be discussing implementation details in terms of HLSL (Shader Model 4, as I also have a D3D10 dev machine).&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m no mathematician so hopefully this information in this post should be pretty accessible.&lt;/p&gt;

&lt;h5 id=&#34;dual-quaternion-skinning:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Dual Quaternion Skinning&lt;/h5&gt;

&lt;p&gt;I spent a couple of hours last week converting my skinning pipeline to use dual quaternions. My animation pipeline works with quaternions; the source animation data, skeleton pose and inverse base pose are quaternion-based. Right at the very end, the composited result is converted to matrix and sent to the GPU. In effect, I&amp;rsquo;m doing this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;for (int i = 0; i &amp;lt; nb_bones; i++)
{
    const rend::Bone&amp;amp; bone = skeleton.bones[i];
    const rend::Keyframe&amp;amp; kf = keyframes[i + frame * nb_bones];

    // Calculate inverse base pose
    math::quat q0 = qConjugate(bone.base_pose.rotation);
    math::vec3 p0 = qTransformPos(q0, v3Negate(bone.base_pose.position));

    // Concatenate with animation keyframe
    math::quat q = qMultiply(q0, kf.rotation);
    math::vec3 p = qTransformPos(kf.rotation, p0);
    p = v3Add(p, kf.position);

    // Set the transform
    math::mat4&amp;amp; transform = transforms[i];
    transform = qToMat4(q);
    transform.r[3] = math::v4Make(p.x, p.y, p.z, 1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In reality, I precalculate the inverse base pose, keeping the inner loop tight and low on ALU operations. My goals were:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Capitalise on the quaternion input and remove the conversion to matrix step. On all past games I&amp;rsquo;ve worked on, the matrix multiply with base pose has had a destructive influence on CPU performance; if I could remove this step, I&amp;rsquo;d have a solution that would be faster than my past implementations.&lt;/li&gt;
&lt;li&gt;Reduce the amount of data being mapped/sent to the GPU. While my existing solution was sending 4x4 matrices, one of the columns was redundant - I could be sending 4x3. However, dual quaternions would allow me to halve the amount of data sent.&lt;/li&gt;
&lt;li&gt;Get volume-preserving skinning on joints under extreme rotation.&lt;/li&gt;
&lt;li&gt;Have a bit of fun and exercise some neglected quaternion/vector math muscles.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I skimmed the paper, copied the HLSL source code and tested everything on a basic idle animation. Bad idea, right? But everything seemed to work. I hooked up my mocap pipeline this week and everything went wrong - limbs were folding inside each other and the character was skewing all over the place.&lt;/p&gt;

&lt;p&gt;Searching the internets for equivalent implementations found that most basically copied and pasted from the paper. Some seemed to make an effort to understand what was going on under the hood but all of them produced the same results (oddly, the nVidia shader was the most needlessly complicated and inefficient of them all). So I knuckled down and decided to read the following papers in more detail:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://wscg.zcu.cz/wscg2012/cd-rom/short/A29-full.pdf&#34;&gt;A Beginners Guide to Dual Quaternions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://isg.cs.tcd.ie/projects/DualQuaternions/&#34;&gt;Geometric Skinning with Approximate Dual Quaternion Blending&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The basic method is this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Convert your quaternion rotation and position vector to a dual quaternion on the CPU for each bone.&lt;/li&gt;
&lt;li&gt;In your vertex shader, load all dual quaternion bone transforms for the vertex.&lt;/li&gt;
&lt;li&gt;Create a single dual quaternion that is the weighted average of all the bone transforms.&lt;/li&gt;
&lt;li&gt;Transform the vertex position and normal by this dual quaternion.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;quaternion-vector-multiplication:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Quaternion/Vector Multiplication&lt;/h5&gt;

&lt;p&gt;To cut a long story short, the reason none of this was working for me was that I was looking at Cg code, as opposed to HLSL code. Having never really used Cg, it never occurred to me that the order of cross product parameters should be swapped to account for handedness. Cross products are used to define the quaternion multiplication:&lt;/p&gt;

&lt;p&gt;$$ Q = (w, V) \\ Q_r = Q_0 Q_1  \\ Q_r = (w_0 w_1 - V_0 \cdot V_1, w_0 V_1 + w_1 V_0 + V_0 \times V_1)$$&lt;/p&gt;

&lt;p&gt;&lt;center&gt; ($\cdot$ is the vector dot product and $\times$ is the vector cross product) &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Naturally, this is then a non-commutative operation, giving the order in which you pass arguments into your multiply functions importance, too. A basic C++ implementation of the multiplication looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;math::quat math::qMultiply(const math::quat&amp;amp; a, const math::quat&amp;amp; b)
{
    quat q =
    {
        a.w * b.x + a.x * b.w + a.y * b.z - a.z * b.y,
        a.w * b.y - a.x * b.z + a.y * b.w + a.z * b.x,
        a.w * b.z + a.x * b.y - a.y * b.x + a.z * b.w,
        a.w * b.w - a.x * b.x - a.y * b.y - a.z * b.z,
    };
    return q;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assuming we&amp;rsquo;re using unit quaternions, you can rotate a vector by a quaternion using multiplication:&lt;/p&gt;

&lt;p&gt;$$P_r = Q*(0, P)*Q&amp;rsquo;$$&lt;/p&gt;

&lt;p&gt;Here, $*$ is the quaternion multiplication, $&amp;lsquo;$ is the quaternion conjugate and $(0,P)$ is construction of a pure quaternion using the vector, setting the quaternion real component to zero. This equation is used to convert to and from dual quaternions, so it&amp;rsquo;s important you keep order of multiplications in mind.&lt;/p&gt;

&lt;p&gt;If you work with Cg, make sure you have your cross products round the other way to my shader examples below!&lt;/p&gt;

&lt;h5 id=&#34;converting-to-dual-quaternion:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Converting to Dual Quaternion&lt;/h5&gt;

&lt;p&gt;I&amp;rsquo;d suggest reading the second paper linked above to get a good introduction to what dual quaternions are and what the various components mean. For our means here it&amp;rsquo;s enough to say that dual quaternions are just a pair of quaternions - the &amp;ldquo;real&amp;rdquo; quaternion and the &amp;ldquo;dual&amp;rdquo; quaternion:&lt;/p&gt;

&lt;p&gt;$$DQ = (Q_r, Q_d)$$&lt;/p&gt;

&lt;p&gt;Converting a quaternion rotation and position vector to this representation is simple. The $Q_r$ term is a simple copy of your quaternion rotation and $Q_d$ is:&lt;/p&gt;

&lt;p&gt;$$Q_d = 0.5(0, V)*Q_r$$&lt;/p&gt;

&lt;p&gt;This allows the matrix conversion code on the CPU to become:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Convert position/rotation to dual quaternion
math::dualquat&amp;amp; transform = transforms[i];
transform.r = q;
transform.d = qScale(qMultiplyPure(q, p), 0.5f);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Much nicer! &lt;code&gt;MultiplyPure&lt;/code&gt; is a simple function that does a special case multiply where &lt;code&gt;p.w&lt;/code&gt; is zero.&lt;/p&gt;

&lt;h5 id=&#34;blending-dual-quaternions:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Blending Dual Quaternions&lt;/h5&gt;

&lt;p&gt;Now we can move over to the HLSL side. This is my transform loading code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;Buffer&amp;lt;float4&amp;gt; g_BoneTransforms;

float2x4 GetBoneDualQuat(uint bone_index)
{
    // Load bone rows individually
    float4 row0 = g_BoneTransforms.Load(bone_index * 2 + 0);
    float4 row1 = g_BoneTransforms.Load(bone_index * 2 + 1);
    return float2x4(row0, row1);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As mentioned before, we want to load the bones that influence a vertex, weight them and transform the vertex position and normal:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float2x4 BlendBoneTransforms(uint4 bone_indices, float4 bone_weights)
{
    // Fetch bones
    float2x4 dq0 = GetBoneDualQuat(bone_indices.x);
    float2x4 dq1 = GetBoneDualQuat(bone_indices.y);
    float2x4 dq2 = GetBoneDualQuat(bone_indices.z);
    float2x4 dq3 = GetBoneDualQuat(bone_indices.w);

    // ...blend...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As with quaternions, weighting dual quaternions can be achieved using a normalised lerp of its components. As explained in the paper &lt;a href=&#34;http://number-none.com/product/Understanding%20Slerp,%20Then%20Not%20Using%20It/&#34;&gt;Understanding Slerp, Then Not Using It&lt;/a&gt;, it&amp;rsquo;s not as good as a SLERP in that it&amp;rsquo;s not constant velocity. However, it has minimal torque, rotating along the sphere and unlike SLERP, is commutative; meaning, if you combine multiple quaternions in a different order, the result will always be the same.&lt;/p&gt;

&lt;p&gt;Besides, when you&amp;rsquo;re regenerating bone rotations each frame, interpolation velocity won&amp;rsquo;t really factor into the solution. The weighting code thus becomes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Blend
float2x4 result =
    bone_weights.x * dq0 +
    bone_weights.y * dq1 +
    bone_weights.z * dq2 +
    bone_weights.w * dq3;

// Normalise
float norm = length(result[0]);
return result / norm;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Simples! In the original paper, Kavan goes into great detail on why this works so well over previous solutions and why a SLERP isn&amp;rsquo;t the ideal solution. Well worth a read.&lt;/p&gt;

&lt;h5 id=&#34;antipodality-or-quaternion-double-cover:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Antipodality or, Quaternion Double-Cover&lt;/h5&gt;

&lt;p&gt;Take a look at one of the classic release bugs of this generation:&lt;/p&gt;

&lt;p&gt;&lt;center&gt; &lt;iframe width=&#34;420&#34; height=&#34;315&#34; src=&#34;http://www.youtube.com/embed/ToKIkw3LIoQ&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s a pretty awesome reason for why the head can spin the long way around to get to its target rotation (no doubt the bug will be more complicated than that). Casey Muratori goes into &lt;a href=&#34;https://mollyrocket.com/837&#34;&gt;great detail on this&lt;/a&gt; and I&amp;rsquo;ll attempt to summarise.&lt;/p&gt;

&lt;p&gt;The axis-angle definition of a quaternion is:&lt;/p&gt;

&lt;p&gt;$$Q = (cos(\frac{\theta}{2}), Vsin(\frac{\theta}{2}))$$&lt;/p&gt;

&lt;p&gt;Inherent in this definition is the ability for quaternions to represent up to 720 degrees of rotation. Assuming we use the x-axis as our example vector, this leads to these quantities:&lt;/p&gt;

&lt;p&gt;$$Q(0) = (1, 0, 0, 0) \\ Q(360) = (-1, 0, 0, 0) \\ Q(720) = (1, 0, 0, 0)$$&lt;/p&gt;

&lt;p&gt;While sine and cosine are periodic every 360 degrees, the division by two of the input angle leads the quaternion representation to be periodic every 720 degrees.&lt;/p&gt;

&lt;p&gt;Clearly, 360 degrees and 720 degrees represent the same geometrical rotation. However, when you interpolate between rotations, you may find yourself interpolating the long way round. Your source/target rotation range may geometrically be only 30 to 35 degrees but your quaternion may represent that as 30 to 395 degrees!&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;ve glimpsed at the inner workings of a SLERP, this is the case they are trying to avoid when trying to solve for the &amp;ldquo;shortest path&amp;rdquo;. Given that $Q$ and $-Q$ represent the same rotation, you can ensure interpolation between two quaternions follows this shortest path by negating one of the quaternions if the dot product between them is negative.&lt;/p&gt;

&lt;p&gt;When blending dual quaternions, you have to watch for the same case. Not only that, you have to ensure that all of your bone transforms are in the same neighbourhood. While there are &lt;a href=&#34;http://pages.cs.wisc.edu/~joony/RESEARCH/online_locomotion.pdf&#34;&gt;complicated ways of achieving that&lt;/a&gt;, most of the time it can be guaranteed by comparing all bone rotations to the first one and adjusting the sign of the blend weight.&lt;/p&gt;

&lt;p&gt;This leads to the final code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float2x4 BlendBoneTransforms(uint4 bone_indices, float4 bone_weights)
{
    // Fetch bones
    float2x4 dq0 = GetBoneDualQuat(bone_indices.x);
    float2x4 dq1 = GetBoneDualQuat(bone_indices.y);
    float2x4 dq2 = GetBoneDualQuat(bone_indices.z);
    float2x4 dq3 = GetBoneDualQuat(bone_indices.w);

    // Ensure all bone transforms are in the same neighbourhood
    if (dot(dq0[0], dq1[0]) &amp;lt; 0.0) bone_weights.y *= -1.0;
    if (dot(dq0[0], dq2[0]) &amp;lt; 0.0) bone_weights.z *= -1.0;
    if (dot(dq0[0], dq3[0]) &amp;lt; 0.0) bone_weights.w *= -1.0;

    // Blend
    float2x4 result =
        bone_weights.x * dq0 +
        bone_weights.y * dq1 +
        bone_weights.z * dq2 +
        bone_weights.w * dq3;

    // Normalise
    float norm = length(result[0]);
    return result / norm;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are cases which can still fail these checks but they are very rare for the general use-case of skinning - I can&amp;rsquo;t imagine this working well for severe joint twists, for example (beyond the range of human constraints, that is).&lt;/p&gt;

&lt;h5 id=&#34;transforming-the-vertex-with-dual-quaternions:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Transforming the Vertex with Dual Quaternions&lt;/h5&gt;

&lt;p&gt;Once you have the blended result you need to convert it back into quaternion/vector form and transform your vertex. There are two ways of achieving this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Convert straight to matrix and use the matrix to transform the vertex.&lt;/li&gt;
&lt;li&gt;Convert to quaternion/vector and transform the vertex using that.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The fastest and by far cleanest way is the second so I will concentrate on that. Given that you already have the rotation in the $Q_r$ component of the dual quaternion, extraction of the translation vector is achieved using the following:&lt;/p&gt;

&lt;p&gt;$$V = 2Q_d*Q_r&amp;rsquo;$$&lt;/p&gt;

&lt;p&gt;This can be implemented directly as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float4 Conjugate(float4 q)
{
    return float4(-q.x, -q.y, -q.z, q.w);
}

float4 Multiply(float4 a, float4 b)
{
    return float4(a.w * b.xyz + b.w * a.xyz + cross(b.xyz, a.xyz), a.w * b.w - dot(a.xyz, b.xyz));
}

float3 ReconstructTranslation(float4 Qr, float4 Qd)
{
    // The input is the dual quaternion, real part and dual part
    return Multiply(Qd, Conjugate(Qr)).xyz;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Of course, the complete calculation can be collapsed by directly applying the conjugate sign and discarding w:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float3 ReconstructTranslation(float4 Qr, float4 Qd)
{
    return 2 * (Qr.w * Qd.xyz - Qd.w * Qr.xyz + cross(Qd.xyz, Qr.xyz));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using the Conjugate and Multiply functions, it&amp;rsquo;s then easy to transform a position and vector by the quaternion rotation and reconstructed position:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float3 QuatRotateVector(float4 Qr, float3 v)
{
    // Straight-forward application of Q.v.Q&#39;, discarding w
    return Multiply(Multiply(Qr, float4(v, 0)), Conjugate(Qr)).xyz;
}

float3 DualQuatTransformPoint(float4 Qr, float4 Qd, float3 p)
{
    // Reconstruct translation from the dual quaternion
    float3 t = 2 * (Qr.w * Qd.xyz - Qd.w * Qr.xyz + cross(Qd.xyz, Qr.xyz));

    // Combine with rotation of the input point
    return QuatRotateVector(Qr, p) + t;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This leaves you with the final code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float2x4 skin_transform = BlendBoneTransforms(input.bone_indices, input.bone_weights);
float3 pos = DualQuatTransformPoint(skin_transform[0], skin_transform[1], input.pos);
float3 normal = QuatRotateVector(skin_transform[0], input.normal);
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;optimising-the-vertex-transformation:f775451b420ca7b05862adf0dcf3e408&#34;&gt;Optimising the Vertex Transformation&lt;/h5&gt;

&lt;p&gt;There&amp;rsquo;s a bit of redundancy in the transformation code above; results being thrown away and inputs being used when they could be discarded. There are also some identities we can apply to the rotation equation that can simplify it. As it stands, reconstruction of the translation is good enough.&lt;/p&gt;

&lt;p&gt;Starting with &lt;code&gt;QuatRotateVector&lt;/code&gt;, we can already see that the first multiplication uses $w=0$, allowing us to construct a function which removes the necessary terms in its calculation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float4 MultiplyPure(float4 a, float3 b)
{
    return float4(a.w * b + cross(b, a.xyz), -dot(a.xyz, b));
}

float3 QuatRotateVector(float4 Qr, float3 v)
{
    return Multiply(MultiplyPure(Qr, v), Conjugate(Qr)).xyz;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The final redundancy is that we&amp;rsquo;re calculating w and throwing it away, leading to:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float3 MultiplyConjugate3(float4 a, float4 b)
{
    return b.w * a.xyz - a.w * b.xyz - cross(b.xyz, a.xyz);
}
float3 QuatRotateVector(float4 Qr, float3 v)
{
    return MultiplyConjugate3(MultiplyPure(Qr, v), Qr);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Realistically, the shader compiler should be able to handle all that for you. However, it gives us a good starting point to take this further.&lt;/p&gt;

&lt;h5 id=&#34;we-can-do-better-than-that:f775451b420ca7b05862adf0dcf3e408&#34;&gt;We can do better than that&lt;/h5&gt;

&lt;p&gt;Let&amp;rsquo;s try to explode the transformation and bring it back to something far simpler. I&amp;rsquo;ll work through the steps I took in simplifying this explicitly - it serves as a nice record for me and will hopefully help if you&amp;rsquo;re trying to understand where the final result came from (I was always losing signs during my school days - I&amp;rsquo;m no better 15 years on!)&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re trying to simplify:&lt;/p&gt;

&lt;p&gt;$$P_r = Q*(0,V)*Q&amp;rsquo;$$&lt;/p&gt;

&lt;p&gt;This is a sequence of two quaternion multiplies. Again, quaternion multiplication is defined as:&lt;/p&gt;

&lt;p&gt;$$Q_0 Q_1 = (w_0 w_1 - V_0 \cdot V_1, w_0 V_1 + w_1 V_0 + V_0 \times V_1)$$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s make a few quick substitutions:&lt;/p&gt;

&lt;p&gt;$$R = Q.xyz \\ w = Q.w$$&lt;/p&gt;

&lt;p&gt;Expand $Q*(0,V)$ first:&lt;/p&gt;

&lt;p&gt;$$P_r = (-R \cdot V + wV + R \times V)(w - R)$$&lt;/p&gt;

&lt;p&gt;Expand the second multiplication:&lt;/p&gt;

&lt;p&gt;$$P_r = -R \cdot Vw + (wV + R \times V) \cdot R + (R \cdot V)R + w(wV + R \times V) - (wV + R \times V) \times R$$&lt;/p&gt;

&lt;p&gt;The dot product distributes over addition so distribute them all:&lt;/p&gt;

&lt;p&gt;$$P_r = -R \cdot Vw + wV \cdot R + R \times V \cdot R + (R \cdot V)R + + w^2V + wR \times V - (wV + R \times V) \times R$$&lt;/p&gt;

&lt;p&gt;The first two terms cancel as the dot product is commutative:&lt;/p&gt;

&lt;p&gt;$$P_r = R \times V \cdot R + (R \cdot V)R + w^2V + wR \times V - (wV + R \times V) \times R$$&lt;/p&gt;

&lt;p&gt;Using the identity $A \times B=-B \times A$ swap the last cross product around:&lt;/p&gt;

&lt;p&gt;$$P_r = R \times V \cdot R + (R \cdot V)R + w^2V + wR \times V + R \times (wV + R \times V)$$&lt;/p&gt;

&lt;p&gt;The cross product distributes over addition so distribute the last cross product:&lt;/p&gt;

&lt;p&gt;$$P_r = R \times V \cdot R + (R \cdot V)R + w^2V + wR \times V + R \times wV + R \times (R \times V)$$&lt;/p&gt;

&lt;p&gt;As we&amp;rsquo;re only interested in the &lt;code&gt;xyz&lt;/code&gt; components of the result, discard all scalar terms:&lt;/p&gt;

&lt;p&gt;$$P_r = (R \cdot V)R + w^2V + wR \times V + R \times wV + R \times (R \times V)$$&lt;/p&gt;

&lt;p&gt;Pull the scalar out of $R \times wV$ and sum with its neighbour:&lt;/p&gt;

&lt;p&gt;$$P_r = (R \cdot V)R + w^2V + wR \times V + wR \times V + R \times (R \times V)$$
$$P_r = (R \cdot V)R + w^2V + 2wR \times V + R \times (R \times V)$$&lt;/p&gt;

&lt;p&gt;The next bit requires knowledge of the &lt;a href=&#34;http://en.wikipedia.org/wiki/Triple_product#Vector_triple_product&#34;&gt;vector triple product&lt;/a&gt; (or Lagrange&amp;rsquo;s formula - of many). This takes the form:&lt;/p&gt;

&lt;p&gt;$$R \times (R \times V) = (R \cdot V)R - (R \cdot R)V$$&lt;/p&gt;

&lt;p&gt;If we rearrange that to equal zero then we can add that to the end of our existing equation and play around with it a little:&lt;/p&gt;

&lt;p&gt;$$R \times (R \times V) - (R \cdot V)R + (R \cdot R)V = 0$$
$$P_r = (R \cdot V)R + w^2V + 2wR \times V + R \times (R \times V) + R \times (R \times V) - (R \cdot V)R + (R \cdot R)V$$
$$P_r = (R \cdot V)R + w^2V + 2wR \times V + 2R \times (R \times V) - (R \cdot V)R + (R \cdot R)V$$&lt;/p&gt;

&lt;p&gt;The $(R \cdot V)R$ terms cancel:&lt;/p&gt;

&lt;p&gt;$$P_r = w^2V + 2wR \times V + 2R \times (R \times V) + (R \cdot R)V$$&lt;/p&gt;

&lt;p&gt;We can now factor the scale of $V$:&lt;/p&gt;

&lt;p&gt;$$P_r = w^2V  + (R \cdot R)V+ 2wR \times V + 2R \times (R \times V)$$
$$P_r = (w^2  + R \cdot R)V+ 2wR \times V + 2R \times (R \times V)$$&lt;/p&gt;

&lt;p&gt;The quaternion norm operation is given by:&lt;/p&gt;

&lt;p&gt;$$norm(q) = q_w q_w + q_x q_x + q_y q_y + q_z q_z$$&lt;/p&gt;

&lt;p&gt;Assuming we&amp;rsquo;re dealing with unit quaternions, the norm will always be 1. Looking above, we can see the norm right at the beginning and can get rid of it:&lt;/p&gt;

&lt;p&gt;$$P_r = V+ 2wR \times V + 2R \times (R \times V)$$&lt;/p&gt;

&lt;p&gt;Finally, factor the 2:&lt;/p&gt;

&lt;p&gt;$$P_r = V+ 2(wR \times V + R \times (R \times V))$$&lt;/p&gt;

&lt;p&gt;And factor the cross product:&lt;/p&gt;

&lt;p&gt;$$P_r = V+ 2(R \times (wV + R \times V))$$&lt;/p&gt;

&lt;p&gt;This is a delightfully simple result! The HLSL code is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float3 QuatRotateVector(float4 Qr, float3 v)
{
    return v + 2 * cross(Qr.w * v + cross(v, Qr.xyz), Qr.xyz);
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Reflection in C&#43;&#43;, Part2: The Simple Implementation of Splinter Cell</title>
      <link>http://donw.io/post/reflection-cpp-2/</link>
      <pubDate>Tue, 03 Jan 2012 07:21:58 +0100</pubDate>
      
      <guid>http://donw.io/post/reflection-cpp-2/</guid>
      <description>

&lt;p&gt;The &lt;a href=&#34;http://donw.io/post/reflection-cpp-1&#34;&gt;first part&lt;/a&gt; in this series on Reflection in C++ gave a high level overview of many of the possibilities open to you when adding reflection to your games. In this second part I&amp;rsquo;m going to go into details and cover the system used to aid the rendering engine in &lt;a href=&#34;http://store.steampowered.com/app/33229/&#34;&gt;Splinter Cell: Conviction&lt;/a&gt; (SC5).&lt;/p&gt;

&lt;p&gt;The motivation for the development of the SC5 engine was a clean break from the past. We were working with a very, very large code base that used Unreal 2.5 with many years of modifications and rewrites. While immensely stable, visually very good looking and a code base you could bet a few million dollars on, it slowed the development of new techniques required to push the SC franchise onto the next generation of consoles (the XBox 360, circa 2005).&lt;/p&gt;

&lt;p&gt;Compile times were painfully slow, link times were in the order of minutes and it suffered from the classic Unreal issue of requiring huge rebuilds whenever you changed a .uc script file (used to define your interfaces to the editor, among other things - partially solved in UE3, removed in UE4). There were many levels of pipeline and engine indirection added to ship titles that were slowing down the iteration and development of new techniques, simultaneously contributing to a lack of runtime performance on the target platform. After a couple of months of starting a new engine from scratch, we were at a few seconds for compile/link on the PC, sub-1 second single file iteration times, vastly simpler/faster import pipelines, multi-threaded performance that was orders of magnitude faster on the Xbox 360 than the old engine, the ability to live edit C++ rendering code and no compile dependency on Unreal.&lt;/p&gt;

&lt;p&gt;As a result we lost a few key technologies along the way that would have helped immensely, such as the ability to carve indoor space up using BSP volumes. We also ended up recreating some already existing features such as light channels and skeletal attachments. But the full story is something for another day and Stephen Hill&amp;rsquo;s fantastic GDC 2010 piece on the development of some of the rendering technologies can give a bit more insight (&lt;a href=&#34;http://blog.selfshadow.com/publications/&#34;&gt;Rendering with Conviction&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;This post will cover just the reflection API developed to replace Unreal&amp;rsquo;s object model. The implementation was very simple, written in a couple of days, constrained to a single cpp/h file pair and slowly grew as the needs of the engine evolved. It also helped us develop the new engine while the old engine was still active, supporting 50+ developers and keeping game progress undisturbed. It is my hope that I can demonstrate how simple (and sometimes naive) solutions can help ship great games, as long as you&amp;rsquo;re willing to rub shoulders with some pretty big limitations.&lt;/p&gt;

&lt;p&gt;An example of this system is &lt;a href=&#34;https://bitbucket.org/dwilliamson/reflectabit/overview&#34;&gt;Reflectabit&lt;/a&gt;, written a few years ago in my spare time. It&amp;rsquo;s unfinished but contains enough to serve as a tutorial of sorts. This post is from memory as I don&amp;rsquo;t have the code to hand anymore.&lt;/p&gt;

&lt;h5 id=&#34;the-type-id:34d857f412ffe3c047d6213141bf474b&#34;&gt;The Type ID&lt;/h5&gt;

&lt;p&gt;The first task in any reflection API is defining what a type ID is: how can you reference types in code? For SC5 we needed a type ID that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Could reference built-in types (&lt;code&gt;int&lt;/code&gt;, &lt;code&gt;char&lt;/code&gt;, etc) as well as custom class types.&lt;/li&gt;
&lt;li&gt;Was unique for each type.&lt;/li&gt;
&lt;li&gt;Was persistent between program invocations.&lt;/li&gt;
&lt;li&gt;Could be used for serialisation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The simplest of solutions is to use an enum:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;enum TypeID
{
    TYPE_INT,
    TYPE_CHAR,
    TYPE_MYTYPE,
    // ...
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each time you add a new type, you add it to the end of the enum. This needs a means of mapping a C++ type to its enum:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Each reflected type must specialise this
template &amp;lt;typename TYPE&amp;gt;
inline TypeID GetTypeID()
{
    // Compile-time assert: Type not implemented (avoiding a return value is enough, really)
};

// Specialisation examples
inline template &amp;lt;&amp;gt; TypeID GetTypeID&amp;lt;int&amp;gt;() { return TYPE_INT; }
inline template &amp;lt;&amp;gt; TypeID GetTypeID&amp;lt;char&amp;gt;() { return TYPE_CHAR; }
inline template &amp;lt;&amp;gt; TypeID GetTypeID&amp;lt;MyType&amp;gt;() { return TYPE_MYTYPE; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is not particularly extensible or maintainable in larger projects: if you&amp;rsquo;re working on a changelist that adds a new type and you are using it for serialisation, any incoming changes from members of your own team have the potential to clobber all your data and make the act of submission a chore that is potentially very dangerous. Type IDs will accrue over time and you must ensure that types are added at the end of the list. It&amp;rsquo;s not suitable for a reflection API that ships as part of a 3rd party library that expects its client code to add its own type, although there are many examples of such systems in decades old code (&lt;a href=&#34;http://msdn.microsoft.com/en-us/library/windows/desktop/ms644930.aspx&#34;&gt;WM_APP&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;One good benefit of this method is that you can immediately see the type name in a debugger when inspecting values of type &lt;code&gt;TypeID&lt;/code&gt;. However, you can&amp;rsquo;t see them at runtime unless you add a means of also mapping the enum value to a string. Of course, there are ways to do this, for example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// ----- TypeIDs.inc ------------------

// List all Type IDs
TYPEID(TYPE_INT)
TYPEID(TYPE_CHAR)
TYPEID(TYPE_MYTYPE)

// ----- TypeIDs.h --------------------

// Build the enum table
#define TYPEID(type) type,
enum TypeID
{
    #include &amp;quot;TypeIDs.inc&amp;quot;
};

// Use the pre-processor &amp;quot;stringiser&amp;quot; operator to specify the name of each name
#undef TYPEID
#define TYPEID(type) #type,
const char* g_TypeNames[] =
{
    #include &amp;quot;TypeIDs.inc&amp;quot;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is a well-used technique in many shipping C/C++ products where its variants have been branded &lt;a href=&#34;http://drdobbs.com/184401387&#34;&gt;X Macros&lt;/a&gt;. At this point it&amp;rsquo;s all getting a bit messy/overkill; we ruled it out on SC5 without much thought as there was a much simpler solution:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Each reflected type must specialise this
template &amp;lt;typename TYPE&amp;gt;
const char* GetTypeName()
{
    // Compile-time assert: Type not implemented
}

// Specialisation examples
inline template &amp;lt;&amp;gt; const char* GetTypeName&amp;lt;int&amp;gt;() { return &amp;quot;int&amp;quot;; }
inline template &amp;lt;&amp;gt; const char* GetTypeName&amp;lt;char&amp;gt;() { return &amp;quot;char&amp;quot;; }
inline template &amp;lt;&amp;gt; const char* GetTypeName&amp;lt;MyType&amp;gt;() { return &amp;quot;MyType&amp;quot;; }

template &amp;lt;typename TYPE&amp;gt;
u32 GetTypeID()
{
    // Calculates the string hash once and then caches it for further use
    static int type_id = CalcStringHash(GetTypeName&amp;lt;TYPE&amp;gt;());
    return type_id;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As long as your hash function is good this is a great way of defining your type ID support:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Practically, you are guaranteed unique, persistent IDs as long as your typenames are unique (you can prefix namespaces if you like).&lt;/li&gt;
&lt;li&gt;Types can be added in isolation; all you need to do is implement your &lt;code&gt;GetTypeName&lt;/code&gt; alongside its type in a header file.&lt;/li&gt;
&lt;li&gt;The type names are readily available in the debugger and are part of your executable.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The choice of hash function is important but don&amp;rsquo;t overthink the issue. SC5 used &lt;a href=&#34;http://www.greenend.org.uk/rjk/2004/crc.html&#34;&gt;CRC32&lt;/a&gt; for both type names and object names but this is technically not the purpose of CRC32 (it&amp;rsquo;s a trivial method of error detection in data packets). We used it for hashing of both type and object names and while I was working on the project we had one hash collision with some materials that was easily sorted with a rename (collisions were tracked offline in a MySQL database). These days I use &lt;a href=&#34;https://sites.google.com/site/murmurhash/&#34;&gt;MurmurHash3&lt;/a&gt;, however &lt;a href=&#34;http://www.cse.yorku.ca/~oz/hash.html&#34;&gt;DJB2&lt;/a&gt; is a nice simple implementation and the field is steadily progressing (e.g. see &lt;a href=&#34;https://github.com/google/cityhash&#34;&gt;CityHash&lt;/a&gt;). Whatever you choose, collision visibility is essential as collisions can cause very subtle data integrity issues.&lt;/p&gt;

&lt;p&gt;Before going any further, a small review of some other methods of generating a type ID may be of interest.&lt;/p&gt;

&lt;p&gt;The first is to use C++ RTTI to replace &lt;code&gt;GetTypeName&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;template &amp;lt;typename TYPE&amp;gt;
const char* GetTypeName()
{
    return typeid(TYPE).name();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that this is not using any runtime aspects of C++ RTTI support beyond calling a function in the &lt;a href=&#34;http://www.cplusplus.com/reference/std/typeinfo/type_info/&#34;&gt;type_info&lt;/a&gt; object returned, which needs to store its information somewhere in memory. Technically this means you should not be penalised for its use at runtime (it doesn&amp;rsquo;t alter the size of any of your objects) but I&amp;rsquo;ve only tested this on MSVC platforms. This is a remarkably simple solution that doesn&amp;rsquo;t require you to specialise &lt;code&gt;GetTypeName&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;One issue you can encounter is that RTTI is a very loosely standardised feature of C++ and different platforms may return different names for each type. I believe GCC &lt;a href=&#34;http://stackoverflow.com/questions/281818/unmangling-the-result-of-stdtype-infoname&#34;&gt;mangles the result in some way&lt;/a&gt;, although none of these issues are insurmountable. Curiously, if you disable RTTI in an MSVC project, typeid still works, demonstrating the theory of no runtime penalty. However, other compilers such as GCC fail to compile.&lt;/p&gt;

&lt;p&gt;Another potentially non-standard side-step involves the use of the pre-defined &lt;a href=&#34;https://msdn.microsoft.com/en-us/library/b0084kay.aspx&#34;&gt;&lt;strong&gt;FUNCTION&lt;/strong&gt;&lt;/a&gt; identifier, &lt;a href=&#34;https://msdn.microsoft.com/en-us/library/dn919276.aspx&#34;&gt;&lt;strong&gt;func&lt;/strong&gt;&lt;/a&gt; (C99/C++11) or whatever equivalent your compiler most likely has these days:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;template &amp;lt;typename TYPE&amp;gt;
const char* GetTypeName()
{
    // GCC&#39;s equivalent is __PRETTY_FUNCTION__
    return __FUNCSIG__;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is MSVC-specific but the output is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;const char *__cdecl GetTypeName&amp;lt;struct MyType&amp;gt;(void)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;An important realisation is that this string is unique if your type name is unique so you don&amp;rsquo;t really need to change it. If that bothers you, however, you can do a quick parse of the string and cache it locally in a static char buffer, or similar.&lt;/p&gt;

&lt;h5 id=&#34;types-in-memory:34d857f412ffe3c047d6213141bf474b&#34;&gt;Types in Memory&lt;/h5&gt;

&lt;p&gt;The next step is in defining how types are represented in memory, their dynamic retrieval and how they can be used to create objects of that type. This involved a few structures:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Used for both type names and object names
struct Name
{
    unsigned int hash;
    const char* text;
};

// Function types for the constructor and destructor of registered types
typedef void (*ConstructObjectFunc)(void*);
typedef void (*DestructObjectFunc)(void*);

// The basic type representation
struct Type
{
    // Parent type database
    class TypeDB* type_db;
    
    // Scoped C++ name of the type
    Name name;
    
    // Pointers to the constructor and destructor functions
    ConstructObjectFunc constructor;
    DestructObjectFunc destructor;
    
    // Result of sizeof(type) operation
    size_t size;
};

// A big registry of all types in the game with methods to manipulate them
class TypeDB
{
public:
    // Example methods; implementations discussed later
    Type&amp;amp; CreateType(Name name);
    Type* GetType(Name name);
private:
    typedef std::map&amp;lt;Name, Type*&amp;gt; TypeMap;
    TypeMap m_Types;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We didn&amp;rsquo;t use the STL to define our types; I&amp;rsquo;m using it above to demonstrate intent.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;Name&lt;/code&gt; type always stored both the null-terminated string pointer and hash of that string. Type names were always present, stored in a read-only segment of memory when the compiler encounters any calls to &lt;code&gt;GetTypeName&lt;/code&gt;. Object names were never stored in memory. Instead, they were stored in a MySQL database which was queried by a Visual Studio debugger plugin whenever it wanted to display a name in the watch window. This was a great way of always having object names present in console builds without consuming runtime memory, even in our most final release builds.&lt;/p&gt;

&lt;p&gt;Types are created dynamically as part of game initialisation and a simple implementation of &lt;code&gt;CreateType&lt;/code&gt; would be:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;template &amp;lt;typename TYPE&amp;gt;
Type&amp;amp; CreateType(Name name)
{
    // Only allocate the type once (GetType will call CreateType if the type doesn&#39;t exist)
    Type* type = 0;
    TypeMap::iterator type_i = m_Types.find(name);
    if (type_i == m_Types.end())
    {
        type = new Type;
        m_Types[name] = type;
    }
    else
    {
        type = i-&amp;gt;second;
    }
    
    // Apply type properties
    type-&amp;gt;type_db = this;
    type-&amp;gt;name = name;
    type-&amp;gt;size = sizeof(TYPE);
    return *type;
}

// Example registration on initialisation
TypeDB db;
db.CreateType&amp;lt;MyType&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This gives enough information to be able to allocate space for objects of a given type, however a means of constructing/destructing that object has yet to be defined. In C++ you can&amp;rsquo;t create function pointers to the constructor or destructor (see C++98 12.1 for more info) but given a memory address, they can be called:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;template &amp;lt;typename TYPE&amp;gt; void ConstructObject(void* object)
{
    // Use placement new to call the constructor
    new (object) TYPE;
}
template &amp;lt;typename TYPE&amp;gt; void DestructObject(void* object)
{
    // Explicit call of the destructor
    ((TYPE*)object)-&amp;gt;TYPE::~TYPE();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This now allows &lt;code&gt;CreateType&lt;/code&gt; to fully define &lt;code&gt;Type&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;template &amp;lt;typename TYPE&amp;gt;
Type* CreateType(NAME name)
{
    // ... alloc type ...
    
    // Apply type properties
    type-&amp;gt;size = sizeof(TYPE);
    type-&amp;gt;constructor = ConstructObject&amp;lt;TYPE&amp;gt;;
    type-&amp;gt;destructor = DestructObject&amp;lt;TYPE&amp;gt;;
    return *type;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is enough information to dynamically create objects of a given type, which will be discussed later. Finally, the default type database needs to register all C++ types that were supported in its constructor:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;TypeDB::TypeDB()
{
    CreateType&amp;lt;char&amp;gt;();
    CreateType&amp;lt;short&amp;gt;();
    CreateType&amp;lt;int&amp;gt;();
    CreateType&amp;lt;float&amp;gt;();
    // ... and so on ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;fields:34d857f412ffe3c047d6213141bf474b&#34;&gt;Fields&lt;/h5&gt;

&lt;p&gt;Each type contains an array of fields that describe it - called a &lt;code&gt;PropertyInfo&lt;/code&gt; in SC5. We needed the field descriptions to be able to serialise and inspect any object, requiring the following structure:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct Field
{
    // C++ name of the field, unscoped
    Name name;
    
    // Name of the field type name and a pointer to its type
    Name type_name;
    Type* type;
    
    // Is this a pointer field? Note that this becomes a flag later on...
    bool is_pointer;
    
    // Offset of this field within the type
    size_t offset;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Only value and pointer field types were supported and the const-ness was irrelevant. We wanted a means of automatically generating the properties of a field to avoid manually-specified registration errors. A typical structure with the desired registration mechanism could look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct MyType
{
    int x;
    float y;
    char z;
    
    OtherType other;
    OtherType* other_ptr;
};

Field fields[] =
{
    Field(&amp;quot;x&amp;quot;, &amp;amp;MyType::x),
    Field(&amp;quot;y&amp;quot;, &amp;amp;MyType::y),
    Field(&amp;quot;z&amp;quot;, &amp;amp;MyType::z),
    Field(&amp;quot;other&amp;quot;, &amp;amp;MyType::other),
    Field(&amp;quot;other_ptr&amp;quot;, &amp;amp;MyType::other_ptr)
};

// Create the type and specify its fields
TypeDB db;
db.CreateType&amp;lt;MyType&amp;gt;().Fields(fields);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Of course, while the properties of a field are automatically deduced, the specification of what fields comprise a type is manual. This caused a few errors along the way on our small team and it was thought that the effort involved trying to minimise this wasn&amp;rsquo;t a priority.&lt;/p&gt;

&lt;p&gt;Note that the field for &lt;code&gt;OtherType&lt;/code&gt; is created before &lt;code&gt;OtherType&lt;/code&gt; is potentially created. To offset the need to register types in any specific order, any calls to &lt;code&gt;GetType&lt;/code&gt; would allocate the type if it didn&amp;rsquo;t already exist. Subsequent calls to &lt;code&gt;CreateType&lt;/code&gt; would retrieve the allocated copy and describe it.&lt;/p&gt;

&lt;p&gt;Note also that the field name is manually specified, which is another potential source of user error. Instead, we could have used the pre-processor stringising operator to ensure it was in sync. Again, this wasn&amp;rsquo;t considered important and at the time and I didn&amp;rsquo;t fancy adding extra layers with pre-processor macros. I did start playing around this a couple of years ago and some investigative results can be found in &lt;a href=&#34;https://bitbucket.org/dwilliamson/reflectabit/src/tip/Test/TestSerialisation.cpp&#34;&gt;Reflectabit&amp;rsquo;s serialisation tests&lt;/a&gt;. I still prefer the manual solution, however.&lt;/p&gt;

&lt;p&gt;Implementing the Field constructor requires answering three questions at compile-time:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What type is the field?&lt;/li&gt;
&lt;li&gt;Is it a pointer?&lt;/li&gt;
&lt;li&gt;What is the field offset?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This required two utility functions that used &lt;a href=&#34;http://www.gotw.ca/gotw/049.htm&#34;&gt;partial template specialisation&lt;/a&gt; on the type qualifiers to identify a pointer and also strip a pointer from the type:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Does a type specification contain a pointer?
template &amp;lt;typename TYPE&amp;gt;
struct IsPointer
{
    static bool val = false;
};
// Specialise for yes
template &amp;lt;typename TYPE&amp;gt;
struct IsPointer&amp;lt;TYPE*&amp;gt;
{
    static bool val = true;
};

// Exactly the same, except the result is the type without the pointer
template &amp;lt;typename TYPE&amp;gt;
struct StripPointer
{
    typedef TYPE Type;
};
// Specialise for yes
template &amp;lt;typename TYPE&amp;gt;
struct StripPointer&amp;lt;TYPE*&amp;gt;
{
    typedef TYPE Type;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It also required the use of the &lt;a href=&#34;http://www.cplusplus.com/reference/clibrary/cstddef/offsetof/&#34;&gt;offsetof&lt;/a&gt; macro, making the assumption that we never use virtual or multiple inheritance (we didn&amp;rsquo;t). With these tools, the &lt;code&gt;Field&lt;/code&gt; constructor is quite simple:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct Field
{
    template &amp;lt;typename OBJECT_TYPE, typename FIELD_TYPE&amp;gt;
    Field(Name name, FIELD_TYPE OBJECT_TYPE::*field)
        : name(name)
        
        // Store the type name as we don&#39;t have an owning type database yet
        , type_name(GetTypeName&amp;lt; StripPointer&amp;lt;FIELD_TYPE&amp;gt;::Type &amp;gt;())
        , type(0)
        
        , is_pointer(IsPointer&amp;lt;FIELD_TYPE&amp;gt;::val)
        , offset(offsetof(OBJECT_TYPE, *field))
    {
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;Fields&lt;/code&gt; method in &lt;code&gt;Type&lt;/code&gt; uses the &lt;a href=&#34;http://www.parashift.com/c++-faq-lite/ctors.html#faq-10.20&#34;&gt;Named Parameter Idiom&lt;/a&gt; to assign a field list to a type. This technique is used pretty frequently to make registration as friendly as possible. Fields is implemented using templates to figure out the size of the C array:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct Type
{
    template &amp;lt;int SIZE&amp;gt;
    Type&amp;amp; Fields(Field (&amp;amp;init_fields)[SIZE])
    {
        for (int i = 0; i &amp;lt; SIZE; i++)
        {
            Field f = init_fields[i];
            
            // Assign the type pointer using the parent type database and add to the type&#39;s field list
            f.type = type_db-&amp;gt;GetType(f.type_name);
            fields.push_back(f);
        }
        return *type;
    }
    
    // New vector of fields for this type
    std::vector&amp;lt;Field&amp;gt; fields;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;inheritance:34d857f412ffe3c047d6213141bf474b&#34;&gt;Inheritance&lt;/h5&gt;

&lt;p&gt;All registered types could only have one base class and fields declared within that type only existed in the fields array of that type (i.e. the fields within an inheritance hierarchy weren&amp;rsquo;t merged). Registering a base class was done with another method in &lt;code&gt;Type&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct Type
{
    template &amp;lt;typename TYPE&amp;gt;
    Type&amp;amp; Base()
    {
        base = type_db-&amp;gt;GetType(GetTypeName&amp;lt;TYPE&amp;gt;());
    }
    
    Type* base_type;
};

// Example registration
TypeDB db;
db.CreateType&amp;lt;SomeType&amp;gt;().Base&amp;lt;ItsBaseType&amp;gt;();
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;enumerations:34d857f412ffe3c047d6213141bf474b&#34;&gt;Enumerations&lt;/h5&gt;

&lt;p&gt;Similar to what was described in part 1 of this series, enumeration constants were simply a name/value pair:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct EnumConst
{
    EnumConst(Name name, int value) : name(name), value(value) { }
    Name name;
    int value;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, in an attempt to keep the API simple and avoid any inheritance trees, there was no enumeration type. Instead, each type had a list of enum constants which would be empty if the type was not an enumeration:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct Type
{
    template &amp;lt;int SIZE&amp;gt;
    Type&amp;amp; EnumConstants(EnumConst (&amp;amp;input_enum_consts)[SIZE])
    {
        for (int i = 0; i &amp;lt; SIZE; i++)
            enum_constants.push_back(input_enum_consts[i]);
    }
    
    // Only used if the type is an enum type
    std::vector&amp;lt;EnumConst&amp;gt; enum_constants;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Registering of enumeration constants then became as easy as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;enum TestEnumType
{
    VAL_A, VAL_B, VAL_C
};

// Collate the enum constants
EnumConst enum_consts[] =
{
    EnumConst(&amp;quot;VAL_A&amp;quot;, VAL_A),
    EnumConst(&amp;quot;VAL_B&amp;quot;, VAL_B),
    EnumConst(&amp;quot;VAL_C&amp;quot;, VAL_C),
};

// Create the enum type
TypeDB db;
db.CreateType&amp;lt;TestEnumType&amp;gt;().EnumConstants(enum_consts);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Again, this relies upon manual registration of any enumeration constants you have and can be error-prone if you forget to add a constant or incorrectly name it. I can&amp;rsquo;t recall this causing us any issues but the potential for making mistakes was there. We were careful and determined that going any further would not be a good investment of our time.&lt;/p&gt;

&lt;h5 id=&#34;attributes:34d857f412ffe3c047d6213141bf474b&#34;&gt;Attributes&lt;/h5&gt;

&lt;p&gt;Attribute systems can get pretty complicated but we wanted something quick and simple that could be improved at a later date if necessary. We pretty much knew from the outset what attributes we would require so each field was extended to contain:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct Field
{
    Field&amp;amp; Flags(unsigned int f)
    {
        flags = f;
        return *this;
    }
    
    Field&amp;amp; Desc(const char* desc)
    {
        description = desc;
        return *this;
    }
    
    Field&amp;amp; Group(const char* g)
    {
        group = g;
        return *this;
    }
    
    // An ORing of boolean attributes and a version number (explained later)
    unsigned int flags;
    
    // An optional property description for editors
    Name description;
    
    // An optional user interface grouping node name for editors
    Name group;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These are entirely hard-coded attributes that the reflection system defines. There are only two string attributes: &lt;code&gt;description&lt;/code&gt; and &lt;code&gt;group&lt;/code&gt;, that are used for user interface population. If you&amp;rsquo;re defining a material type then you can group its properties into (for example) &amp;ldquo;Textures&amp;rdquo; and &amp;ldquo;Lighting&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;The rest of the attributes were boolean flags, merged into the single flags field. Some examples are:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;enum Flags
{
    // Is this field a pointer type? (replacing the is_pointer bool in Field)
    F_Pointer = 0x01,
    
    // Is this a transient field, ignored during serialisation?
    F_Transient = 0x02,
    
    // Is this a network transient field, ignored during network serialisation?
    // A good example for this use-case is a texture type which contains a description
    // and its data. For disk serialisation you want to save everything, for network
    // serialisation you don&#39;t really want to send over all the texture data.
    F_NetworkTransient = 0x04,
    
    // Can this field be edited by tools?
    F_ReadOnly = 0x08,
    
    // Is this a simple type that can be serialised in terms of a memcpy?
    // Examples include int, float, any vector types or larger types that you&#39;re not
    // worried about versioning.
    F_SimpleType = 0x10,
    
    // Set if the field owns the memory it points to.
    // Any loading code must allocate it before populating it with data.
    F_OwningPointer = 0x20
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As evident, you could only add new boolean attributes if there were flag bits left and adding attributes with more complexity required extending &lt;code&gt;Field&lt;/code&gt;. Perfect for our use-case but not ideal for a more general system.&lt;/p&gt;

&lt;h5 id=&#34;containers:34d857f412ffe3c047d6213141bf474b&#34;&gt;Containers&lt;/h5&gt;

&lt;p&gt;Our container support was very primitive, similar to the &lt;a href=&#34;https://bitbucket.org/dwilliamson/reflectabit/src/tip/inc/rflb/Container.h&#34;&gt;container support in Reflectabit&lt;/a&gt; but lacking its completeness. The basic premise was to use an interface pointer to an underlying container wrapper, like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct IContainer
{
    virtual int GetCount() = 0;
    virtual void* GetValue(void* container, int index) = 0;
    // ...etc...
};

// An example container implementation for std::vector
template &amp;lt;typename TYPE&amp;gt;
struct VectorContainer
{
    int GetCount()
    {
        return ((std::vector&amp;lt;TYPE&amp;gt;*)container)-&amp;gt;size();
    }
    void* GetValue(void* container, int index)
    {
        return &amp;amp;((std::vector&amp;lt;TYPE&amp;gt;*)container)-&amp;gt;at(index);
    }
};

struct Field
{
    // The first constructor, specified above
    Field(// ...
    
    // An overload for std::vector container fields
    template &amp;lt;typename OBJECT_TYPE, typename FIELD_TYPE&amp;gt;
    Field(Name name, std::vector&amp;lt;FIELD_TYPE&amp;gt; OBJECT_TYPE::*field)
        : name(name)
        , type_name(GetTypeName&amp;lt; StripPointer&amp;lt;FIELD_TYPE&amp;gt;::Type &amp;gt;())
        , type(0)
        , is_pointer(IsPointer&amp;lt;FIELD_TYPE&amp;gt;::val)
        , offset(offsetof(OBJECT_TYPE, *field))
    {
        // Allocate the implementation
        container = new VectorContainer&amp;lt;TYPE&amp;gt;();
    }
    
    IContainer* container;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is more information on the technique in part 1 of this series. Again, we didn&amp;rsquo;t use any STL code, opting for our own custom containers, so the above is just an example to highlight how it was achieved. For each field container type, the compiler will generate all of the necessary code to access/mutate the containers which are controlled through the container interface. It&amp;rsquo;s not ideal in terms of generated code size but it&amp;rsquo;s simple and it works well enough.&lt;/p&gt;

&lt;h5 id=&#34;working-with-objects:34d857f412ffe3c047d6213141bf474b&#34;&gt;Working with objects&lt;/h5&gt;

&lt;p&gt;We had the luxury of not having to create a controlling object model as Unreal&amp;rsquo;s package system was already doing a good enough job. As a result, all of our objects were anonymously contained by an equivalent &lt;code&gt;UObject&lt;/code&gt; and we merely had a resource database that mapped object names to their instances:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// The base object type for root-serialisable objects
struct Object
{
    // Called after post-load or any UI modified properties, allowing the internal
    // representation to update itself
    virtual void OnChanged() = 0;
    
    Name name;
    Type* type;
};

class ResourceDB
{
public:
    // Fundamental object management methods
    Object* CreateObject(Name name, Type* type);
    void DestroyObject(Object* object);
    
    // Helper for retrieving the type and applying the appropriate cast
    template &amp;lt;typename TYPE&amp;gt;
    TYPE* CreateObject(Name name)
    {
        return (TYPE*)CreateObject(name, m_TypeDB-&amp;gt;GetType(GetTypeName&amp;lt;TYPE&amp;gt;()));
    }
    
    Object* GetObject(Name name);
    
private:
    TypeDB* m_TypeDB;

    // Map of all objects
    typedef std::map&amp;lt;Name, Object*&amp;gt; ObjectMap;
    ObjectMap m_Objects;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;CreateObject&lt;/code&gt; was used everywhere: from serialisation to networked object creation. It used the description of whatever type was being created to safely construct whatever you needed:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;Object* ResourceDB::CreateObject(Name name, Type* type)
{
    // Allocate enough space for the object and call its constructor
    Object* object = (Object*)malloc(type-&amp;gt;size);
    type-&amp;gt;constructor(object);
    
    // Assign its properties
    object-&amp;gt;name = name;
    object-&amp;gt;type = type;
    return object;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This was paired with &lt;code&gt;DestroyObject&lt;/code&gt; and both replaced typical &lt;code&gt;new&lt;/code&gt;/&lt;code&gt;delete&lt;/code&gt; use:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void ResourceDB::DestroyObject(Object* object)
{
    // Call destructor and release memory
    object-&amp;gt;type-&amp;gt;destructor(object);
    free(object);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With a few helpers, you already can do some pretty funky things not normally possible with C++:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct Field
{
    // Helper to get a pointer to the field within an object
    void* GetPtr(void* object)
    {
        return (char*)object + offset;
    }
};

struct Type
{
    // A simple linear search looking for a field by name
    Field* GetField(const char* name)
    {
        for (size_t i = 0; i &amp;lt; fields.size(); i++)
        {
            // This is just a hash comparison
            if (Name(name) == fields[i]-&amp;gt;name)
                return fields[i];
        }
        
        // Recurse up through base type
        if (base_type)
            return base_type-&amp;gt;GetField(name);
            
        return 0;
    }
};

// Create an object using its type name
TypeDB db;
ResourceDB rdb;
MyType* mt = rdb.CreateObject(&amp;quot;objectname&amp;quot;, db.GetType(&amp;quot;MyType&amp;quot;));

// Assign a field within that object using its field name
Field* x = mt-&amp;gt;type-&amp;gt;GetField(&amp;quot;x&amp;quot;);
int* x_ptr = (int*)x-&amp;gt;GetPtr(mt);
*x_ptr = 3;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That covers the fundamentals, from which the rest of the code was built upon.&lt;/p&gt;

&lt;h5 id=&#34;serialisation:34d857f412ffe3c047d6213141bf474b&#34;&gt;Serialisation&lt;/h5&gt;

&lt;p&gt;We only supported one form of a serialisation and that was a versionable, binary IFF variant. Serialisation was only ever applied to a memory buffer that grew as more data was added to it. The chunk header was similar to:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct ChunkHeader
{
    // Hash of the field name to uniquely identify the chunk
    unsigned int name_hash;
    
    // Size of the data
    unsigned int size;
    
    // Type data when the field was serialised
    unsigned int type_name_hash;
    unsigned int type_flags;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unlike IFF, this uses the hash of the field name to uniquely identify a chunk. If the field didn&amp;rsquo;t exist, the data was skipped during load and not preserved. It also uses 8 bytes to carry a small description of the type of the field when it was serialised. This allowed us to change the type or attributes of a field and have the loading code skip over the data or convert it if any of those changed.&lt;/p&gt;

&lt;p&gt;The serialisation logic was very similar to that discussed in part 1 with some additions. Reflectabit&amp;rsquo;s &lt;a href=&#34;https://bitbucket.org/dwilliamson/reflectabit/src/tip/src/SerialiseBinary.cpp&#34;&gt;binary serialisation&lt;/a&gt; contains a simpler example of this.&lt;/p&gt;

&lt;p&gt;One minor feature was the ability to use masks to specify what fields would be serialised based on what attributes the field had set. This allowed the use of the same code path for serialising files on disk and network messages, described shortly.&lt;/p&gt;

&lt;p&gt;As we only supported one file format, custom loading and saving function pointers were attached to each field, keeping everything simple and fast:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;typedef void (*LoadFieldFunc)(Buffer&amp;amp; inbuf, unsigned int flags, void* object);
typedef void (*SaveFieldFunc)(Buffer&amp;amp; outbuf, unsigned int flags, void* object);

struct Field
{
    // additions to Field...
    
    Field&amp;amp; LoadSave(LoadFieldFunc load, SaveFieldFunc save)
    {
        load_field = load;
        save_field = save;
        return *this;
    }
    
    LoadFieldFunc load_field;
    SaveFieldFunc save_field;
};

// An example of texture type registration with custom load/save for the data

enum Format
{
    FMT_RGBA,
    // etc...
};

EnumConst format_enums[] =
{
    EnumConst(&amp;quot;FMT_RGBA&amp;quot;, FMT_RGBA),
};

struct Texture
{
    int width, height;
    Format format;
    IDirect3DTexture9* data;
};

Field texture_fields[] =
{
    Field(&amp;quot;width&amp;quot;, &amp;amp;Texture::width),
    Field(&amp;quot;height&amp;quot;, &amp;amp;Texture::height),
    Field(&amp;quot;format&amp;quot;, &amp;amp;Texture::format),
    Field(&amp;quot;data&amp;quot;, &amp;amp;Texture::data).LoadSave(LoadTextureData, SaveTextureData),
};

TypeDB db;
db.CreateType&amp;lt;Format&amp;gt;().EnumConstants(format_enums);
db.CreateType&amp;lt;Texture&amp;gt;().Base&amp;lt;Object&amp;gt;().Fields(texture_fields);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;data&lt;/code&gt; field above is a raw &lt;code&gt;IDirect3DTexture&lt;/code&gt; pointer. A version number was embedded in the field flags, occupying about 5 or 6 bits, I can&amp;rsquo;t recall which exactly. This allowed the loading code to skip version numbers it didn&amp;rsquo;t know how to load or, in the case of custom loading code, forward onto the appropriate loading code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void LoadTextureData2(Buffer&amp;amp; inbuf, unsigned int flags, void* object)
{       
    // Given the already known texture dimensions and format (serialised in order)
    // Create the D3D texture object
    Texture* texture = (Texture*)object;
    texture-&amp;gt;data = g_Resources-&amp;gt;CreateTexture(texture);
    
    // Lock the texture, copy the data into it, unlock
    LockRect r = texture-&amp;gt;Lock();
    memcpy(r.data, inbuf.MemBuf(), TexSizeBytes(texture));
    texture-&amp;gt;Unlock();
}

void LoadTextureData(Buffer&amp;amp; inbuf, unsigned int flags, void* object)
{
    // Dispatch to the correct loader
    unsigned int version = GetVersion(flags);
    switch (version)
    {
        case 1: LoadTextureData1(inbuf, flags, object); break;
        case 2: LoadTextureData2(inbuf, flags, object); break;
    }
}

void SaveTextureData2(Buffer&amp;amp; outbuf, unsigned int flags, void* object)
{
    // Lock the texture, read the data from it, unlock
    Texture* texture = (Texture*)object;
    LockRect r = texture-&amp;gt;Lock();
    outbuf.Write(r.data, TexSizeBytes(texture));
    texture-&amp;gt;Unlock();
}

void SaveTextureData(Buffer&amp;amp; outbuf, unsigned int flags, void* object)
{
    // Always save as the latest format
    SaveTextureData2(outbuf, flags, object);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The code above describes the texture loading code in its early state. Eventually, texture streaming was supported; at which point, the texture data was serialised on-demand and the reflection code was merely responsible for creating texture handles.&lt;/p&gt;

&lt;p&gt;Unreal performs version upgrades incrementally: it can load old file formats and when you save your package, it will be saved in the new format. Tools can be written which further automate this process. When it comes to serialising complicated data, Unreal&amp;rsquo;s solution is a single method within your object. Over time you prune old loading code as your compiled data catches up. We found that our modification to this process was more stable and easier to maintain.&lt;/p&gt;

&lt;p&gt;Pointers were serialised as the hash of the name of any object being pointed to. Because we didn&amp;rsquo;t control the order of loading (that was up to Unreal) we had to come up with ways of ensuring pointers to objects that weren&amp;rsquo;t yet created were satisfied. I think the solution we settled on was to create a proxy object using the type information embedded in the field chunk before actual object creation came along later and completed the creation. While this also handled the issue of circular references, it wasn&amp;rsquo;t a great solution, but it worked!&lt;/p&gt;

&lt;p&gt;After adding support for stream writing containers of PODs as an optimisation, bitfields and automatic endianness swapping, the serialisation didn&amp;rsquo;t change much and was a pretty straight-forward piece of code.&lt;/p&gt;

&lt;h5 id=&#34;the-network-server:34d857f412ffe3c047d6213141bf474b&#34;&gt;The Network Server&lt;/h5&gt;

&lt;p&gt;The engine had the ability to accept arbitrary TCP/IP connections while running on Windows or console, using Winsock. Again, the code was pretty minimal, just a bunch of socket, &lt;code&gt;bind&lt;/code&gt;, &lt;code&gt;accept&lt;/code&gt;, &lt;code&gt;send&lt;/code&gt;, &lt;code&gt;recv&lt;/code&gt; calls for dealing with anonymous chunks of data.&lt;/p&gt;

&lt;p&gt;The network server ran on the same thread as the engine, polling once a frame for any incoming connections or data. Obviously you don&amp;rsquo;t want to do this kind of thing for actual game network code but for development code it works superbly - don&amp;rsquo;t let any work-hungry programmers try to convince you otherwise.&lt;/p&gt;

&lt;p&gt;There was only one format of network message it could send and receive, but those messages were of arbitrary length and contained reflection-serialised data within them:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct MessageHeader
{
    unsigned int type_name_hash;
    unsigned int object_name_hash;
    unsigned int message_size;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There were two ways the network server could respond based on the contents of the Message type:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The network server had an internal map of event type names to handler functions. If the message type name matched anything in that map, the message data would be deserialised and passed onto the handler function.&lt;/li&gt;
&lt;li&gt;Failing that, the message would be interpreted as a full or partial object replication request. The message data would be deserialised and assigned to the requested object.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This was enough to allow tools written in C# to remotely interact with the game through a network socket, with the appropriate network and marshalling code written on the C# side:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;bool NetworkServer::ReceiveNextMessage()
{
    // Receive an entire message header before proceeding or leave if there are no more messages
    MessageHeader header;
    if (!m_Network-&amp;gt;Receive(&amp;amp;header, sizeof(header)))
        return false;
    
    // Read the message data into a memory buffer
    Buffer data(header.message_size);
    m_Network-&amp;gt;Receive(data.MemBuf(), header.message_size);
    
    // Get the message type, skipping the data if it can&#39;t be handled
    Type* message_type = m_TypeDB-&amp;gt;GetType(header.type_name_hash);
    if (message_type == 0)
        return true;
    
    // Is this an event being sent remotely?
    if (Event* event = m_Events.find(header.type_name_hash))
    {
        // Create an object of the event type and parse its data
        Object* object = m_ResourceDB-&amp;gt;CreateObject(header.type_name_hash);
        SerialiseLoadBinary(data, object);
        
        // Dispatch to the handler and destroy the message object
        event-&amp;gt;handler(object);
        m_ResourceDB-&amp;gt;DestroyObject(object);
        return true;
    }
    
    // This is an object replication request; need to get the object and serialise all or only
    // a few of its fields - at least, only those that are specified due to the binary IFF nature
    // of the serialisation code.
    Object* object = m_ResourceDB-&amp;gt;GetObject(header.object_name_hash);
    if (object)
        SerialiseLoadBinary(data, object);
    
    return true;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The network server could similarly send events and replication requests to remote machines if it needed to.&lt;/p&gt;

&lt;h5 id=&#34;c-tools-development:34d857f412ffe3c047d6213141bf474b&#34;&gt;C# Tools Development&lt;/h5&gt;

&lt;p&gt;Regardless of your wrapper of choice, developing tools in C/C++ can be quite painful. Microsoft managed to hit a sweet spot with with C#, .NET and Forms development that was very easy to use and not interminably slow and bloated. However, it did require the use of 3rd party libraries to get some truly useful/fast user interfaces to replace stuff like the woeful grid control. We used it to good effect, developing a few tools in C# that would communicate directly with the running game on either Windows or the console, such as:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A material editor.&lt;/li&gt;
&lt;li&gt;A sort-of &amp;ldquo;realtime PIX&amp;rdquo; profiling and debugging tool.&lt;/li&gt;
&lt;li&gt;A post-processing editor.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These were all small applications that existed outside the UnrealEd framework that, once launched, could connect to any running game and manipulate/read its state.&lt;/p&gt;

&lt;p&gt;The profiling tool is one example I can share. In real-time (every couple of ms), it updated all of its panels with performance info on the GPU and CPU  much of the information that PIX was providing back in 2006:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://donw.io/img/profiler.gif&#34; alt=&#34;Lead 3D Debug Client&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In order to achieve this, we needed a set of C# libraries that understood the C++ reflection API, its serialisation and its object model. Network communication was trivial and much easier than using Winsock on the C++ side - we just used &lt;a href=&#34;http://msdn.microsoft.com/en-us/library/system.net.sockets.aspx&#34;&gt;System.Net.Sockets&lt;/a&gt; to build the C# equivalent of the C++ NetworkServer.&lt;/p&gt;

&lt;p&gt;The C# clients and the C++ network server would communicate with messages that would be serialised either end. The steps involved in getting messages from C# to C++ were:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;All messages and their parameters were defined in C#.&lt;/li&gt;
&lt;li&gt;A separate C# tool would use &lt;a href=&#34;http://msdn.microsoft.com/en-us/library/system.reflection.aspx&#34;&gt;System.Reflection&lt;/a&gt; to walk the message types and automatically generate C++ code with the equivalent message structures, alongside their C++ reflection registration code.&lt;/li&gt;
&lt;li&gt;At runtime, marshalling code would use &lt;code&gt;System.Reflection&lt;/code&gt; to create messages of the requested type and serialise their parameters into an intermediate runtime object model.&lt;/li&gt;
&lt;li&gt;The intermediate representation would then be serialised to a byte stream that the C++ code could load (we only used the binary serialisation discussed above) and sent over the network.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;NetworkServer&lt;/code&gt; code would pick up the message and use the C++ reflection to create the message object and deserialise its contents.&lt;/li&gt;
&lt;li&gt;Several message handlers attached to &lt;code&gt;NetworkServer&lt;/code&gt; would pick up and respond to the messages using the message structures already defined.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While this covers how the two programs logically interacted with each other, it doesn&amp;rsquo;t explain how the C# tools could modify any object running live in the game. Whenever a C# tool connected to the game, one of the first messages it would send would be a request for the entire C++ type database. Once received, it could use that type information to auto-generate user interfaces, swapping in whatever widget was necessary for the type being edited (e.g. an HSB colour selector, slider, check-box for bools, list-box for enum lookup) and adding tool-tips/descriptions from the C++ metadata.&lt;/p&gt;

&lt;p&gt;This was a very stable means of getting type descriptions, as the editor could never be out-of-sync with the game it was editing. Contrast this to methods that involve loading a description of types from a separate file that must be integrated with your build system, somehow.&lt;/p&gt;

&lt;p&gt;After that the C# tool would request a copy of all objects currently live in the game. This is where the intermediate object model comes into play. The C# type description API would look something like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Equivalent to C++ Name using a C# port of CRC32
public class Name
{
    public string text;
    public uint hash;
}

// A minimal copy of the C++ Type structure
public class Type
{
    public Name name;
    public List&amp;lt;Field&amp;gt; fields;
    public List&amp;lt;EnumConst&amp;gt; enum_constants;
}

// Just enough information to control marshalling/serialisation and UI generation
public class Field
{
    public Name name;
    public Type type;
    public string display_name;
    public string description;
    public string group;
}

public class EnumConst
{
    public Name name;
    public int value;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each allocated C++ object would have an equivalent C# object of the type:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;public class Object
{
    Name name;
    Value value;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There would also be a big map of names to allocated C# objects, so whenever a message came through that referenced an object, that object could be retrieved. The intermediate object model was thus:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Base value object with the type its paired to
public class Value
{
    Type type;
}

// Objects for each type of value representable in C++
public class StringValue : Value
{
    public string data;
}
public class IntValue : Value
{
    public int value;
}
public class UIntValue  : Value{ // ...
public class FloatValue  : Value{ // ...
// ...

// A enum constant where its data is the enum value (can be paired with EnumConst above to get descriptive value)
public class EnumConstValue : Value
{
    public int data;
}

// Pointers could be network-serialised and represented in the tools, also.
// They were just names, after-all, and the type could be used to ensure you couldn&#39;t point to objects
// of an incorrect type.
public class PointerValue : Value
{
    public Name name;
}

// Each C++ container had a C# equivalent - the C# equivalent stored Value&#39;s
public class ArrayValue : Value
{
    public ArrayList data;
}

public ClassValue : Value
{
    public Dictionary&amp;lt;Name, Value&amp;gt; values;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each &lt;code&gt;Value&lt;/code&gt; implementation had various functions for displaying the type at runtime, generating widget controls, serialising and marshalling (converting between C# native and the object model) their contents.&lt;/p&gt;

&lt;p&gt;Once you wrote your code for displaying/editing the objects, entire objects could be replicated or the same code could be used to partially replicate an object. The C++ code would simply locate the existing object by name and overwrite only the fields which were present in the network-serialised data. The editor tools could request that the runtime generate data for it; the material editor, for example, would request material, mesh and texture thumbnails be generated and sent over the network on demand.&lt;/p&gt;

&lt;p&gt;And finally, on Windows, the C# tools could create a blank canvas window, send its &lt;code&gt;HWND&lt;/code&gt; over the network and the 3D renderer would happily render into it, taking cues from whatever keyboard and mouse input was sent along with it. This meant that we didn&amp;rsquo;t need to send over any of the heavyweight data, such as textures or vertices, choosing instead to give them the &amp;ldquo;network transient&amp;rdquo; attribute. Of course, that information could be sent over on-demand (for when you wanted to inspect all pixels of a texture, for example) but it was never stored persistently.&lt;/p&gt;

&lt;p&gt;This method of tools development was really quite natural: you could iterate amazingly quickly on the C# tools code while the game was still running, edit your C# code, build (a couple of seconds), and have it running and connected another couple of seconds later without any expensive level/data reloads!&lt;/p&gt;

&lt;h5 id=&#34;conclusion:34d857f412ffe3c047d6213141bf474b&#34;&gt;Conclusion&lt;/h5&gt;

&lt;p&gt;The methods contained within are among those that you should keep in your bag of tricks and bring out when you need good, scalable solutions quickly. If you&amp;rsquo;re into the new-fangled idea of developing your tools in a web browser, these techniques will get you most of the way there and even allow you to write native browser games without having to write plugins!&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re meta-programming hungry, part 3 will cover some more elaborate reflection technology which I wouldn&amp;rsquo;t necessarily recommend these days. It will hopefully serve as a lesson in how things can get complicated very fast. Stay tuned, as the internals of a basic IDL compiler will also be covered.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reflection in C&#43;&#43;, Part 1: Introduction</title>
      <link>http://donw.io/post/reflection-cpp-1/</link>
      <pubDate>Sun, 25 Sep 2011 23:34:13 +0100</pubDate>
      
      <guid>http://donw.io/post/reflection-cpp-1/</guid>
      <description>

&lt;p&gt;If there was one job I&amp;rsquo;d love to do other than writing games it&amp;rsquo;d be writing compilers. This probably explains my obsession with the subject of reflection; a topic I&amp;rsquo;ve been hammering away at for almost 10 years now. Having written a few compilers in the past, it became glaringly obvious to me that reflection would be quite simple to add to C++ &amp;ndash; if you&amp;rsquo;re willing to place some limits on it &amp;ndash; and that the language has suffered from its absence.&lt;/p&gt;

&lt;p&gt;Adding reflection to C++ via a library or other means can be a simple task, a very hard task, or a down-right impossible task. You can&amp;rsquo;t reflect all aspects of your C++ program and it&amp;rsquo;s highly unlikely that you will ever want to.&lt;/p&gt;

&lt;p&gt;This is the start of a series of tutorials on reflection from the point of view of a game programmer. As a first post it is very high-level with the hope that it will provide you with some key reasons why you might want to add reflective features to your game engine.&lt;/p&gt;

&lt;p&gt;Subsequent posts will provide in-depth case studies of methods I&amp;rsquo;ve developed in the past that are either out there in shipped games, buried in code bases never to be seen again or the result of frenzied late night coding sessions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I&amp;rsquo;ll cover a very simple method of reflection that can be very powerful, developed in my spare time as &lt;a href=&#34;https://bitbucket.org/dwilliamson/reflectabit&#34;&gt;Reflectabit&lt;/a&gt;, with a similar implementation written for Splinter Cell: Conviction. The main selling points of the implementation are the ease with which you can replicate anything over a network connection and the extra bonus of being able to live-edit your C++ code while the game is running.&lt;/li&gt;
&lt;li&gt;This will be followed by an approach that required the development of an IDL compiler and some crazy template programming for performing binding to arbitrary programming languages. Even though it worked on a PSP, it wasn&amp;rsquo;t the ideal method of achieving a solution for that platform and a subset of its implementation could prove a good match for others out there.&lt;/li&gt;
&lt;li&gt;Another spare time project of mine I&amp;rsquo;ll cover is something I informally call &lt;a href=&#34;https://bitbucket.org/dwilliamson/rfl&#34;&gt;Reflectalot&lt;/a&gt;. It works by scanning a PDB file and is surprisingly thorough at providing you with most of the information you need, albeit not really cross-platform (PC &amp;amp; Xbox 360 only). One of its cunning little features is its ability to provide you with a constant-time &lt;code&gt;typeof&lt;/code&gt; operator.&lt;/li&gt;
&lt;li&gt;Finally I&amp;rsquo;ll cover my latest development, &lt;a href=&#34;https://github.com/Celtoys/clReflect&#34;&gt;clReflect&lt;/a&gt;, that uses the &lt;a href=&#34;http://clang.llvm.org/&#34;&gt;clang C++ frontend&lt;/a&gt; to build a reflection database. This to me is as close to ideal as I&amp;rsquo;m going to get for C++ on Windows, however it can be taken to its logical conclusion on other platforms such as MacOS or Linux where the LLVM backend is more stable. Please checkout its webpage because I&amp;rsquo;d really love some help developing it further!&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;what-is-reflection:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;What is Reflection?&lt;/h4&gt;

&lt;p&gt;A reflection API is a very basic, powerful tool that every game studio should have at their disposal. It normally contains some or all of the following features:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A database of types and their inheritance relationship with each other.&lt;/li&gt;
&lt;li&gt;A means of creating objects of a specific type by name.&lt;/li&gt;
&lt;li&gt;A list of data member descriptions for each type, with name/type/offset tuples.&lt;/li&gt;
&lt;li&gt;A database of enumeration types and their associated key/value pairs.&lt;/li&gt;
&lt;li&gt;A database of functions/methods with their return types and parameter lists.&lt;/li&gt;
&lt;li&gt;A means of calling functions/methods by name at runtime with an arbtrarily constructed parameter list.&lt;/li&gt;
&lt;li&gt;A database of properties represented as Get/Set method pairs that externally look like a named value.&lt;/li&gt;
&lt;li&gt;A database of attributes that can be attached to any of the above, describing how they should be used.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each language has varying levels of support for reflection, while C++ has RTTI. You can do various things with RTTI but it&amp;rsquo;s an incredibly limited system that only gives you:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The ability to discover an object&amp;rsquo;s type at runtime through the &lt;code&gt;typeid&lt;/code&gt; operator.&lt;/li&gt;
&lt;li&gt;A &lt;code&gt;typeid&lt;/code&gt; operator that can also be applied to types themselves.&lt;/li&gt;
&lt;li&gt;A type&amp;rsquo;s name, its hash code and some comparison functions.&lt;/li&gt;
&lt;li&gt;Runtime downcasting and similar operations through &lt;code&gt;dynamic_cast&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is not nearly enough! RTTI also has varying levels of support between compilers and type names are implementation specific.&lt;/p&gt;

&lt;p&gt;So why would you want reflection? Perhaps it&amp;rsquo;s best to list a few things that it can enable:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Serialisation of any game type.&lt;/li&gt;
&lt;li&gt;Transparent implementations of various backend data formats with one point of serialisation for any given format.&lt;/li&gt;
&lt;li&gt;Versionable serialisation of any data.&lt;/li&gt;
&lt;li&gt;Inspect game state of any object at runtime for debugging.&lt;/li&gt;
&lt;li&gt;Dependency tracking with the pointer graph (ever wanted to know what objects are dependent on another before deleting?).&lt;/li&gt;
&lt;li&gt;Reloadable resource (mesh, texture, script, etc) reference updating.&lt;/li&gt;
&lt;li&gt;Automatically populate and describe user interfaces for editing tools.&lt;/li&gt;
&lt;li&gt;Binding to arbitrary programming languages (Lua, C#, Python, etc.) through minimal translation layers.&lt;/li&gt;
&lt;li&gt;Network communication/replication through serialisation and RPC.&lt;/li&gt;
&lt;li&gt;Memory mapping of data formats with post-load pointer patching.&lt;/li&gt;
&lt;li&gt;Live C++ code editing.&lt;/li&gt;
&lt;li&gt;Garbage collection or defragmentable memory heaps (useful on systems where the GPU uses physical addressing).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can of course build individual systems for each of these but they all share the same need to register type data and access it offline or at runtime. Using reflection for these systems can either make everything easier to understand and maintain or obfuscate intent and lead to a brittle code base. As such, a clean and simple reflection API is absolutely vital if you intend to adopt one.&lt;/p&gt;

&lt;p&gt;Generating a reflection database can be done in any number of different ways with C++, including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Using macros to simultaneously annotate your code and generate registration calls.&lt;/li&gt;
&lt;li&gt;Using templates and meta-programming techniques to achieve the same goal.&lt;/li&gt;
&lt;li&gt;Using a hybrid of the above or even doing it non-intrusively. Collectively these are runtime databases with no offline representation.&lt;/li&gt;
&lt;li&gt;Using an IDL/DDL compiler to generate cpp/h files containing C++ equivalents and registration code. This can also generate an offline representation of your database that can be used in tools.&lt;/li&gt;
&lt;li&gt;Using an existing language that already has reflection to describe your data/interfaces to achieve the same as the previous method (C# is a good candidate for this).&lt;/li&gt;
&lt;li&gt;Performing a pre/post process on your C++ code using a custom parser that picks up interesting information.&lt;/li&gt;
&lt;li&gt;Inspecting debug information emitted by the compiler.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are many tradeoffs with each technique and covering each is beyond the scope of these posts. However, the use-cases should be broad enough to show how varied implementations can be.&lt;/p&gt;

&lt;h4 id=&#34;basic-c-reflection-api:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Basic C++ Reflection API&lt;/h4&gt;

&lt;p&gt;To introduce the above concepts we&amp;rsquo;ll need a quick API we can talk about:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct Name
{
	int hash;
	string text;
};
struct Primitive
{
	Name name;
};
struct Type : public Primitive
{
	int size;
};
struct EnumConstant : public Primitive
{
	int value;
}
struct Enum : public Type
{
	EnumConstant constants[];
};
struct Field : public Primitive
{
	Type type;
	int offset;
};
struct Function : public Primitive
{
	Field return_parameter;
	Field parameters[];
};
struct Class : public Type
{
	Field fields[];
	Function functions[];
};
struct Namespace : public Primitive
{
	Enum enums[];
	Class classes[];
	Function functions[];
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The base type for any entry in the reflection database is a &lt;strong&gt;Primitive&lt;/strong&gt; and will be used below to describe any such entry.&lt;/p&gt;

&lt;h4 id=&#34;serialisation:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Serialisation&lt;/h4&gt;

&lt;p&gt;The cross-over between serialisation and reflection APIs is quite large and subtle. When you have game objects that you want to load and save from disk, a natural response is to develop a dedicated serialisation API that reads and writes data from within your game types. Reflection can be considered a generalisation of such a serialisation API by presenting a runtime description of all your types and their memory layout. This allows you to write serialisation code separate from your types that can be adapted to suit multiple file formats.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start with a very basic set of game types:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct Vector
{
	float x, y, z;
};

struct PhysicsComponent
{
	Vector position;
	Vector velocity;
	Vector acceleration;
};
	
struct GameObject : public Object
{
	PhysicsComponent physics;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The reflection database can tell you:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Vector&lt;/code&gt; has 3 floating point data members at offsets 0, 4 and 8.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PhysicsComponent&lt;/code&gt; has 3 data members of type &lt;code&gt;Vector&lt;/code&gt; at offsets 0, 12 and 24.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GameObject&lt;/code&gt; has one &lt;code&gt;PhysicsComponent&lt;/code&gt; at offset 0.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;Object&lt;/code&gt; is a type introduced by the reflection API that all objects must inherit from if they intend to be the root of any serialisation requests. In the code above &lt;code&gt;Vector&lt;/code&gt; and &lt;code&gt;PhysicsComponent&lt;/code&gt; do not inherit from &lt;code&gt;Object&lt;/code&gt;, representing any of your lightweight game types. This means that you can only serialise objects of type &lt;code&gt;GameObject&lt;/code&gt; - however, as long as the reflection database contains a description of the &lt;code&gt;Vector/PhysicsObject&lt;/code&gt; types, they can be serialised as part of any objects that contain them. This should become apparent when we introduce what &lt;code&gt;Object&lt;/code&gt; actually looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct Object
{
	Type* type;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So far that&amp;rsquo;s all we need. &lt;code&gt;Object&lt;/code&gt; simply stores a pointer to the reflection database&amp;rsquo;s description of whatever type that object is. Some psuedo-code for a save function would be:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void SaveObject(Object* object)
{
	// Types that inherit from Object already know their type so can call
	// the overloaded SaveObject directly
	SaveObject(object, object-&amp;gt;type);
}

void SaveObject(char* data, Type* type)
{
	// Using the description of the type, iterate over all fields in
	// the object
	for (Field* field in type-&amp;gt;fields)
	{
		// Each field knows its offset so add that to the base address of the
		// object being saved to get at the individual field data
		char* field_data = data + field-&amp;gt;offset;

		// If the field type is a known built-in type then we&#39;re at leaf nodes of
		// our object field hierarchies. These can be saved with explicit save
		// functions that know their type. If not, then we need to further
		// recurse until we reach a leaf node.
		Type* field_type = field-&amp;gt;type;
		if (field_type is builtin)
			SaveBuiltin(field_data, field_type);
		else
			SaveObject(field_data, field_type);
	}
}

void SaveBuiltin(char* data, Type* type)
{
	switch (type)
	{
		case (char): WriteChar(data);
		case (short): WriteShort(data);
		case (int): WriteInt(data);
		case (float): WriteFloat(data);
		// ... etc ...
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Whether your file format is text XML or binary, the algorithm is the same. The difference is in how you write your known built-in types and how you annotate your output data along the way (e.g. text tags for XML). A nice side-effect of writing your serialisation this way is that for a given file format, your serialisation code is written in one place and can handle any object that can be described by your reflection API - you just have different files for each format implementation.&lt;/p&gt;

&lt;h4 id=&#34;containers:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Containers&lt;/h4&gt;

&lt;p&gt;Game objects are more complicated than those specified above and will have containers. This is an umbrella term for any of these:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;C-style Arrays&lt;/li&gt;
&lt;li&gt;Vectors&lt;/li&gt;
&lt;li&gt;Linked Lists&lt;/li&gt;
&lt;li&gt;Sets&lt;/li&gt;
&lt;li&gt;Key/Value Maps and Hash Maps&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the moment if we assume that our primary goal is to make these serialisable, a simple means of doing so is to extend &lt;code&gt;SaveObject&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void SaveObject(char* data, Type* type)
{
	// ... start of function ...
	
		if (field_type is builtin)
			SaveBuiltin(field_data, field_type);
		else if (field_type is container)
			SaveContainer(field_data, field_type);
		else
			SaveObject(field_data, field_type);
	
	// ... rest of function ...
}

void SaveContainer(char* data, Type* type)
{
	switch (type)
	{
		case (vector): WriteVector(data, type);
		case (list): WriteList(data, type);
		// ... etc ...
	}
}

void SaveVector(char* data, Type* type)
{
	// Cast the data to your vector type
	vector&amp;amp; vec = data cast as vector;
	
	Type* stored_type = type-&amp;gt;container_value_type;
	
	for (int i in vec.count)
	{
		char* value_data = data + i * stored_type-&amp;gt;size;
		SaveObject(value_data, stored_type);
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first problem we come up against is that, taking &lt;code&gt;SaveVector&lt;/code&gt; as an example, the type of the vector changes based on the data it stores. So, &lt;code&gt;std::vector&amp;lt;int&amp;gt;&lt;/code&gt; is a different type to &lt;code&gt;std::vector&amp;lt;short&amp;gt;&lt;/code&gt; and can&amp;rsquo;t be cast at runtime. There are two ways of dealing with this that will be covered in more detail later in the use-case studies. They are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The reflection API is entirely runtime-based and when you register a field that is a container, code gets generated using templates that will be used to serialise when needed. This has the benefit that any container becomes easily serialisable without you having to know the memory layout of the container type itself. It has the drawback that it can generate quite a substantial amount of code that can have a negative impact on your memory budget.&lt;/li&gt;
&lt;li&gt;If you can rely on knowing the memory layout of your container independent of its type, you can use that to iterate over all elements using the type information stored in the reflection database, as above. This has the benefit that there is only one section of your code that is used to serialise all containers of that type. It has the drawback that you may not want to rely on knowing the internal layout of your container because it&amp;rsquo;s not part of an API that you own/control, e.g. STL.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The second problem you encounter is that if you have N file formats and M types of container, you&amp;rsquo;re going to have to write M*N functions that handle all your serialisation possibilities. Later discussion covers how to use the reflection database for other purposes, such as walking a pointer graph, and in such cases you&amp;rsquo;d also have to write specific implementations for each container type.&lt;/p&gt;

&lt;p&gt;Obviously that won&amp;rsquo;t do and you can add a layer of indirection to get around this. The way I deal with this is by introducing the container interface to report basic information about a container, such as its entry count, and read/write iterator interfaces for reading and modifying the containers:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;interface IContainer
{
	Type* GetKeyType() const;
	Type* GetValueType() const;
	
	ReadIterator GetReadIterator();
	WriteIterator GetWriteIterator();
};

interface IReadIterator
{
	char* GetKey() const;
	char* GetValue() const;
	int GetCount() const;
	
	void MoveNext();
	bool IsValid();
};

interface IWriteIterator
{
	void SetKey(char* data);
	void SetValue(char* data);
	
	void MoveNext();
	bool IsValid();
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you want to skip ahead, &lt;a href=&#34;https://bitbucket.org/dwilliamson/reflectabit/src/tip/inc/rflb/Container.h&#34;&gt;Reflectabit&lt;/a&gt; contains a very good example of this.&lt;/p&gt;

&lt;p&gt;All container types you support implement these interfaces. Notice that they account for both the key and value of an item in a container, which can be safely ignored for those containers that don&amp;rsquo;t conceptually have keys. Use is then a simple case of:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void SaveContainer(char* data, Type* type)
{
	ContainerInterface* container = type-&amp;gt;GetContainerInterface(data);
	Type* key_type = container-&amp;gt;GetKeyType();
	Type* value_type = container-&amp;gt;GetValueType();
	
	Serialise iterator-&amp;gt;GetCount();
	
	WriteIterator* iterator = container-&amp;gt;GetWriteIterator();
	while (iterator-&amp;gt;IsValid())
	{
		if (key_type)
			SaveObject(iterator-&amp;gt;GetKey(), key_type);
		
		SaveObject(iterator-&amp;gt;GetValue(), value_type);
		
		iterator-&amp;gt;Next();
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Like the serialisation code that we started with, this algorithm is independent of file format and only differs in how the data is finally written. This also requires you to write only one container save per file format, cleanly solving the implementation explosion.&lt;/p&gt;

&lt;h4 id=&#34;pointers-and-the-object-database:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Pointers and the Object Database&lt;/h4&gt;

&lt;p&gt;Serialising pointers can be a tricky subject and any grizzled console programmer will tell you that a good way to handle the problem is to not serialise them at all! If you can get away with using indices and handles you may find them more comfortable than pointers. With a reflection API and object database, however, serialising pointers is remarkably easy. Not only that, it opens up a whole host of possibilities for future use.&lt;/p&gt;

&lt;p&gt;To start you need some means of creating objects from a central source and assigning them a unique ID, so let&amp;rsquo;s redefine &lt;code&gt;Object&lt;/code&gt; and introduce the object database:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct Name
{
	u32 id;
	const char* text;
};

struct Object
{
	Name name;
	Type* type;
};

class ObjectDatabase
{
	Object* CreateObject(const char* type_name);
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, the &lt;code&gt;Name&lt;/code&gt; type represents the full name of your object, assigned offline by your tools/editor or generated at runtime. It contains a pointer to the text of the name that can be used for debugging and a unique ID that maps to that name - usually a hash of the name. The text can be removed in your release builds or preferrably, not stored at all: it&amp;rsquo;s pretty simple to create a Visual Studio debugger plugin that can map the ID to a locally stored text database or write network logging tools that only require the ID to print the name. The important point is that your means of generating the ID from the name must be consistent and there must be no collisions.&lt;/p&gt;

&lt;p&gt;Given such properties, serialising pointers is a straight-forward case of serialising their ID in place of their pointer:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;if (field_type is pointer)
{
	Object* object = (Object*)field_data;
	Serialise object-&amp;gt;hash as u32
}
else if (field_type is builtin) ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Generally you will need a top-level collection of all objects in a level, package or whatever abstraction you choose. The classic example of this is the &lt;a href=&#34;http://udn.epicgames.com/Three/UnrealPackages.html&#34;&gt;Unreal Package&lt;/a&gt;. When loading these IDs, you generally won&amp;rsquo;t create them on-demand, but assume they exist and look them up/point to them. For this reason you need to be careful about loading order.&lt;/p&gt;

&lt;p&gt;Several solutions I&amp;rsquo;ve used in the past are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If the referenced object doesn&amp;rsquo;t exist, create an uninitialised proxy object for it.&lt;/li&gt;
&lt;li&gt;Use scoped tree-referencing where pointers can only go in one direction.&lt;/li&gt;
&lt;li&gt;The package being loaded contains a list of packages it depends upon that need to be loaded first.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;custom-loading-functions:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Custom loading functions&lt;/h4&gt;

&lt;p&gt;Game objects can be even more complicated than this - sometimes you have fields which can&amp;rsquo;t directly be serialised to disk. A good example of this is a D3D vertex buffer, which is represented as a D3D resource interface pointer. Other times there are types which may not be reflection-registered due to their complexity that you still want to save - &lt;code&gt;std::string&lt;/code&gt; is a nice example of this.&lt;/p&gt;

&lt;p&gt;With each type or field you can associate a means of loading and saving data of that type via a function pointer. The serialisation code first checks to see if the field type has an associated set of load/save functions before trying to serialise another way. It can be a little more complicated than that if you&amp;rsquo;re worried about performance and support for multiple file formats; take the simplest example of this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Serialisation code for the XML file format
if (SaveFunc f = field_type-&amp;gt;save_funcs.find(FORMAT_XML))
{
	f(field_data, field_type);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Before you get to checking what other properties the field may have, you&amp;rsquo;re doing some form of map lookup.&lt;/p&gt;

&lt;p&gt;The simplest/fastest way of doing this I&amp;rsquo;ve found is by assigning your file format types indexed enums and having an array of function pointers inside your type/field:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;enum Format
{
	FORMAT_BINARY,
	FORMAT_TEXT_XML,
	FORMAT_BINARY_XML,
	FORMAT_COUNT
};

struct Type
{
	SaveFunc save_funcs[FORMAT_COUNT];
	LoadFunc load_funcs[FORMAT_COUNT];
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Serialisation becomes quick and simple but there is a loose-coupling of concepts between reflection API and serialisation code which you may not like. A happy medium of the two is storing a sorted, dynamic array in the type that can be binary searched - the general case would be an empty array that is quickly skipped.&lt;/p&gt;

&lt;p&gt;The serialisation code with custom save array lookup now looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void SaveObject(char* data, Type* type)
{
	// Using the description of the type, iterate over all fields in
	// the object
	for (Field* field in type-&amp;gt;fields)
	{
		// Each field knows its offset so add that to the base address of the
		// object being saved to get at the individual field data
		char* field_data = data + field-&amp;gt;offset;

		// Branch on field type
		Type* field_type = field-&amp;gt;type;
		if (field_type is pointer)
			Serialise ((Object*)field_data)-&amp;gt;hash as u32
		else if (SaveFunc f = field_type-&amp;gt;save_funcs[FORMAT_XML])
			f(field_data, field_type);
		else if (field_type is builtin)
			SaveBuiltin(field_data, field_type);
		else if (field_type is container)
			SaveContainer(field_data, field_type);
		else
			SaveObject(field_data, field_type);
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s worth mentioning that another means of achieving this is to have a single Load/Save function per object that handles the serialisation of all fields that are too complicated to reflect in one place. Unreal Engine (UE) is a good example of this and it&amp;rsquo;s one of the main reasons I prefer the above solution. There are no marked boundaries between serialised fields so it&amp;rsquo;s very easy to damage an entire object by messing up one field - you can&amp;rsquo;t temporarily skip it and keep everybody working while you solve the problem at hand. It gets more unwieldy when you get into versioning, which is covered below.&lt;/p&gt;

&lt;h4 id=&#34;versioned-file-formats:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Versioned file formats&lt;/h4&gt;

&lt;p&gt;So far we haven&amp;rsquo;t taken a look at any loading code. Some pseudo-code for loading anything saved with the features we&amp;rsquo;ve covered above could look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void LoadObject(char* data, const Type* type)
{
	for (Field* field in type-&amp;gt;fields)
	{
		char* field_data = data + field-&amp;gt;offset;
		Type* field_type = field-&amp;gt;type;
		
		if (field_type is pointer)
			// Load u32 hash, lookup in Object Database, point to it (or create, or proxy object, impl defined...)
		else if (LoadFunc f = field_type-&amp;gt;load_funcs[FORMAT_XML])
			f(data, field_type);
		else if (field_type is container)
			LoadContainer(field_data, field_type);
		else if (field_type is builtin)
			LoadBuiltin(field_data, field_type);
		else
			LoadObject(field_data, field_type);
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This code expects the data to be saved in the order the fields are specified in the type. If you add or remove fields or change the implementation of your custom loading function then catastrophe awaits. A versionable file format is one which can adapt to these changes gracefully.&lt;/p&gt;

&lt;p&gt;Versionable file formats can be an incredibly important tool for development files in game asset pipelines. A good example here would be a mesh file format, as loaded by your game:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Edit the mesh in your DCC.&lt;/li&gt;
&lt;li&gt;Export the mesh to an intermediate file format - this is custom or 3rd party (e.g. COLLADA, FBX or XSI).&lt;/li&gt;
&lt;li&gt;A custom tool &amp;ldquo;compiles&amp;rdquo; the mesh to its game-loadable file (per platform).&lt;/li&gt;
&lt;li&gt;Editor loads the output to use as level edit placement.&lt;/li&gt;
&lt;li&gt;Game loads the output.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Discussion of the merits of different build and development strategies goes far beyond the scope of this post, considering the variety of approaches developers take. However, if you&amp;rsquo;re using a build system that caches the compiled mesh contents so that other developers don&amp;rsquo;t have to build them locally to run the game, you&amp;rsquo;ll need to have a system in place to handle changes to the formats of those cached files.&lt;/p&gt;

&lt;p&gt;A common approach taken in many studios, including some I&amp;rsquo;ve worked at is to store a version number at the start of each mesh file and refuse to load the file (or assert) if there&amp;rsquo;s a version mismatch. When a programmer wants to change the file format, they do the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Make the change locally on their machine and iterate on a small subset of the assets.&lt;/li&gt;
&lt;li&gt;Kick off a process that recompiles every mesh in the game. This can be overnight on your machine or offloaded to an worker machine and distributed in some way.&lt;/li&gt;
&lt;li&gt;Submit new compilation tools, game and compiled assets.&lt;/li&gt;
&lt;li&gt;Content creators sync to new tools and new assets - potentially gigabytes of data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On one project it was not unknown for a complete rebuild of all textures to take up to a week. This put the programmer offline for a considerable amount of time, requiring multiple client-specs to maintain productivity. It completely killed any enthusiasm to change the file formats. Your mileage may vary but I&amp;rsquo;ve found that the ease at which I can optimise a game is greatly influenced by the ease at which I can modify the format of the files it loads.&lt;/p&gt;

&lt;p&gt;If your file format is amenable to change, you can do the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Make the change locally and iterate on a small subset of the assets.&lt;/li&gt;
&lt;li&gt;You can integrate these assets into larger levels with older assets during testing.&lt;/li&gt;
&lt;li&gt;Submit new compilation tools and game.&lt;/li&gt;
&lt;li&gt;Content creators get latest and can still play/edit the game.&lt;/li&gt;
&lt;li&gt;Any assets created or modified use the latest file format.&lt;/li&gt;
&lt;li&gt;Programmer schedules an offline build process to gradually go through all cached meshes and convert them to the new format.&lt;/li&gt;
&lt;li&gt;Content creators slowly sync over time to the updated assets.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This forms the backbone of UE-based development and scales gracefully to 150-200 man teams with outsourced developers added on top. It&amp;rsquo;s also how we built the Splinter Cell: Conviction engine, allowing us to rewrite the renderer on the main branch while around 50-80 content creators continued to work with daily tool/game updates.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m straying a little too far from the point of this post but this is a worthy discussion to have. The reality is, each developer views the issue differently and it&amp;rsquo;s possible to take any of the above solutions and create an environment in which it works wonderfully well or is a constant production risk.&lt;/p&gt;

&lt;p&gt;So, back to the point! If your output format is XML, you can simply change your loading code to:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void LoadObject(char* data, const Type* type)
{
	for (string tag in xml_nodes)
	{
		// Skip any fields that have been removed
		Field* field = type-&amp;gt;find_field(tag);
		if (field == 0)
			continue;

		// Normal loading
		char* field_data = data + field-&amp;gt;offset;
		Type* field_type = field-&amp;gt;type;
		if (field_type is pointer)
			// Load u32 hash, lookup in Object Database, point to/create it
		else if (LoadFunc f = field_type-&amp;gt;load_funcs[FORMAT_XML])
			f(data, field_type);
		else if (field_type is builtin)
			LoadBuiltin(field_data, field_type);
		else if (field_type is container)
			LoadContainer(field_data, field_type);
		else
			LoadObject(field_data, field_type);
	}
	
	// Any added fields in the type won&#39;t be present in the data so are
	// naturally handled if you provide them with a default value
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If your output format is binary you can use a solution similar to &lt;a href=&#34;http://www.ibm.com/developerworks/power/library/pa-spec16/&#34;&gt;IFF files&lt;/a&gt;: each field is prefixed with a chunk descriptor that specifies a tag ID and chunk size. In our case, the tag ID can be the hash of the field name:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void LoadObject(char* data, const Type* type)
{
	int nb_fields = read from file;
	
	for (i in nb_fields)
	{
		// Read the chunk header
		u32 field_hash = read from file;
		u32 data_size = read from file;
		
		// Skip any fields that have been removed
		Field* field = type-&amp;gt;find_field(field_hash);
		if (field == 0)
		{
			// seek from current position over the data_size
			continue;
		}
		
		// Normal loading
		char* field_data = data + field-&amp;gt;offset;
		Type* field_type = field-&amp;gt;type;
		// ...
		
		// You can insert an extra check here to verify that the loading code has
		// consumed the number of bytes equal to data_size. Very useful for tracking
		// errors in custom loading functions.
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This has two issues you need to solve:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If somebody loads a new file version with an older version of your editor, it will discard data when resaving. One way of solving this is to store the data of any skipped fields in a dictionary assigned to that object that gets saved later. A simpler way is to force everybody to update to any new tools versions!&lt;/li&gt;
&lt;li&gt;If data for a newly added field is not present in the file, a nice default value needs to come from somewhere. An easy solution is to initialise your default value in the object constructor. The downside to this is that the default value is not visible to external tools and you need to recompile source each time you change a default value. Another approach would be to specify the default value as some reflection attribute that gets saved offline. You would need to change the code above to then manually assign these defaults to any missing fields.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Custom load/save functions need special attention with respect to versioning. As mentioned above, UE has a &lt;a href=&#34;https://docs.unrealengine.com/latest/INT/API/Runtime/CoreUObject/UObject/UObject/Serialize/index.html&#34;&gt;custom Serialize function per object&lt;/a&gt;, within which multiple version checks are made to see what needs to be serialised. This can get very complicated to manage and is easy to break.&lt;/p&gt;

&lt;p&gt;When you have the ability to associate custom load/save functions per type or per field, this becomes easier to manage. If you serialise version numbers with each function then the job of deciding what&amp;rsquo;s valid and skipping invalid chunks is handled automatically for you, leading to more maintainable and fault tolerant code.&lt;/p&gt;

&lt;p&gt;Both methods can suffer from lack of old version pruning. When we started Splinter Cell: Conviction, there was still loading code for the mesh format in the original Splinter Cell. Nobody knew whether this worked as it hadn&amp;rsquo;t been tested in years. Updating the code was fraught with problems and a reboot was required.&lt;/p&gt;

&lt;h4 id=&#34;enumerations:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Enumerations&lt;/h4&gt;

&lt;p&gt;Enumerations can quite easily be serialised as integers but this is quite brittle. If a programmer changes the order of enumerations, changes their value or adds/removes any, all existing data that uses that enum type will likely be invalidated. I have worked on projects that would require rebuilding the entire asset database if you were ever bold enough to try such a move!&lt;/p&gt;

&lt;p&gt;A very simple way to avoid this problem is to serialise enumerations as the hash of their name:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void SaveEnum(char* data, Type* type)
{
	// Cast the type to an enum and retrieve the value
	Enum* enum_type = type-&amp;gt;AsEnum();
	int enum_value = *(int*)data;

	// Lookup the constant and save its hash
	EnumConstant* constant = enum_type-&amp;gt;find_constant(enum_value);
	WriteU32(constant-&amp;gt;name.hash);
}

void LoadEnum(char* data, Type* type)
{
	// Cast the type to an enum and read the constant hash
	Enum* enum_type = type-&amp;gt;AsEnum();
	int hash = ReadU32();
	
	// Lookup the constant and assign the value
	EnumConstant* constant = enum_type-&amp;gt;find_constant(hash);
	*(int*)data = constant-&amp;gt;value;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You will also have to account for data that stores old enum values, typically handled by leaving the destination untouched and initialised at its default value.&lt;/p&gt;

&lt;h4 id=&#34;performance-baked-serialisation-functions-pods:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Performance: Baked serialisation functions &amp;amp; PODs&lt;/h4&gt;

&lt;p&gt;This may all seem a little slow but the reality is you are likely to be I/O bound; even on hard-drives none of this code factors negatively in the performance.&lt;/p&gt;

&lt;p&gt;However, it can be given a little speed boost with a technique that you may find easier to read/maintain: give each field a custom serialisation function. Instead of the inner loop of &lt;code&gt;SaveObject&lt;/code&gt; branching, ahead of time you can figure out what the result will be and record it for that field:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void BakeSerialisationFunctions(Field* field, Format format)
{
	// Don&#39;t bake anything for transient fields
	if (&amp;quot;transient&amp;quot; in field-&amp;gt;attributes)
		return;

	// Bake the save function based on the type
	if (field_type is pointer)
		field-&amp;gt;save_funcs[FORMAT_XML] = SavePointer;
	else if (field_type-&amp;gt;save_funcs[FORMAT_XML])
		field-&amp;gt;save_funcs[FORMAT_XML] = field_type-&amp;gt;save_funcs[FORMAT_XML];
	else if (field_type is builtin)
		field-&amp;gt;save_funcs[FORMAT_XML] = SaveBuiltin;		
	else if (field_type is enum)
		field-&amp;gt;save_funcs[FORMAT_XML] = SaveEnum
	else if (field_type is container)
		field-&amp;gt;save_funcs[FORMAT_XML] = SaveContainer;
	else
		field-&amp;gt;save_funcs[FORMAT_XML] = SaveObject;
}

void SaveObject(char* data, Type* type)
{
	// Call the save for each field
	for (Field* field in type-&amp;gt;fields)
	{
		char* field_data = data + field-&amp;gt;offset;
		Type* field_type = field-&amp;gt;type;
		field-&amp;gt;save_funcs[FORMAT_XML](field_data, field_type);
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Furthermore, if your reflection API deems that an object is of a POD type, you don&amp;rsquo;t have to recurse into the children and can instead write a binary blob for the entire object (un-versioned, binary only).&lt;/p&gt;

&lt;h4 id=&#34;field-offsets-and-inheritance:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Field offsets and inheritance&lt;/h4&gt;

&lt;p&gt;The basic implementation of a &lt;code&gt;Class&lt;/code&gt; type will store only the fields that were declared within the class. Field layout is ABI-specific and you will need a database per compiler/platform when using field offsets. Access to fields of its base class requires following the base class pointer in &lt;code&gt;Class&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void SaveObject(char* data, Type* type)
{
	// ... end of the function ...
	
	// Recurse into base types
	if (type is class &amp;amp;&amp;amp; type-&amp;gt;base_class)
		SaveObject(data, type);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This has some subtle side-effects. If your class contains virtual methods then it&amp;rsquo;s up to the compiler where it stores the virtual function table pointer. Typically this has no effect on the validity of recording field offsets that are used at runtime but there are some simple cases where it breaks. Take this piece of code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct PodBase { int x; };
struct NonPodDerived : public PodBase { virtual void f(); };
NonPodDerived obj;
NonPodDerived* a = &amp;amp;obj;
PodBase* b = a;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The addresses of &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; will be different because &lt;code&gt;NonPodDerived&lt;/code&gt; needs to store an extra virtual function table pointer. This means that the address of &lt;code&gt;PodBase::x&lt;/code&gt; will be different to &lt;code&gt;NonPodDerived::x&lt;/code&gt;!&lt;/p&gt;

&lt;p&gt;If you want to use multiple inheritance, things get a little trickier:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct B0 { int x; };
struct B1 { int y; };
struct C : public B0, public B1 { int z; };
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The field offsets for both &lt;code&gt;x&lt;/code&gt; &amp;amp; &lt;code&gt;y&lt;/code&gt; in their class descriptions will be 0. When serialising &lt;code&gt;B0&lt;/code&gt; and &lt;code&gt;B1&lt;/code&gt; on their own this will be fine, but when serialising &lt;code&gt;C&lt;/code&gt;, both &lt;code&gt;x&lt;/code&gt; &amp;amp; &lt;code&gt;y&lt;/code&gt; can&amp;rsquo;t live at offset 0! The compiler may layout &lt;code&gt;C&lt;/code&gt; like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x: 0
y: 4
z: 8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Serialising this kind of object using the class descriptions of &lt;code&gt;C&lt;/code&gt;, &lt;code&gt;B0&lt;/code&gt; and &lt;code&gt;B1&lt;/code&gt; will not work. This simple case can be solved by calculating the offsets of &lt;code&gt;x&lt;/code&gt; &amp;amp; &lt;code&gt;y&lt;/code&gt; when contained in &lt;code&gt;C&lt;/code&gt; and storing them in the class description of &lt;code&gt;C&lt;/code&gt; itself. No longer will your serialisation code walk up the inheritance hierarchy finding members, and given that reflection databases are usually quite small, you may actually find this kind of setup preferrable. It will also fix the first issue.&lt;/p&gt;

&lt;p&gt;But what if &lt;code&gt;B0&lt;/code&gt; and &lt;code&gt;B1&lt;/code&gt; themselves inherit from the same base class? This is the dastardly diamond inheritance issue:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct A { int w; }
struct B0 : public A { int x; };
struct B1 : public A { int y; };
struct C : public B0, public B1 { int z; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this case &lt;code&gt;C&lt;/code&gt; will contain two copies of &lt;code&gt;A&lt;/code&gt;, each with different offsets for their own &lt;code&gt;w&lt;/code&gt;. There&amp;rsquo;s really no clean solution to this in a reflection API unless you add more complexity. One way to force the compiler to only embed one copy of &lt;code&gt;A&lt;/code&gt; in &lt;code&gt;C&lt;/code&gt; is to use virtual inheritance:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct A { int w; }
struct B0 : virtual public A { int x; };
struct B1 : virtual public A { int y; };
struct C: public B0, public B1 { int z; };
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;re into highly implementation specific territory here but the compiler might offset like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vptr B0: 0
x: 4
vptr B1: 8
y: 12
z: 16
w: 20
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that &lt;code&gt;w&lt;/code&gt; is right at the end and there&amp;rsquo;s only one copy. There&amp;rsquo;s also a couple of virtual table pointers in &lt;code&gt;C&lt;/code&gt; that help the compiler cast between the various classes at runtime. At first sight, it appears that using the initial multiple inheritance solution might work here, however the representation of a member offset for non-POD types is implementation defined and not guaranteed to work on any compiler. Indeed, the following code crashes at runtime in MSVC2005:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct VirtualBase { };
struct Derived : virtual public VirtualBase { int x; };
int offset = offsetof(Derived, x);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You will hit this issue if you decide to allow multiple inheritance of root serialisation types as they all need to inherit from &lt;code&gt;Object&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;There are a few ways of recording the offset of a field, including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;With runtime, templated registration, you can create &amp;ldquo;visitor functions&amp;rdquo; that wrap access to the field. This is by far the most portable/standards-compliant way of doing this but you&amp;rsquo;re adding complexity to your API &amp;amp; runtime, increasing compile times and generated code size.&lt;/li&gt;
&lt;li&gt;At runtime you can use the C++ &lt;code&gt;offsetof&lt;/code&gt; macro. This is standards-compliant for &lt;a href=&#34;http://www.fnal.gov/docs/working-groups/fpcltf/Pkg/ISOcxx/doc/POD.html&#34;&gt;POD types&lt;/a&gt;. It&amp;rsquo;s practically compliant for a variety of non-POD configurations for the platforms game developers use but will break down with pure virtual inheritance.&lt;/li&gt;
&lt;li&gt;Offline, you can use a layout generator that knows the target ABI and can calculate the field offsets for you. A good example of this is the one that ships as part of clang: &lt;a href=&#34;http://clang.llvm.org/doxygen/RecordLayoutBuilder_8cpp_source.html&#34;&gt;RecordLayoutBuilder.cpp&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Get your compiler to report field offsets after a compile step.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In later posts I&amp;rsquo;ll explain how &lt;code&gt;offsetof&lt;/code&gt; works and how you can work-around its limitations with pure virtual inheritance. However, it&amp;rsquo;s hairy territory and I&amp;rsquo;d advise avoiding the problem altogether - personal experience has shown that the added complexity required to deal with such cases does not justify the limited use it sees.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth reading &lt;a href=&#34;http://www.phpcompiler.org/articles/virtualinheritance.html&#34;&gt;Memory Layout for Multiple and Virtual Inheritance&lt;/a&gt; to get more background information on this problem.&lt;/p&gt;

&lt;h4 id=&#34;attributes:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Attributes&lt;/h4&gt;

&lt;p&gt;Attributes are a means of annotating your primitives, adding extra data that can be used to control how your program performs at runtime. &lt;a href=&#34;http://en.cppreference.com/w/cpp/language/attributes&#34;&gt;C++11 attributes&lt;/a&gt; are not what I&amp;rsquo;m referring to here as they don&amp;rsquo;t allow you to define your own attributes/values. &lt;a href=&#34;http://msdn.microsoft.com/en-us/library/aa287992.aspx&#34;&gt;C# attributes&lt;/a&gt; are closer but a little too powerful/complicated.&lt;/p&gt;

&lt;p&gt;A simpler attribute system would allow:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Flags: Named flags that represent a boolean state. A classic example is &lt;code&gt;transient&lt;/code&gt;, which allows you to mark fields which you don&amp;rsquo;t want to serialise.&lt;/li&gt;
&lt;li&gt;Values: These are name/value pairs, such as &lt;code&gt;min_value&lt;/code&gt;, &lt;code&gt;max_value&lt;/code&gt;, &lt;code&gt;default_value&lt;/code&gt;, that can be used to drive user interface widgets. Integer or floating point value types can be used.&lt;/li&gt;
&lt;li&gt;Strings: These are name/value pairs, such as &lt;code&gt;description&lt;/code&gt; and &lt;code&gt;group&lt;/code&gt;, that allow you to attach descriptive/grouping data to a primitive for user interfaces.&lt;/li&gt;
&lt;li&gt;Functions: Name/function name pairs that allow you to more conveniently specify custom load/save functions (e.g. &lt;code&gt;load=FunctionName&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Later posts will describe ways in which you can annotate primitives and retrieve them at runtime. There are, as you would guess, many tradeoffs with each approach.&lt;/p&gt;

&lt;h4 id=&#34;network-serialisation-and-visualisation-of-game-state:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Network Serialisation and Visualisation of Game State&lt;/h4&gt;

&lt;p&gt;It&amp;rsquo;s probably obvious by now how this can be achieved: use serialisation to a byte buffer that is optionally compressed and send that to your endpoint - most likely binary and versionable. With the addition of an attribute that describes network transient fields, this allows you to make some very powerful editing tools.&lt;/p&gt;

&lt;p&gt;The main class of tool is an editor that connects to a live game, edits an intermediate data representation and broadcasts changes to a live game. There are many benefits to this approach:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;You get live updates of any changes on PC or console.&lt;/li&gt;
&lt;li&gt;Design is multi-threaded due to the nature of network communication, making for some graceful UI tools.&lt;/li&gt;
&lt;li&gt;You can iterate on your tool code without bringing the live game down. If the tool crashes, it doesn&amp;rsquo;t bring down the game.&lt;/li&gt;
&lt;li&gt;If your game gets into a state that is deemed incorrect, you can connect and visually see the state of all your objects.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you want to write your tool code in C# or embrace the era of the Internets and write in a combination of Javascript, HTML, CSS, etc. you only need to write the equivalent of the above serialisation code in that language to allow editing and communication. Each C++ container type you support will need to map to an equivalent in the tool language.&lt;/p&gt;

&lt;p&gt;This is how a stand-alone material editor, realtime PIX debugging tool and post-process editor were developed for Splinter Cell: Conviction, to be discussed in a later post.&lt;/p&gt;

&lt;p&gt;This is more than likely not good enough for communicating real-time network updates for game code as you&amp;rsquo;ll want to do things like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use context-specific knowledge to compress data (e.g. movement updates).&lt;/li&gt;
&lt;li&gt;Use smaller situation-specific packet structures to communicate small changes to objects.&lt;/li&gt;
&lt;li&gt;Compress the ID representation of any objects that are referenced by packets.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can use a reflection API to describe your packet structures and binary serialise them or generate C++ code from the offline representation. If your packet structures end up being PODs then you can write code which performs a memcpy, exchanging any pointers for the unique hash of the object pointed to. However you choose to do it, the basic description of types and their layout that a reflection API can provide you with can give you a good head start.&lt;/p&gt;

&lt;h4 id=&#34;walking-the-object-graph-and-the-ui:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Walking the Object Graph and the UI&lt;/h4&gt;

&lt;p&gt;With the tools developed above you can visit all data members within an object and perform arbitrary operations, such as printing their value to a console, displaying them in a widget in-game or recording them using some form of programmable logging system.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re generating a UI for your tools, you might be best off using an offline description of your types stored in some easily loadable format (e.g. JSON or XML). If none exists then you need to somehow send the runtime database to your tool (something I&amp;rsquo;ve achieved in the past by sending the entire database over the network on tool connect). With this you can:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use attributes to specify default values, descriptions, field grouping and ranges.&lt;/li&gt;
&lt;li&gt;Use the type of a field to determine what kind of widget to use, inspecting optional attributes to refine the choice.&lt;/li&gt;
&lt;li&gt;Restrict the assignment of object references based on type.&lt;/li&gt;
&lt;li&gt;Automatically populate enumeration list boxes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When you can walk the object graph you can also record any pointers an object contains: what other objects does it reference? We used this technique in Splinter Cell: Conviction to accelerate deletes in UE. UE used to serialise all objects in a level, discarding everything but pointers when it needed to check for dependencies. This was incredibly slow in levels which contained 10s of thousands of actors - I believe we got delete operations from minutes down to a couple of seconds. More recent versions of UE have made significant performance improvements in this area, however.&lt;/p&gt;

&lt;p&gt;On systems where the GPU can only use physical addressing to reference data, runtime defragmentation of specific memory heaps for vertices and textures becomes a very useful technique. Of course, you need a system that informs any referencing assets where the memory has moved to. The ability to inspect pointers and relocate them makes this quite trivial. You can also solve this issue with handles or an extra level of indirection - you may or may not be willing to accept the runtime performance this costs you based on your overall engine design.&lt;/p&gt;

&lt;p&gt;Generalising the issue, you can also do controlled &lt;a href=&#34;http://www.cs.kent.ac.uk/people/staff/rej/gc.html&#34;&gt;Garbage Collection&lt;/a&gt; by following the pointer graph and highlighting orphaned objects. UE achieves the &lt;a href=&#34;http://wiki.beyondunreal.com/Legacy:Garbage_Collection&#34;&gt;same goal&lt;/a&gt; by serialising all objects, checking for references in a mark and sweep operation.&lt;/p&gt;

&lt;h4 id=&#34;calling-functions-script-binding-and-rpc:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Calling Functions, Script Binding and RPC&lt;/h4&gt;

&lt;p&gt;You can build a reflection API for your game without needing to worry about adding function call support. By this I mean the ability to do something similar to the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Retrieve the function by name
Function* function = db.GetFunction(&amp;quot;FunctionName&amp;quot;);

// Build a set of parameters to pass to the function
ParameterStack params;
params.Add(1);
params.Add(&amp;quot;string&amp;quot;);

// Call the function and inspect any return value
function-&amp;gt;Call(params);
int ret = params.GetReturnValue();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is an incredibly useful tool to have at your disposal for binding to scripting languages. A very simple way to bind to a scripting language is to use its API directly and manually register each function you want to expose:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void NativeFunctionExample(BindLanguageContext* ctx)
{
	// Pop some parameters off the script language stack
	int param0 = ctx-&amp;gt;PopInt();
	string param1 = ctx-&amp;gt;PopString();

	// ...do some work with the parameters...
	
	// Push a return value result of the work done
	ctx-&amp;gt;PushInt(1);
}

void RegisterFunctions(BindLanguageContext* ctx)
{
	ctx-&amp;gt;RegisterFunction(&amp;quot;NativeFunctionExample&amp;quot;, NativeFunctionExample);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This of course means your function can only be called from script. If you want to call it from C++ code as well the classic solution is to instead create wrapper functions and register them:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;int NativeFunctionExample(int param0, string param1)
{
	// ...do some work with the parameters...
}

void NativeFunctionExample_Wrapper(BindLanguageContext* ctx)
{
	int param0 = ctx-&amp;gt;PopInt();
	string param1 = ctx-&amp;gt;PopString();
	int ret = NativeFunctionExample(param0, param1);
	ctx-&amp;gt;PushInt(ret);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now you can call &lt;code&gt;NativeFunctionExample&lt;/code&gt; from C++ and register &lt;code&gt;NativeFunctionExample_Wrapper&lt;/code&gt; with the script environment. Of course this is highly error-prone and downright tedious. It also gets worse when you try to bind to multiple languages, which is why many solutions have been developed to address these shortcomings.&lt;/p&gt;

&lt;p&gt;Examples of automated binding approaches include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.swig.org/&#34;&gt;SWIG&lt;/a&gt;: This scans your C/C++ header files and automatically generates wrapper code for anything you want to bind to other languages.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.boost.org/doc/libs/1_47_0/libs/python/doc/&#34;&gt;Boost.Python&lt;/a&gt;: Uses template meta-programming to generate the required wrappers at compile-time.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.rasterbar.com/products/luabind.html&#34;&gt;LuaBind&lt;/a&gt;: Uses template meta-programming for binding C++ to Lua.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://scottbilas.com/publications/gem-fubi/&#34;&gt;Gem (FuBi)&lt;/a&gt;: Uses knowledge of the platform ABI and a description of parameters to populate the native stack.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Template meta-programming approaches suffer from increased compile-times and along with code generation, result in larger than necessary executables. However, the approaches are cross-platform. On the other hand, if you have knowledge of the platform ABI you can write one function that takes a function signature and places parameters on the native stack before calling it. This requires highly platform-specific code but is remarkably concise and has a tiny footprint.&lt;/p&gt;

&lt;p&gt;In each of these binding libraries, however, you&amp;rsquo;ll find very similar function registration, parameter description and code generation techniques. This typically takes up a large majority of the implementation and can be quite complicated - the amount of code that deals with the specifics of the script language is not that great. If instead you took one of the above techniques and used it to populate an intermediate stack representation, you can write very simple code for each language variant you need to use:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void MakeParameterStack(ParameterStack&amp;amp; params, BindLanguageContext* ctx)
{
	// Iterate over every value pushed onto the script stack
	for (int i = 0; i &amp;lt; ctx-&amp;gt;ParametersOnStack(); i++)
	{
		BindLanguageVal* val = ctx-&amp;gt;GetStackRef();
		
		switch (val-&amp;gt;type)
		{
			// If required, convert the script value to a native equivalent
			// In the case of ints, floats, etc, nothing may need to be done
			// In the case of object references, you need a means of preserving
			//    the reference in the target language
		}
		
		// Add to the intermediate stack
		params.Add(val);
	}
}

void CallFunctionFromScript(BindLanguageContext* ctx, string function_name)
{
	// Retrieve the function from the reflecton database
	Function* function = db.GetFunction(function_name);
	
	// Build the parameter stack
	ParameterStack params;
	MakeParameterStack(params, ctx);
	
	// Call the native function
	function-&amp;gt;Call(params);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The complicated part of the problem is now holed up in the &lt;code&gt;Call&lt;/code&gt; function and whatever techniques you use to generate the reflection description of your functions. It&amp;rsquo;s comparitively easy to add new languages with this.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re uncomfortable with the overhead this introduces then an offline reflection database can be used to generate C++ wrappers for each function you want to call from script. Naturally, this increases the size of your executable but that may be a trade-off you can handle.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll be discussing techniques I&amp;rsquo;ve used to bind to Lua, C#, Python and my own custom game language in future posts. This will also include coverage of how container binding was handled.&lt;/p&gt;

&lt;p&gt;The final piece of the puzzle, RPC, should now be evident. All you need to do is serialise the parameter stack to a byte buffer and send that over the network. Any return values are serialised and returned. The details of how you wait/poll/interrupt on results are all you need to worry about.&lt;/p&gt;

&lt;h4 id=&#34;live-c-code-editing:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Live C++ code editing&lt;/h4&gt;

&lt;p&gt;Edit-and-continue is OK when it works, but what if you had the ability to edit large sections of your C++ code without having to shutdown the game, reload the compiled executable, load your levels, navigate to your testing location and resume what you were doing? What if you could come to work, load up the game and sit there all day &lt;strong&gt;in the game&lt;/strong&gt;, coding away until the day ended. Iteration is essential for creating great games and most studios will already have dynamic reloading of ingame assets such as scripts, textures, meshes, sounds or even entire level layouts. Some may even have a live connection between their editor and the game running on the console. C++ programmers are missing the boat!&lt;/p&gt;

&lt;p&gt;Before I cover this, there are a number of ways you can minimise the impact of this problem:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If you find a scripting language which doesn&amp;rsquo;t sacrifice expressiveness, safety and stability, you can swap it in for coding your game in C++. Correct use of scripting languages can allow you to build the majority of your game logic without also sacrificing performance.&lt;/li&gt;
&lt;li&gt;Compile shaders directly to object files that can be dynamically loaded and reloaded by your engine. Irrespective of how you represent shaders (HLSL files, shader graphs, DCC plugins, etc.) this is easy enough to achieve and should be first on your list.&lt;/li&gt;
&lt;li&gt;Try to make your rendering in some way scriptable without affecting performance - Direct3D effect files are a good example of this.&lt;/li&gt;
&lt;li&gt;Have a level editor that allows easy construction of test levels by programmers so that they can create libraries of levels that test specific features in the game for iterating on them. It should be no substitute for testing said features in final game levels before check-in, however.&lt;/li&gt;
&lt;li&gt;Have save games that can be triggered from any point that can save as much of the game state as possible.&lt;/li&gt;
&lt;li&gt;Work on your loading times before it&amp;rsquo;s too late. Long load times will reduce the amount of time you can spend iterating on your work and make the game harder to test within whatever time frame you have allocated.&lt;/li&gt;
&lt;li&gt;Work on the boot times and stability of your game and editors.&lt;/li&gt;
&lt;li&gt;Work on your compile times.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Done all that? Great! It&amp;rsquo;s not good enough, is it? As an engine programmer, the biggest problem I&amp;rsquo;ve always had with just having reloadable shaders is that at some point you have to edit your render code. When you start adding scriptability to your rendering pipeline you increase its complexity, make the performance more opaque, and never quite reach the flexibility you need, requiring endless hours moving back and forth or adapting the system to your requirements; time that could be spent writing your engine!&lt;/p&gt;

&lt;p&gt;During early development of the Splinter Cell: Conviction engine we had such a system. It was a custom rendering engine hosted within the UE framework that allowed the engine programers to iterate on the engine C++ code while UnrealEd was running. Most times code changes would take a couple of seconds to build and reload within the editor and at times we could code for a few hours without bringing the editor down. It was a little brittle and would break now and again because somebody would check-in engine changes that were incompatible with the object model - whether the object model had flaws or it required too much contextual knowledge to keep working, I unfortunately never got the chance to find out.&lt;/p&gt;

&lt;p&gt;However, you can achieve a similar system with a reflection API that has the following requirements:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Embed your code in reasonably partitioned DLLs.&lt;/li&gt;
&lt;li&gt;Cross-DLL communication occurs with interfaces (abstract base classes in C++, structures of function pointers in C).&lt;/li&gt;
&lt;li&gt;All dynamically created objects in your game are created from the same source.&lt;/li&gt;
&lt;li&gt;All objects have a unique ID through which they can be serialised - usually a 32-bit CRC of the object name.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you write a file system watcher that continously waits for changes to your DLL (or polls for it) then you can react to any change as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Identify all objects of any types in the changed DLL and store them.&lt;/li&gt;
&lt;li&gt;Iterate over the properties of objects that point to the collected objects. Replace the pointers with the unique ID of those objects.&lt;/li&gt;
&lt;li&gt;Serialise the collected objects to memory.&lt;/li&gt;
&lt;li&gt;Release the collected objects.&lt;/li&gt;
&lt;li&gt;Reload the DLL.&lt;/li&gt;
&lt;li&gt;Deserialise the collected objects from memory.&lt;/li&gt;
&lt;li&gt;Iterate over the properties of objects that point to the collected objects. Replace the unique ID with the newly allocated pointers to the objects.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The key to this is that you&amp;rsquo;re serialising everything that changes and you have the ability to walk the pointer graph and patch up the objects that are kept alive with the location of the newly created objects. The serialisation can be done to RAM on PC, letting the OS take care of the paging. On consoles you can&amp;rsquo;t really do that (with the exception of some debug kits) so you may have to implement a slower path that uses your network connection. Debugging is achieved simply by attaching/detaching to your process whenever necessary.&lt;/p&gt;

&lt;p&gt;I can&amp;rsquo;t stress enough how good this setup felt and how strongly I feel that every game should have it. This setup was literally serialising everything in a level within a few seconds (models, textures, data structures, etc.) without breaking a sweat.&lt;/p&gt;

&lt;h4 id=&#34;memory-mapping:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Memory Mapping&lt;/h4&gt;

&lt;p&gt;Memory mapping is an old technique that in its most basic form involves loading a file from whatever storage medium you are using with one single read, not touching the result: it&amp;rsquo;s usable as it is. It naturally evolved from the ROM programming model where both your code and data is defined in your code files, making limited use of slow-access RAM. There are notable cases of old Playstation games, for example, serialising the entire contents of RAM to a memory card for save games!&lt;/p&gt;

&lt;p&gt;Of course, in these days of heavy dynamic memory allocation and far more complicated data structures, this practice is rarely used. Especially when you consider that your load times are likely dominated by seek latency, volume of data and the complexity of any compression/recompression steps you perform.&lt;/p&gt;

&lt;p&gt;In cases where you really do need to-the-metal memory-mapped loading of specific data types you can do this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Walk over every pointer in the object and replace the object pointer with the hash of the object pointed to.&lt;/li&gt;
&lt;li&gt;Save with a single write to disk.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The loading code then becomes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;// Read the memory map header for this object, which determines its type
u32 type_hash = ReadU32();
Type* type = db.GetType(type_hash);

// Read the entire object into memory
void *object = AllocateAndConstruct();
ReadBlob(object, type-&amp;gt;size);

// Lookup each pointer hash
for (ptr in type-&amp;gt;pointers)
{
	void* ref = object_db.GetObject((u32)ptr);
	ptr = ref;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Of course, you&amp;rsquo;re now bound by the object lookups being performed per pointer. This can be accelerated by using bank/package files that store collections of objects with link tables. These link tables specify what objects are exported and imported, while object references now store indices into the link table. When a bank/package file is initially loaded, its import link table is updated by searching other bank/package files around it. The resolving of pointers then becomes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;for (ptr in type-&amp;gt;pointers)
{
	// The ptr now represents an index into the link table and a single bit representing
	// which link table to use
	u32 ptr_id = (u32)ptr;
	bool is_import = ptr_id &amp;amp; 0x80000000;
	
	// Pointer lookup is a simple array index
	if (is_import)
		ptr = import_table[ptr_id &amp;amp; 0x7FFFFFFF];
	else
		ptr = export_table[ptr_id &amp;amp; 0x7FFFFFFF];		
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;conclusion:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Conclusion&lt;/h4&gt;

&lt;p&gt;I hope nothing in the post above implies that specific techniques are the only options available to you. I&amp;rsquo;ve spent many years researching and implementing alternatives to the above and these are a sampling of the techniques I feel most comfortable with.&lt;/p&gt;

&lt;p&gt;To give you an sampling of how diverse the implementations can be, I&amp;rsquo;ve collected some articles/implementations you may find interesting.&lt;/p&gt;

&lt;h6 id=&#34;implementations:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Implementations&lt;/h6&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/HeliumProject/Reflect&#34;&gt;Helium Reflection&lt;/a&gt; - Initially part of the Insomniac Games Nocturnal initiative. It&amp;rsquo;s an intrusive, registration-based reflection API.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://root.cern.ch/how/how-use-reflex&#34;&gt;Reflex&lt;/a&gt; - Can use &lt;a href=&#34;http://www.gccxml.org/HTML/Index.html&#34;&gt;GCCXML&lt;/a&gt; or &lt;a href=&#34;http://root.cern.ch/drupal/content/cint&#34;&gt;CINT&lt;/a&gt; to parse header files and auto-generate reflection dictionaries.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://kifri.fri.uniza.sk/~chochlik/mirror-lib/html/&#34;&gt;Mirror&lt;/a&gt; - Template-based, built using Boost and intended for submission to the project. Offers both compile-time and runtime databases. Contains a separate tool to automatically generate C++ registration code.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://doc.qt.io/qt-4.8/metaobjects.html&#34;&gt;Qt Meta-Object System&lt;/a&gt; - The ubiquitous Qt has its own reflection system that uses a &amp;ldquo;Meta-Object Compiler&amp;rdquo; to scan C++ files for custom-marked properties that need reflecting.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ischo.com/xrtti/&#34;&gt;Xrtti&lt;/a&gt; - Uses GCCXML to generate C++ files that register reflection information for you.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cbloom.com/3d/galaxy3/&#34;&gt;Galaxy 3 Reflection&lt;/a&gt; - Intrusive, manual registration with some added template help.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cbloomrants.blogspot.com/2009/05/05-05-09-autoreflect.html&#34;&gt;Galaxy 4 Auto-Reflection&lt;/a&gt; - Uses a custom pre-processor to scan C++ files for markup, auto-generating the required C++ registration code.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://sourceforge.net/projects/crd/&#34;&gt;CRD&lt;/a&gt; - Template-based with heavy STL influences. Implementation mainly in one header file.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.garret.ru/cppreflection/docs/reflect.html&#34;&gt;cppreflect&lt;/a&gt; - Intrusive, macro-based manual registration.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tegesoft/camp&#34;&gt;CAMP&lt;/a&gt; - Template-based, manual registration with a minimal DSL-in-C++ approach.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&#34;articles:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Articles&lt;/h6&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/naughty_dog/adventures-in-data-compilation&#34;&gt;Adventures in Data Compilation&lt;/a&gt; - A Scheme DDL is used to generate C++ header files and runtime data files for Naughty Dog&amp;rsquo;s games.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.vollmann.com/en/pubs/meta/meta/meta.html&#34;&gt;Metaclasses and Reflection in C++&lt;/a&gt; - Classic article, one of the first in-depth C++ community discussions of reflection, describing MOP. This is another manual registration library.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/n1751.html&#34;&gt;Aspects of Reflection in C++&lt;/a&gt; - An introduction intended to kick-off discussion about adding reflection to C++0x.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.codeguru.com/Cpp/Cpp/cpp_mfc/rtti/article.php/c4061&#34;&gt;Advanced RTTI in C++&lt;/a&gt; - Extensive documentation of `&lt;code&gt;Oops&lt;/code&gt;, an inhouse property reflection API that uses macros to manually register property information.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.gamasutra.com/view/feature/6379/sponsored_feature_behind_the_.php&#34;&gt;Behind the Mirror - Adding Reflection to C++&lt;/a&gt; - Discussion of the Nocturnal reflection API.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&#34;blog-posts:17c7cde88a740d3a914f2e8970b0045b&#34;&gt;Blog posts&lt;/h6&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.enchantedage.com/cpp-reflection&#34;&gt;Static reflection in C++ using minimal repetition&lt;/a&gt; - Tries to reduce the inherent instability in registration-based reflection systems by embedding registration with declaration.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://msinilo.pl/blog/?p=517&#34;&gt;Reflection in C++&lt;/a&gt; - A system that scans PDB files for all the reflection info it needs and makes the result loadable at runtime. There are a few more posts on the site so hunt around a bit.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://gameangst.com/?p=107&#34;&gt;Class Reflection in the Despair Engine&lt;/a&gt; - Uses template-based registration with an attempted DSL-in-C++ approach.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is a bit of a big post and I&amp;rsquo;d like to thank everybody who&amp;rsquo;s reviewed it for me. Special mentions go to Stephen Hill who made several tireless passes and Patrick Duquette, who cleared the road at Ubisoft for me to talk about the SC5 stuff.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>